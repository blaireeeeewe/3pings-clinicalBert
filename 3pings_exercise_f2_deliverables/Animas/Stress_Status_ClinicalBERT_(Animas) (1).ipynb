{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQE7XBmrhZ2H"
      },
      "source": [
        "\n",
        "# Stress Status Detection ‚Äî End‚Äëto‚ÄëEnd Colab Notebook  \n",
        "**Order:** Load Dataset ‚Üí Baseline Models ‚Üí Pre‚ÄëTrained Models ‚Üí Training of Data ‚Üí Fine‚Äëtuning ‚Üí Eval\n",
        "\n",
        "> This notebook encodes the provided fine‚Äëtuning script into a structured, well‚Äëcommented pipeline.  \n",
        "> It includes at least **three hyperparameter experiments** (aiming to maximize **F1‚ÄëScore**).  \n",
        "> Replace the dataset path with your CSV if needed ‚Äî required columns: `statement` (text) and `status` (0/1).\n"
      ],
      "id": "iQE7XBmrhZ2H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwoPghthZ2K"
      },
      "source": [
        "# 0) Setup (libraries and reproducibility)"
      ],
      "id": "lOwoPghthZ2K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Import and Environment Setup ---\n",
        "\n",
        "import os\n",
        "\n",
        "- manages system paths, folders, and environment variables to handle files and directories efficiently during the execution of the notebook.\n",
        "\n",
        "import math\n",
        "\n",
        "- includes mathematical tools and formulas that can assist in calculations such as learning rate adjustments or numeric transformations during model training.\n",
        "\n",
        "import random\n",
        "\n",
        "- controls and initializes random number generation, ensuring that every run of the model produces consistent outcomes for reproducibility.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "- provides extensive support for numerical data handling, offering fast and flexible operations on arrays and matrices used throughout the data preparation process.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "- allows for structured data loading and manipulation, making it easier to explore, clean, and organize datasets, especially when working with CSV files.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "- gives a cleaner and more reliable way to manage file and directory paths across different operating systems.\n",
        "\n",
        "--- Core Framework Imports ---\n",
        "\n",
        "import torch\n",
        "\n",
        "- provides the base framework for tensor manipulation and GPU acceleration, enabling efficient computation for training and evaluating deep learning models.\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "- transforms pandas DataFrames into optimized dataset objects that integrate smoothly with the Hugging Face Transformers library for preprocessing and training.\n",
        "\n",
        "from transformers import (\n",
        "AutoTokenizer,\n",
        "\n",
        "- automatically selects and loads the appropriate tokenizer for a specific pre-trained model to ensure consistent tokenization.\n",
        "AutoModelForSequenceClassification,\n",
        "\n",
        "- initializes a pre-trained Transformer model with an added classification head, suitable for tasks like sentiment analysis or text categorization.\n",
        "TrainingArguments,\n",
        "\n",
        "- specifies and stores key hyperparameters such as the number of epochs, batch size, and evaluation frequency for the model training process.\n",
        "Trainer\n",
        "\n",
        "- streamlines the entire fine-tuning procedure, managing training, evaluation, logging, and checkpoint saving without requiring manual loop implementation.\n",
        ")\n",
        "\n",
        "--- Evaluation Metric Imports ---\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "- brings in performance evaluation tools that calculate key metrics such as accuracy, precision, recall, and F1-score to assess the model‚Äôs prediction quality.\n",
        "\n",
        "--- Reproducibility Configuration ---\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "- defines a fixed seed number to guarantee that all random processes across libraries yield consistent results.\n",
        "random.seed(SEED)\n",
        "\n",
        "- ensures that Python‚Äôs random number operations remain stable and predictable in every run.\n",
        "np.random.seed(SEED)\n",
        "\n",
        "- controls NumPy‚Äôs internal random processes to maintain the same shuffling or sampling patterns across executions.\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "- fixes PyTorch‚Äôs randomization for consistent model weight initialization and data handling.\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "- applies the same reproducibility rule across all available GPUs to maintain uniform outcomes even in multi-GPU training setups.\n",
        "\n",
        "--- Device Detection ---\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "- determines whether a GPU is available for acceleration and defaults to CPU if not, ensuring compatibility in any environment.\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "- prints out the current hardware in use to confirm that GPU acceleration is properly detected and active."
      ],
      "metadata": {
        "id": "lXM6q7RwB9PV"
      },
      "id": "lXM6q7RwB9PV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1V0utC5hZ2L",
        "outputId": "e0e1464a-b307-427c-d5ab-9d1e0194bcda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Every import has an explanatory comment.\n",
        "import os                         # file paths and environment checks\n",
        "import math                       # math helpers (may be useful for schedules)\n",
        "import random                     # Python's RNG for reproducibility\n",
        "import numpy as np                # numerical arrays and metrics support\n",
        "import pandas as pd               # data loading and manipulation\n",
        "from pathlib import Path          # convenient and robust path handling\n",
        "\n",
        "# Hugging Face / PyTorch stack (for transformer fine‚Äëtuning)\n",
        "import torch                      # tensor and GPU utilities\n",
        "from datasets import Dataset      # lightweight dataset wrapper around pandas\n",
        "from transformers import (       # core HF components for tokenization and training\n",
        "    AutoTokenizer,               # auto‚Äëloads the right tokenizer for a given model checkpoint\n",
        "    AutoModelForSequenceClassification,  # classification head on top of a transformer\n",
        "    TrainingArguments,           # training hyperparameters container\n",
        "    Trainer                      # training loop helper (handles eval and logging)\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Make runs reproducible (seed Python, NumPy, and PyTorch)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Detect device once and print for visibility\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")  # shows 'cuda' when a GPU is available in Colab\n"
      ],
      "id": "z1V0utC5hZ2L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ3rjAL2hZ2L"
      },
      "source": [
        "## 1) Load Dataset"
      ],
      "id": "wQ3rjAL2hZ2L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Load Dataset (Upload version, auto-encodes text labels) ---\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "- imports the pandas library, which is essential for reading, organizing, and analyzing CSV data within Python.\n",
        "\n",
        "#from pathlib import Path\n",
        "\n",
        "- provides a structured and cross-platform way to handle file paths, making directory navigation and file references more reliable.\n",
        "\n",
        "#from google.colab import files\n",
        "\n",
        "- activates Google Colab‚Äôs file upload feature, allowing users to upload local datasets directly into the runtime environment.\n",
        "\n",
        "#print(\"üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\")\n",
        "\n",
        "- displays a clear message prompting the user to upload a dataset file in CSV format for processing.\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        " -opens a file selection dialog so that the user can choose and upload the desired dataset from their computer.\n",
        "\n",
        "#filename = list(uploaded.keys())[0]\n",
        "\n",
        "- extracts the name of the uploaded file from the dictionary of uploaded files.\n",
        "\n",
        "#csv_path = Path(f\"/content/{filename}\")\n",
        "\n",
        "- constructs a full, system-compatible file path pointing to the uploaded dataset within the Colab working directory.\n",
        "\n",
        "#print(f\"‚úÖ File uploaded successfully: {csv_path}\")\n",
        "\n",
        "- provides feedback confirming that the file upload was successful and shows where the file was saved.\n",
        "\n",
        "#df = pd.read_csv(csv_path)\n",
        "\n",
        "- loads the uploaded CSV file into a pandas DataFrame, preparing it for inspection and processing.\n",
        "\n",
        "# --- Validate columns ---\n",
        "\n",
        "#expected_cols = {'statement', 'status'}\n",
        "\n",
        "- defines the columns that must exist in the dataset to ensure it matches the expected structure for further steps.\n",
        "\n",
        "#assert expected_cols.issubset(df.columns), f\"‚ùå Missing required columns: {expected_cols - set(df.columns)}\"\n",
        "\n",
        "- verifies that all required columns are present in the dataset; if not, the code stops and reports which ones are missing.\n",
        "\n",
        "# --- Clean ---\n",
        "\n",
        "#df = df.dropna(subset=['statement', 'status']).copy()\n",
        "\n",
        "- deletes any rows containing missing values in the ‚Äòstatement‚Äô or ‚Äòstatus‚Äô columns to maintain data consistency.\n",
        "\n",
        "#df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "- converts all entries in the ‚Äòstatement‚Äô column into string type to prevent formatting or type errors later in processing.\n",
        "\n",
        "# --- Encode text labels into integers ---\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "- brings in a class from scikit-learn that converts categorical text labels into numerical form for model compatibility.\n",
        "\n",
        "#le = LabelEncoder()\n",
        "\n",
        "- initializes the LabelEncoder, preparing it to map text categories into numeric codes.\n",
        "\n",
        "#df['status_encoded'] = le.fit_transform(df['status'])\n",
        "\n",
        "- fits the encoder to the ‚Äòstatus‚Äô column and generates a new column containing the corresponding numeric label values.\n",
        "\n",
        "#print(\"üî§ Label encoding map:\")\n",
        "\n",
        "- prints a section heading to indicate that the label-to-code mapping will be shown next.\n",
        "\n",
        "#for label, code in zip(le.classes_, range(len(le.classes_))):\n",
        "\n",
        "- loops through each label and its encoded numeric representation to display the mapping relationship.\n",
        "  print(f\"  {code} ‚Üí {label}\")  - prints each numeric code and its associated label for verification.\n",
        "\n",
        "#df['status'] = df['status_encoded']\n",
        "\n",
        "- replaces the original ‚Äòstatus‚Äô column‚Äôs text labels with their corresponding numeric values.\n",
        "\n",
        "#df.drop(columns=['status_encoded'], inplace=True)\n",
        "\n",
        "- deletes the temporary ‚Äòstatus_encoded‚Äô column since the main ‚Äòstatus‚Äô column now contains the encoded values.\n",
        "\n",
        "#print(\"\\n‚úÖ Dataset loaded and label-encoded successfully!\")\n",
        "\n",
        "- outputs a confirmation message indicating that the dataset has been fully cleaned and encoded without errors.\n",
        "\n",
        "#print(df['status'].value_counts(dropna=False))\n",
        "\n",
        "- displays a frequency count of each encoded label, helping verify that the encoding process was applied correctly.\n",
        "\n",
        "#df.head(3)\n",
        "\n",
        "- shows the first three rows of the cleaned and processed dataset to confirm that all transformations were applied successfully.\n"
      ],
      "metadata": {
        "id": "UKbddZcLB-e5"
      },
      "id": "UKbddZcLB-e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "CMBpEom1hZ2M",
        "outputId": "0b419b6c-46d6-4b46-89e7-1b34b216b0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4da332ec-4edb-4bfb-9dc0-c6593407b70f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4da332ec-4edb-4bfb-9dc0-c6593407b70f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Combined Data.csv to Combined Data (2).csv\n",
            "‚úÖ File uploaded successfully: /content/Combined Data (2).csv\n",
            "üî§ Label encoding map:\n",
            "  0 ‚Üí Anxiety\n",
            "  1 ‚Üí Bipolar\n",
            "  2 ‚Üí Depression\n",
            "  3 ‚Üí Normal\n",
            "  4 ‚Üí Personality disorder\n",
            "  5 ‚Üí Stress\n",
            "  6 ‚Üí Suicidal\n",
            "\n",
            "‚úÖ Dataset loaded and label-encoded successfully!\n",
            "status\n",
            "3    16343\n",
            "2    15404\n",
            "6    10652\n",
            "0     3841\n",
            "1     2777\n",
            "5     2587\n",
            "4     1077\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                          statement  status\n",
              "0           0                                         oh my gosh       0\n",
              "1           1  trouble sleeping, confused mind, restless hear...       0\n",
              "2           2  All wrong, back off dear, forward doubt. Stay ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57642578-bac5-498e-bc81-5c4d7597b015\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57642578-bac5-498e-bc81-5c4d7597b015')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57642578-bac5-498e-bc81-5c4d7597b015 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57642578-bac5-498e-bc81-5c4d7597b015');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6b88fae-1411-4565-a5ae-000d91305bfd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6b88fae-1411-4565-a5ae-000d91305bfd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6b88fae-1411-4565-a5ae-000d91305bfd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52681,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15235,\n        \"min\": 0,\n        \"max\": 53042,\n        \"num_unique_values\": 52681,\n        \"samples\": [\n          3008,\n          44705,\n          50186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51073,\n        \"samples\": [\n          \"he's been a chain smoker for 30 years.\",\n          \"Dependence on therapist I attend IOP groups and individual therapy sessions at the same place, my therapist who I have worked with on and off for a year and a couple months just told me today that she is leaving soon and I am heartbroken. I love my therapist and I don't know how I am going to keep progressing without her. There will be a replacement for her but idk what to do, I don't want a different therapist. :(\",\n          \"These feelings constantly come back. Someone from my past that hurt me came back a month ago and once again disrespected me and i just feel like shit. Idk why these feelings keep resurfacing but it just hurts. I do not want to be over dramatic but Its hurts when you were nothing but loving/kind to someone and they disrespect you. I just hate feeling like this, feeling like i cannot trust anyone or that no one would ever truly love me unless i have something to offer. I am always worried about my looks and its just making me depressed. I really do not feel like i fit in with the world I am just here. Idk what my next step should be to get help but I am really going through it. (Yes I am in therapy) but how do i help myself ? I have been depressed/anxious for years and most day i do not even leave my house. But nobody around me seems to care and honestly I am tired of feeling this way. But at the same time i do not want to give up on myself bc i feel like I am here to be somebody great. I am just trying to find my way right now. It keeps coming back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# --- Load Dataset (Upload version, auto-encodes text labels) ---\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Automatically pick the first uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "csv_path = Path(f\"/content/{filename}\")\n",
        "\n",
        "print(f\"‚úÖ File uploaded successfully: {csv_path}\")\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# --- Validate columns ---\n",
        "expected_cols = {'statement', 'status'}\n",
        "assert expected_cols.issubset(df.columns), f\"‚ùå Missing required columns: {expected_cols - set(df.columns)}\"\n",
        "\n",
        "# --- Clean ---\n",
        "df = df.dropna(subset=['statement', 'status']).copy()\n",
        "df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "# --- Encode text labels into integers ---\n",
        "# This maps each unique label (like 'Anxiety', 'Stress', etc.) to a numeric ID\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['status_encoded'] = le.fit_transform(df['status'])\n",
        "\n",
        "# Optional: print mapping for your reference\n",
        "print(\"üî§ Label encoding map:\")\n",
        "for label, code in zip(le.classes_, range(len(le.classes_))):\n",
        "    print(f\"  {code} ‚Üí {label}\")\n",
        "\n",
        "# Replace 'status' with the encoded version\n",
        "df['status'] = df['status_encoded']\n",
        "df.drop(columns=['status_encoded'], inplace=True)\n",
        "\n",
        "print(\"\\n‚úÖ Dataset loaded and label-encoded successfully!\")\n",
        "print(df['status'].value_counts(dropna=False))\n",
        "df.head(3)\n"
      ],
      "id": "CMBpEom1hZ2M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymAj-xUdhZ2M"
      },
      "source": [
        "## 2) Baseline Models (TF‚ÄëIDF + Linear)"
      ],
      "id": "ymAj-xUdhZ2M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Baseline Models (TF-IDF + Linear, supports multi-class) ---\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "‚Äì divides the dataset into separate subsets for training and validation purposes\n",
        "\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "‚Äì transforms raw text into numerical representations using the TF-IDF method\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "‚Äì loads the logistic regression algorithm used for text classification\n",
        "\n",
        "#from sklearn.svm import LinearSVC\n",
        "‚Äì loads the linear support vector machine classifier for categorizing text\n",
        "\n",
        "#from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "‚Äì provides built-in functions to measure model performance using common evaluation metrics\n",
        "\n",
        "#import numpy as np\n",
        "‚Äì supports efficient numerical calculations and operations on arrays\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_test_split(\n",
        "\n",
        "df['statement'].values,\n",
        "df['status'].values,\n",
        "test_size=0.2,\n",
        "random_state=42,\n",
        "stratify=df['status'].values\n",
        "\n",
        "#)\n",
        "‚Äì separates the dataset into 80% training and 20% validation samples while maintaining balanced class distribution\n",
        "\n",
        "#tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=40000)\n",
        "‚Äì builds a TF-IDF model that captures single words and two-word phrases, ignoring rare terms and limiting total features to 40,000\n",
        "\n",
        "#Xtr = tfidf.fit_transform(X_train)\n",
        "‚Äì learns vocabulary patterns from the training set and converts text into TF-IDF feature vectors\n",
        "\n",
        "#Xva = tfidf.transform(X_val)\n",
        "‚Äì applies the trained TF-IDF transformation to the validation set without retraining\n",
        "\n",
        "#num_classes = len(np.unique(y_train))\n",
        "‚Äì determines how many distinct categories or labels exist in the dataset\n",
        "\n",
        "#avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "‚Äì automatically chooses whether to use binary or weighted averaging based on the number of classes\n",
        "\n",
        "#print(f\"Detected {num_classes} classes ‚Üí using average='{avg_type}' for metrics.\\n\")\n",
        "‚Äì outputs the number of identified classes and indicates which averaging method will be applied for evaluation\n",
        "\n",
        "--- Baseline 1: Logistic Regression ---\n",
        "\n",
        "#logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "‚Äì creates a logistic regression model configured to balance uneven class frequencies and allow more training iterations\n",
        "\n",
        "#logreg.fit(Xtr, y_train)\n",
        "‚Äì trains the logistic regression classifier using the prepared TF-IDF features and corresponding labels\n",
        "\n",
        "#pred_lr = logreg.predict(Xva)\n",
        "‚Äì produces predictions on unseen validation data using the trained logistic regression model\n",
        "\n",
        "#p, r, f, _ = precision_recall_fscore_support(y_val, pred_lr, average=avg_type)\n",
        "‚Äì calculates the precision, recall, and F1-score metrics according to the averaging method chosen\n",
        "\n",
        "#acc = accuracy_score(y_val, pred_lr)\n",
        "‚Äì evaluates how often the logistic regression model predicted the correct label\n",
        "\n",
        "#print(f\"[Baseline-LR] Acc={acc:.3f} P={p:.3f} R={r:.3f} F1={f:.3f}\")\n",
        "‚Äì prints the accuracy, precision, recall, and F1-score results for the logistic regression model\n",
        "\n",
        "--- Baseline 2: Linear SVM ---\n",
        "\n",
        "#svm = LinearSVC(class_weight=\"balanced\")\n",
        "‚Äì initializes a linear SVM model that compensates for class imbalance during training\n",
        "\n",
        "#svm.fit(Xtr, y_train)\n",
        "‚Äì fits the SVM classifier using the TF-IDF features from the training data\n",
        "\n",
        "#pred_svm = svm.predict(Xva)\n",
        "‚Äì predicts the validation set labels using the trained SVM model\n",
        "\n",
        "#p, r, f, _ = precision_recall_fscore_support(y_val, pred_svm, average=avg_type)\n",
        "‚Äì computes precision, recall, and F1-score for the SVM‚Äôs predictions based on the selected averaging mode\n",
        "\n",
        "#acc = accuracy_score(y_val, pred_svm)\n",
        "‚Äì determines the SVM model‚Äôs accuracy across all validation examples\n",
        "\n",
        "#print(f\"[Baseline-SVM] Acc={acc:.3f} P={p:.3f} R={r:.3f} F1={f:.3f}\")\n",
        "‚Äì displays the accuracy, precision, recall, and F1-score achieved by the SVM baseline model\n"
      ],
      "metadata": {
        "id": "xNWyoNu3CBhm"
      },
      "id": "xNWyoNu3CBhm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4IjGl_JhZ2M",
        "outputId": "9664c070-a5a5-4a8b-eed7-3d14618b933f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 7 classes ‚Üí using average='weighted' for metrics.\n",
            "\n",
            "[Baseline-LR] Acc=0.778  P=0.787  R=0.778  F1=0.777\n",
            "[Baseline-SVM] Acc=0.782  P=0.779  R=0.782  F1=0.780\n"
          ]
        }
      ],
      "source": [
        "# --- Baseline Models (TF-IDF + Linear, supports multi-class) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Train/validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['statement'].values,\n",
        "    df['status'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['status'].values\n",
        ")\n",
        "\n",
        "# Convert raw text into TF-IDF features\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=40000)\n",
        "Xtr = tfidf.fit_transform(X_train)\n",
        "Xva = tfidf.transform(X_val)\n",
        "\n",
        "# Detect if this is binary or multiclass\n",
        "num_classes = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "print(f\"Detected {num_classes} classes ‚Üí using average='{avg_type}' for metrics.\\n\")\n",
        "\n",
        "# --- Baseline 1: Logistic Regression ---\n",
        "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "logreg.fit(Xtr, y_train)\n",
        "pred_lr = logreg.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_lr, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_lr)\n",
        "print(f\"[Baseline-LR] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n",
        "\n",
        "# --- Baseline 2: Linear SVM ---\n",
        "svm = LinearSVC(class_weight=\"balanced\")\n",
        "svm.fit(Xtr, y_train)\n",
        "pred_svm = svm.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_svm, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_svm)\n",
        "print(f\"[Baseline-SVM] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n"
      ],
      "id": "k4IjGl_JhZ2M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xic-iii4hZ2N"
      },
      "source": [
        "## 3) Pre‚ÄëTrained Models (Tokenization and Dataset Prep)"
      ],
      "id": "xic-iii4hZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Transformer Backbone and Tokenization Setup ---\n",
        "\n",
        "#CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "‚Äì specifies the pretrained ClinicalBERT model, which is optimized for understanding clinical and medical language\n",
        "\n",
        "#DISTIL_BERT = \"distilbert-base-uncased\"\n",
        "‚Äì specifies the lightweight DistilBERT model designed for faster and more efficient fine-tuning compared to larger transformer models\n",
        "\n",
        "#BACKBONE = CLINICAL_BERT\n",
        "‚Äì assigns ClinicalBERT as the main transformer model to be used for this experiment\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "‚Äì loads the tokenizer associated with the selected transformer model to ensure text encoding consistency\n",
        "\n",
        "#def tokenize_texts(texts, max_length=128):\n",
        "‚Äì defines a reusable function that converts a collection of raw text samples into tokenized sequences suitable for the model\n",
        "    #return tokenizer(\n",
        "      list(texts),‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚Äì transforms the input texts into a list format\n",
        "      padding=True,‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚Äì automatically pads all sequences to the same length\n",
        "      truncation=True,‚ÄÉ‚ÄÉ‚ÄÉ‚Äì shortens sequences that exceed the specified maximum length\n",
        "      max_length=max_length,‚ÄÉ‚Äì defines the limit for each tokenized text sequence\n",
        "      return_tensors=\"pt\"‚ÄÉ‚ÄÉ‚Äì outputs data as PyTorch-compatible tensors\n",
        "    )\n",
        "‚Äì applies the tokenizer configuration to the texts and produces ready-to-use numerical tensors\n",
        "\n",
        "#train_enc = tokenize_texts(X_train)\n",
        "‚Äì processes and encodes all training sentences into model-readable token IDs and attention masks\n",
        "\n",
        "#val_enc = tokenize_texts(X_val)\n",
        "‚Äì applies the same tokenization steps to the validation set to maintain consistency with the training data\n",
        "\n",
        "#train_ds = Dataset.from_dict({\n",
        "\n",
        "\"input_ids\": train_enc[\"input_ids\"],\n",
        "\"attention_mask\": train_enc[\"attention_mask\"],\n",
        "\"labels\": torch.tensor(y_train)\n",
        "\n",
        "#})\n",
        "‚Äì builds a structured Hugging Face dataset for the training portion, including encoded inputs and their respective labels\n",
        "\n",
        "#val_ds = Dataset.from_dict({\n",
        "\n",
        "\"input_ids\": val_enc[\"input_ids\"],\n",
        "\"attention_mask\": val_enc[\"attention_mask\"],\n",
        "\"labels\": torch.tensor(y_val)\n",
        "\n",
        "#})\n",
        "‚Äì constructs a matching dataset object for the validation data with identical field structure\n",
        "\n",
        "#len(train_ds), len(val_ds)\n",
        "‚Äì verifies and displays how many records are contained within the training and validation datasets"
      ],
      "metadata": {
        "id": "SBeklvMECK6W"
      },
      "id": "SBeklvMECK6W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "591cdd45c7b74fa181821f9529944da2",
            "776524b1ce5c4c5bb65f8d8e65516273",
            "3d089afa63744558bb3a6f7a1b876aef",
            "e4a09e0a755241daad5e0330cfe68fd2",
            "b81c22472d7940c798254fd44d9877b8",
            "5da86772c65244f09c694822bd730ce2",
            "1cd05c5690a743bbb2472e7b3d8a91c5",
            "b07464960b8645bbaca506d2ef31bace",
            "5fde31686a35414f962235ea930bdccb",
            "4b95ecc756ea41f29095ab7890ab856c",
            "5a1b98fe2c514b45a8153a30ba29225b",
            "bd7b191158e14b56b7fb18d781905220",
            "c86017ab938b4f46baa78b381b03320c",
            "11930ebd9ce2434c8aaf21655a0f564a",
            "e217ae1ba3974278934fbb75fae99d57",
            "3c9e5917c4754acbbb908f3431191d45",
            "1c6926731b6e4c06a63e5a2ef414f6a9",
            "35c4939c98a141cdaecbbd978211e48d",
            "ddd174a933954b4fab9f1640ad491973",
            "ade9e93734a1456797e0340e38182c04",
            "74b176f12a3d42139088e6f4dd3f2d12",
            "08e6b823fa1042c9892bc49c949a2857"
          ]
        },
        "id": "CJsRDxIlhZ2N",
        "outputId": "baf876dd-c9d2-4b5e-8220-70328e404cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "591cdd45c7b74fa181821f9529944da2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd7b191158e14b56b7fb18d781905220"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42144, 10537)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "# Choose your checkpoints.\n",
        "# We include ClinicalBERT (for clinical text) and DistilBERT (fast baseline).\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "# Pick one as the default backbone for experiments below.\n",
        "BACKBONE = CLINICAL_BERT\n",
        "\n",
        "# Initialize tokenizer for the chosen backbone\n",
        "tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "\n",
        "# Helper to tokenize a pandas series with per-line comments\n",
        "def tokenize_texts(texts, max_length=128):\n",
        "    # Apply the tokenizer: returns dict with input_ids and attention_mask\n",
        "    return tokenizer(\n",
        "        list(texts),                 # a Python list of strings\n",
        "        padding=True,                # pad to the longest in the batch\n",
        "        truncation=True,             # cut off text exceeding max_length\n",
        "        max_length=max_length,       # cap sequence length\n",
        "        return_tensors=\"pt\"          # return PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize train/validation splits\n",
        "train_enc = tokenize_texts(X_train)\n",
        "val_enc   = tokenize_texts(X_val)\n",
        "\n",
        "# Wrap into HF Datasets with labels\n",
        "train_ds = Dataset.from_dict({\n",
        "    \"input_ids\": train_enc[\"input_ids\"],\n",
        "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_train)\n",
        "})\n",
        "val_ds = Dataset.from_dict({\n",
        "    \"input_ids\": val_enc[\"input_ids\"],\n",
        "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_val)\n",
        "})\n",
        "\n",
        "len(train_ds), len(val_ds)\n"
      ],
      "id": "CJsRDxIlhZ2N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A6SNywxhZ2N"
      },
      "source": [
        "## 4) Training of Data (Trainer utilities and metrics)"
      ],
      "id": "2A6SNywxhZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric function for the Trainer: computes Accuracy, Precision, Recall, F1\n",
        "\n",
        "‚Äì defines a function used by the Trainer to evaluate model performance through key metrics such as accuracy, precision, recall, and F1-score\n",
        "\n",
        "eval_pred is a tuple of (logits, labels)\n",
        "\n",
        "‚Äì indicates that the function receives two components: the model‚Äôs raw predictions (logits) and the actual ground-truth labels (labels)\n",
        "\n",
        "logits, labels = eval_pred\n",
        "\n",
        "‚Äì unpacks the tuple into separate variables representing predicted outputs and true labels\n",
        "\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "‚Äì selects the class with the highest predicted probability for each input sample\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "\n",
        "‚Äì calculates precision, recall, and F1-score across all predictions using a binary averaging scheme\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "\n",
        "‚Äì measures the overall proportion of correct predictions made by the model\n",
        "\n",
        "return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "‚Äì returns the computed metrics in a dictionary format for reporting and monitoring during training\n",
        "\n",
        "Optional: class weights for imbalanced datasets\n",
        "\n",
        "‚Äì introduces a section that handles uneven class distributions by adjusting their relative training importance\n",
        "\n",
        "Compute weights inversely proportional to class frequencies\n",
        "\n",
        "‚Äì derives weight values where less frequent classes receive higher importance in the loss function\n",
        "\n",
        "pos = (y_train == 1).sum()\n",
        "\n",
        "‚Äì counts how many samples belong to the positive class in the training data\n",
        "\n",
        "neg = (y_train == 0).sum()\n",
        "\n",
        "‚Äì counts how many samples belong to the negative class in the training data\n",
        "\n",
        "w_pos = neg / max(pos, 1) # weight for positive class\n",
        "\n",
        "‚Äì assigns a weight to the positive class that is inversely proportional to its frequency to counter class imbalance\n",
        "\n",
        "w_neg = 1.0 # keep negative as baseline\n",
        "\n",
        "‚Äì keeps the negative class weight as the standard reference (baseline weight of 1.0)\n",
        "\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float).to(device)\n",
        "\n",
        "‚Äì converts both class weights into a PyTorch tensor and transfers them to the active computing device (CPU or GPU)\n",
        "\n",
        "#print(f\"Class weights (neg, pos): {class_weights.tolist()}\")\n",
        "‚Äì outputs the computed class weights for verification and transparency\n",
        "\n",
        "Custom Trainer that injects weighted loss\n",
        "\n",
        "‚Äì defines a subclass of the Hugging Face Trainer that incorporates class-weighted loss during backpropagation\n",
        "\n",
        "#from torch.nn import CrossEntropyLoss\n",
        "‚Äì imports the cross-entropy loss function, which is standard for classification tasks\n",
        "\n",
        "#class WeightedTrainer(Trainer):\n",
        "‚Äì creates a custom training class that inherits properties and methods from the base Trainer class\n",
        "\n",
        "#def compute_loss(self, model, inputs, return_outputs=False):\n",
        "‚Äì overrides the default loss computation method to integrate the weighted loss function\n",
        "\n",
        "#labels = inputs.get(\"labels\")\n",
        "‚Äì extracts the true labels from the batch input dictionary\n",
        "\n",
        "#outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "‚Äì performs a forward pass through the model while excluding the labels from the input arguments\n",
        "\n",
        "#logits = outputs.get(\"logits\")\n",
        "‚Äì retrieves the predicted logits from the model output\n",
        "\n",
        "#loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "‚Äì initializes a cross-entropy loss function that applies the predefined class weights\n",
        "\n",
        "#loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "‚Äì computes the final weighted loss by comparing predicted logits and true labels across all samples\n",
        "\n",
        "#return (loss, outputs) if return_outputs else loss\n",
        "‚Äì returns both loss and model outputs (if requested), otherwise only the computed loss for training"
      ],
      "metadata": {
        "id": "rUDnzZ1_CMLD"
      },
      "id": "rUDnzZ1_CMLD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_4oBKl6hZ2N",
        "outputId": "66d05985-aab7-4927-d23a-7341b0cd56be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights (neg, pos): [1.0, 1.3836109638214111]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Metric function for the Trainer: computes Accuracy, Precision, Recall, F1\n",
        "def compute_metrics(eval_pred):\n",
        "    # eval_pred is a tuple of (logits, labels)\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Optional: class weights for imbalanced datasets\n",
        "# Compute weights inversely proportional to class frequencies\n",
        "pos = (y_train == 1).sum()\n",
        "neg = (y_train == 0).sum()\n",
        "w_pos = neg / max(pos, 1)   # weight for positive class\n",
        "w_neg = 1.0                 # keep negative as baseline\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float).to(device)\n",
        "print(f\"Class weights (neg, pos): {class_weights.tolist()}\" )\n",
        "\n",
        "# Custom Trainer that injects weighted loss\n",
        "from torch.nn import CrossEntropyLoss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "id": "9_4oBKl6hZ2N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvrjk1PlhZ2N"
      },
      "source": [
        "## 5) Fine‚Äëtuning (Three Experiments)"
      ],
      "id": "Dvrjk1PlhZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* `# --- 5) Fine-tuning (Three Experiments) [version-compatible] ---`\n",
        "  ‚Äì runs three fine-tuning trials with settings that work across different Transformers versions.\n",
        "\n",
        "* `# 1) Metrics: binary vs multiclass handled automatically`\n",
        "  ‚Äì chooses the proper metric averaging based on whether the task is binary or multi-class.\n",
        "\n",
        "* `# 2) Class weights for imbalanced data (size == num_labels)`\n",
        "  ‚Äì builds a weight vector per class to address label imbalance.\n",
        "\n",
        "* `# Heuristic: inverse-frequency scaled to max=1.0 (safe for CE)`\n",
        "  ‚Äì uses inverse class frequency, normalized so the largest weight equals 1.0, suitable for cross-entropy.\n",
        "\n",
        "* `# 3) Helper: tokenizer already defined above. Re-tokenize per max_length`\n",
        "  ‚Äì re-encodes text using the existing tokenizer, honoring the given maximum sequence length.\n",
        "\n",
        "* `# 4) Version-compatible TrainingArguments factory`\n",
        "  ‚Äì creates TrainingArguments that adapt to both newer and older library versions.\n",
        "\n",
        "* `# Try modern signature first`\n",
        "  ‚Äì attempts to instantiate with contemporary argument names and options.\n",
        "\n",
        "* `# Fallback for older transformers (no evaluation_strategy/save_strategy)`\n",
        "  ‚Äì switches to legacy parameters when the newer ones aren‚Äôt supported.\n",
        "\n",
        "* `# do_eval=True  # legacy way to enable evaluation`\n",
        "  ‚Äì turns on evaluation using the older configuration style.\n",
        "\n",
        "* `# save_steps=500  # periodic saving`\n",
        "  ‚Äì saves checkpoints at fixed step intervals.\n",
        "\n",
        "* `# Re-tokenize for this max_length`\n",
        "  ‚Äì encodes the train/validation texts again for the chosen sequence length.\n",
        "\n",
        "* `# Load backbone with correct num_labels`\n",
        "  ‚Äì initializes the model with the appropriate number of output classes.\n",
        "\n",
        "* `# --- Define backbones (already set earlier) ---`\n",
        "  ‚Äì lists the model names used in the experiments.\n",
        "\n",
        "* `# Exp-A: ClinicalBERT, conservative LR, small batch`\n",
        "  ‚Äì first run: ClinicalBERT with a lower learning rate and batch size 16.\n",
        "\n",
        "* `# Exp-B: ClinicalBERT, slightly higher LR, more epochs`\n",
        "  ‚Äì second run: ClinicalBERT with a higher learning rate and an extra training epoch.\n",
        "\n",
        "* `# Exp-C: DistilBERT fast baseline`\n",
        "  ‚Äì third run: DistilBERT configured for a quicker baseline comparison.\n",
        "\n",
        "* `# Leaderboard`\n",
        "  ‚Äì prints a summary table ranking experiments by F1-score (with accuracy shown as well).\n"
      ],
      "metadata": {
        "id": "bYaD7RDrCPdp"
      },
      "id": "bYaD7RDrCPdp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LkYDOan1hZ2O",
        "outputId": "55215eba-a0e6-4915-947f-809800dc0e16"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4064124003.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 1) Metrics: binary vs multiclass handled automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mavg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Fine-tune] Detected {num_labels} classes ‚Üí metrics average='{avg_type}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "source": [
        "# --- 5) Fine-tuning (Three Experiments) [version-compatible] ---\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Metrics: binary vs multiclass handled automatically\n",
        "num_labels = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "print(f\"[Fine-tune] Detected {num_labels} classes ‚Üí metrics average='{avg_type}'\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "# 2) Class weights for imbalanced data (size == num_labels)\n",
        "counts = np.bincount(y_train, minlength=num_labels)\n",
        "# Heuristic: inverse-frequency scaled to max=1.0 (safe for CE)\n",
        "weights = counts.max() / np.maximum(counts, 1)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "print(f\"[Fine-tune] Class weights: {class_weights.tolist()}\")\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 3) Helper: tokenizer already defined above. Re-tokenize per max_length\n",
        "def tokenize_texts(texts, max_length=160):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# 4) Version-compatible TrainingArguments factory\n",
        "import inspect\n",
        "\n",
        "def make_training_args(name, batch_size, lr, epochs, weight_decay, warmup_ratio):\n",
        "    kwargs_modern = dict(\n",
        "        output_dir=f\"./runs/{name}\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[]\n",
        "    )\n",
        "    try:\n",
        "        # Try modern signature first\n",
        "        return TrainingArguments(**kwargs_modern)\n",
        "    except TypeError:\n",
        "        # Fallback for older transformers (no evaluation_strategy/save_strategy)\n",
        "        print(\"[Fine-tune] Using legacy TrainingArguments fallback.\")\n",
        "        kwargs_legacy = dict(\n",
        "            output_dir=f\"./runs/{name}\",\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            learning_rate=lr,\n",
        "            num_train_epochs=epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            logging_steps=50,\n",
        "            do_eval=True,          # legacy way to enable evaluation\n",
        "            save_steps=500,        # periodic saving\n",
        "            overwrite_output_dir=True,\n",
        "            fp16=torch.cuda.is_available()\n",
        "        )\n",
        "        return TrainingArguments(**kwargs_legacy)\n",
        "\n",
        "def run_experiment(name, backbone, batch_size=16, lr=2e-5, epochs=3,\n",
        "                   weight_decay=0.01, warmup_ratio=0.1, max_length=160):\n",
        "    # Re-tokenize for this max_length\n",
        "    tr = tokenize_texts(X_train, max_length=max_length)\n",
        "    va = tokenize_texts(X_val,   max_length=max_length)\n",
        "\n",
        "    train_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": tr[\"input_ids\"],\n",
        "        \"attention_mask\": tr[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_train, dtype=torch.long)\n",
        "    })\n",
        "    val_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": va[\"input_ids\"],\n",
        "        \"attention_mask\": va[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_val, dtype=torch.long)\n",
        "    })\n",
        "\n",
        "    # Load backbone with correct num_labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        backbone, num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    args = make_training_args(\n",
        "        name=name, batch_size=batch_size, lr=lr, epochs=epochs,\n",
        "        weight_decay=weight_decay, warmup_ratio=warmup_ratio\n",
        "    )\n",
        "\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds_local,\n",
        "        eval_dataset=val_ds_local,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"\\n>>> {name} results: {metrics}\\n\")\n",
        "    return metrics, trainer\n",
        "\n",
        "# --- Define backbones (already set earlier) ---\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "results = OrderedDict()\n",
        "\n",
        "# Exp-A: ClinicalBERT, conservative LR, small batch\n",
        "results['expA_clinicalbert_bs16_lr2e-5_ep3'] = run_experiment(\n",
        "    name=\"expA_clinicalbert_bs16_lr2e-5_ep3\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=2e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-B: ClinicalBERT, slightly higher LR, more epochs\n",
        "results['expB_clinicalbert_bs16_lr5e-5_ep4'] = run_experiment(\n",
        "    name=\"expB_clinicalbert_bs16_lr5e-5_ep4\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=5e-5, epochs=4,\n",
        "    weight_decay=0.01, warmup_ratio=0.06, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-C: DistilBERT fast baseline\n",
        "results['expC_distilbert_bs32_lr3e-5_ep3'] = run_experiment(\n",
        "    name=\"expC_distilbert_bs32_lr3e-5_ep3\",\n",
        "    backbone=DISTIL_BERT,\n",
        "    batch_size=32, lr=3e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=128\n",
        ")\n",
        "\n",
        "# Leaderboard\n",
        "board = []\n",
        "for k,(m,_t) in results.items():\n",
        "    board.append((k, m.get('eval_f1', float('nan')), m.get('eval_accuracy', float('nan'))))\n",
        "board = sorted(board, key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nLeaderboard (by F1):\")\n",
        "for name, f1, acc in board:\n",
        "    print(f\"{name:35s}  F1={f1:.4f}  Acc={acc:.4f}\")\n"
      ],
      "id": "LkYDOan1hZ2O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSTDHJX1hZ2O"
      },
      "source": [
        "## 6) Eval (Pick Best and Run Inference)"
      ],
      "id": "MSTDHJX1hZ2O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `# Select the best run from 'results' dict above`\n",
        "  Introduces the section that will pick the highest-scoring experiment.\n",
        "\n",
        "* `best_name, best_f1 = None, -1.0`\n",
        "  Initializes the current ‚Äúbest‚Äù run name to nothing and its F1 to a very low value.\n",
        "\n",
        "* `best_trainer = None`\n",
        "  Placeholder for the Trainer object of the best run.\n",
        "\n",
        "* `for name,(metrics, trainer) in results.items():`\n",
        "  Loops through each experiment entry, unpacking its metrics and Trainer.\n",
        "\n",
        "* `    if metrics['eval_f1'] > best_f1:`\n",
        "  Checks if this experiment‚Äôs F1 beats the current best.\n",
        "\n",
        "* `        best_f1 = metrics['eval_f1']`\n",
        "  Updates the best F1 score.\n",
        "\n",
        "* `        best_name = name`\n",
        "  Records the winning experiment‚Äôs name.\n",
        "\n",
        "* `        best_trainer = trainer`\n",
        "  Stores the Trainer tied to the winning run.\n",
        "\n",
        "* `print(f\"Best run: {best_name} with F1={best_f1:.4f}\")`\n",
        "  Prints which run won and its F1 rounded to four decimals.\n",
        "\n",
        "* `# Save the best model for reuse`\n",
        "  Marks the section that persists the best model and tokenizer.\n",
        "\n",
        "* `save_dir = f\"./best_model_{best_name}\"`\n",
        "  Builds a folder path named after the best run.\n",
        "\n",
        "* `best_trainer.save_model(save_dir)`\n",
        "  Saves model weights and config to that folder.\n",
        "\n",
        "* `tokenizer.save_pretrained(save_dir)`\n",
        "  Saves the tokenizer files to the same folder.\n",
        "\n",
        "* `# Simple inference helper`\n",
        "  Introduces a convenience function for making predictions later.\n",
        "\n",
        "* `def predict(texts, model_dir=save_dir):`\n",
        "  Starts a function that takes raw texts and an optional model path.\n",
        "\n",
        "* `    tok = AutoTokenizer.from_pretrained(model_dir)`\n",
        "  Loads the tokenizer from the saved folder.\n",
        "\n",
        "* `    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)`\n",
        "  Loads the saved classifier and moves it to CPU/GPU.\n",
        "\n",
        "* `    enc = tok(list(texts), padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)`\n",
        "  Tokenizes the input texts, pads and truncates to length 160, returns PyTorch tensors, and moves them to the device.\n",
        "\n",
        "* `    with torch.no_grad():`\n",
        "  Disables gradient tracking for faster, memory-light inference.\n",
        "\n",
        "* `        logits = mdl(**enc).logits`\n",
        "  Runs the model forward pass and grabs raw class scores.\n",
        "\n",
        "* `    pred = torch.argmax(logits, dim=-1).cpu().numpy()`\n",
        "  Converts logits to predicted class IDs and moves them to NumPy.\n",
        "\n",
        "* `    prob = torch.softmax(logits, dim=-1).cpu().numpy()[:,1]`\n",
        "  Turns logits into probabilities and selects the column for class 1.\n",
        "\n",
        "* `    return pred, prob`\n",
        "  Returns predicted labels and their positive-class probabilities.\n",
        "\n",
        "* `# Demo predictions on a few samples`\n",
        "  Starts a small test to show the function in action.\n",
        "\n",
        "* `samples = [`\n",
        "  Opens a list of example texts.\n",
        "\n",
        "* `    \"I feel calm and in control today.\",`\n",
        "  Sample 1: likely not stressed.\n",
        "\n",
        "* `    \"My chest is tight and I cannot focus, I think I am very stressed.\",`\n",
        "  Sample 2: likely stressed.\n",
        "\n",
        "* `    \"Workload is heavy but manageable so far.\"`\n",
        "  Sample 3: borderline but manageable tone.\n",
        "\n",
        "* `]`\n",
        "  Closes the list of samples.\n",
        "\n",
        "* `pred, prob = predict(samples)`\n",
        "  Runs inference on the samples, returning labels and probabilities.\n",
        "\n",
        "* `for s, y, p in zip(samples, pred, prob):`\n",
        "  Iterates over each sample with its predicted label and probability.\n",
        "\n",
        "* `    lab = \"stressed(1)\" if y==1 else \"not-stressed(0)\"`\n",
        "  Converts numeric label to a readable string.\n",
        "\n",
        "* `    print(f\"[{lab}  p={p:.3f}]  {s}\")`\n",
        "  Prints the label, probability (to three decimals), and the original text.\n"
      ],
      "metadata": {
        "id": "SAA1gEu1CTdp"
      },
      "id": "SAA1gEu1CTdp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24E_Tay_hZ2O"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select the best run from 'results' dict above\n",
        "best_name, best_f1 = None, -1.0\n",
        "best_trainer = None\n",
        "for name,(metrics, trainer) in results.items():\n",
        "    if metrics['eval_f1'] > best_f1:\n",
        "        best_f1 = metrics['eval_f1']\n",
        "        best_name = name\n",
        "        best_trainer = trainer\n",
        "\n",
        "print(f\"Best run: {best_name} with F1={best_f1:.4f}\")\n",
        "\n",
        "# Save the best model for reuse\n",
        "save_dir = f\"./best_model_{best_name}\"\n",
        "best_trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# Simple inference helper\n",
        "def predict(texts, model_dir=save_dir):\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)\n",
        "    enc = tok(list(texts), padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "    pred = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "    prob = torch.softmax(logits, dim=-1).cpu().numpy()[:,1]\n",
        "    return pred, prob\n",
        "\n",
        "# Demo predictions on a few samples\n",
        "samples = [\n",
        "    \"I feel calm and in control today.\",\n",
        "    \"My chest is tight and I cannot focus, I think I am very stressed.\",\n",
        "    \"Workload is heavy but manageable so far.\"\n",
        "]\n",
        "pred, prob = predict(samples)\n",
        "for s, y, p in zip(samples, pred, prob):\n",
        "    lab = \"stressed(1)\" if y==1 else \"not‚Äëstressed(0)\"\n",
        "    print(f\"[{lab}  p={p:.3f}]  {s}\")\n"
      ],
      "id": "24E_Tay_hZ2O"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "591cdd45c7b74fa181821f9529944da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776524b1ce5c4c5bb65f8d8e65516273",
              "IPY_MODEL_3d089afa63744558bb3a6f7a1b876aef",
              "IPY_MODEL_e4a09e0a755241daad5e0330cfe68fd2"
            ],
            "layout": "IPY_MODEL_b81c22472d7940c798254fd44d9877b8"
          }
        },
        "776524b1ce5c4c5bb65f8d8e65516273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da86772c65244f09c694822bd730ce2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1cd05c5690a743bbb2472e7b3d8a91c5",
            "value": "config.json:‚Äá100%"
          }
        },
        "3d089afa63744558bb3a6f7a1b876aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07464960b8645bbaca506d2ef31bace",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fde31686a35414f962235ea930bdccb",
            "value": 385
          }
        },
        "e4a09e0a755241daad5e0330cfe68fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b95ecc756ea41f29095ab7890ab856c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5a1b98fe2c514b45a8153a30ba29225b",
            "value": "‚Äá385/385‚Äá[00:00&lt;00:00,‚Äá33.1kB/s]"
          }
        },
        "b81c22472d7940c798254fd44d9877b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da86772c65244f09c694822bd730ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd05c5690a743bbb2472e7b3d8a91c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b07464960b8645bbaca506d2ef31bace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fde31686a35414f962235ea930bdccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b95ecc756ea41f29095ab7890ab856c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1b98fe2c514b45a8153a30ba29225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7b191158e14b56b7fb18d781905220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86017ab938b4f46baa78b381b03320c",
              "IPY_MODEL_11930ebd9ce2434c8aaf21655a0f564a",
              "IPY_MODEL_e217ae1ba3974278934fbb75fae99d57"
            ],
            "layout": "IPY_MODEL_3c9e5917c4754acbbb908f3431191d45"
          }
        },
        "c86017ab938b4f46baa78b381b03320c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6926731b6e4c06a63e5a2ef414f6a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_35c4939c98a141cdaecbbd978211e48d",
            "value": "vocab.txt:‚Äá"
          }
        },
        "11930ebd9ce2434c8aaf21655a0f564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd174a933954b4fab9f1640ad491973",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ade9e93734a1456797e0340e38182c04",
            "value": 1
          }
        },
        "e217ae1ba3974278934fbb75fae99d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b176f12a3d42139088e6f4dd3f2d12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_08e6b823fa1042c9892bc49c949a2857",
            "value": "‚Äá213k/?‚Äá[00:00&lt;00:00,‚Äá7.07MB/s]"
          }
        },
        "3c9e5917c4754acbbb908f3431191d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6926731b6e4c06a63e5a2ef414f6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c4939c98a141cdaecbbd978211e48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddd174a933954b4fab9f1640ad491973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ade9e93734a1456797e0340e38182c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74b176f12a3d42139088e6f4dd3f2d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e6b823fa1042c9892bc49c949a2857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}