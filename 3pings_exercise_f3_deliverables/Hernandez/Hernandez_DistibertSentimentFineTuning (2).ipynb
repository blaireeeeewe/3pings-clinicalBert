{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwoPghthZ2K"
      },
      "source": [
        "# 0) Setup (libraries and reproducibility)"
      ],
      "id": "lOwoPghthZ2K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Import and Environment Setup ---\n",
        "\n",
        "import os\n",
        "\n",
        "- manages system paths, folders, and environment variables to handle files and directories efficiently during the execution of the notebook.\n",
        "\n",
        "import math\n",
        "\n",
        "- includes mathematical tools and formulas that can assist in calculations such as learning rate adjustments or numeric transformations during model training.\n",
        "\n",
        "import random\n",
        "\n",
        "- controls and initializes random number generation, ensuring that every run of the model produces consistent outcomes for reproducibility.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "- provides extensive support for numerical data handling, offering fast and flexible operations on arrays and matrices used throughout the data preparation process.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "- allows for structured data loading and manipulation, making it easier to explore, clean, and organize datasets, especially when working with CSV files.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "- gives a cleaner and more reliable way to manage file and directory paths across different operating systems.\n",
        "\n",
        "--- Core Framework Imports ---\n",
        "\n",
        "import torch\n",
        "\n",
        "- provides the base framework for tensor manipulation and GPU acceleration, enabling efficient computation for training and evaluating deep learning models.\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "- transforms pandas DataFrames into optimized dataset objects that integrate smoothly with the Hugging Face Transformers library for preprocessing and training.\n",
        "\n",
        "from transformers import (\n",
        "AutoTokenizer,\n",
        "\n",
        "- automatically selects and loads the appropriate tokenizer for a specific pre-trained model to ensure consistent tokenization.\n",
        "AutoModelForSequenceClassification,\n",
        "\n",
        "- initializes a pre-trained Transformer model with an added classification head, suitable for tasks like sentiment analysis or text categorization.\n",
        "TrainingArguments,\n",
        "\n",
        "- specifies and stores key hyperparameters such as the number of epochs, batch size, and evaluation frequency for the model training process.\n",
        "Trainer\n",
        "\n",
        "- streamlines the entire fine-tuning procedure, managing training, evaluation, logging, and checkpoint saving without requiring manual loop implementation.\n",
        ")\n",
        "\n",
        "--- Evaluation Metric Imports ---\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "- brings in performance evaluation tools that calculate key metrics such as accuracy, precision, recall, and F1-score to assess the model‚Äôs prediction quality.\n",
        "\n",
        "--- Reproducibility Configuration ---\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "- defines a fixed seed number to guarantee that all random processes across libraries yield consistent results.\n",
        "random.seed(SEED)\n",
        "\n",
        "- ensures that Python‚Äôs random number operations remain stable and predictable in every run.\n",
        "np.random.seed(SEED)\n",
        "\n",
        "- controls NumPy‚Äôs internal random processes to maintain the same shuffling or sampling patterns across executions.\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "- fixes PyTorch‚Äôs randomization for consistent model weight initialization and data handling.\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "- applies the same reproducibility rule across all available GPUs to maintain uniform outcomes even in multi-GPU training setups.\n",
        "\n",
        "--- Device Detection ---\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "- determines whether a GPU is available for acceleration and defaults to CPU if not, ensuring compatibility in any environment.\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "- prints out the current hardware in use to confirm that GPU acceleration is properly detected and active."
      ],
      "metadata": {
        "id": "lXM6q7RwB9PV"
      },
      "id": "lXM6q7RwB9PV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z1V0utC5hZ2L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1V0utC5hZ2L",
        "outputId": "d897b0e2-9a42-49c7-e3f4-fa11ee3b420b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Every import has an explanatory comment.\n",
        "import os                         # file paths and environment checks\n",
        "import math                       # math helpers (may be useful for schedules)\n",
        "import random                     # Python's RNG for reproducibility\n",
        "import numpy as np                # numerical arrays and metrics support\n",
        "import pandas as pd               # data loading and manipulation\n",
        "from pathlib import Path          # convenient and robust path handling\n",
        "\n",
        "# Hugging Face / PyTorch stack (for transformer fine‚Äëtuning)\n",
        "import torch                      # tensor and GPU utilities\n",
        "from datasets import Dataset      # lightweight dataset wrapper around pandas\n",
        "from transformers import (       # core HF components for tokenization and training\n",
        "    AutoTokenizer,               # auto‚Äëloads the right tokenizer for a given model checkpoint\n",
        "    AutoModelForSequenceClassification,  # classification head on top of a transformer\n",
        "    TrainingArguments,           # training hyperparameters container\n",
        "    Trainer                      # training loop helper (handles eval and logging)\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Make runs reproducible (seed Python, NumPy, and PyTorch)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Detect device once and print for visibility\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")  # shows 'cuda' when a GPU is available in Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ3rjAL2hZ2L"
      },
      "source": [
        "## 1) Load Dataset"
      ],
      "id": "wQ3rjAL2hZ2L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Load Dataset (Upload version, auto-encodes text labels) ---\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "- imports the pandas library, which is essential for reading, organizing, and analyzing CSV data within Python.\n",
        "\n",
        "#from pathlib import Path\n",
        "\n",
        "- provides a structured and cross-platform way to handle file paths, making directory navigation and file references more reliable.\n",
        "\n",
        "#from google.colab import files\n",
        "\n",
        "- activates Google Colab‚Äôs file upload feature, allowing users to upload local datasets directly into the runtime environment.\n",
        "\n",
        "#print(\"üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\")\n",
        "\n",
        "- displays a clear message prompting the user to upload a dataset file in CSV format for processing.\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        " -opens a file selection dialog so that the user can choose and upload the desired dataset from their computer.\n",
        "\n",
        "#filename = list(uploaded.keys())[0]\n",
        "\n",
        "- extracts the name of the uploaded file from the dictionary of uploaded files.\n",
        "\n",
        "#csv_path = Path(f\"/content/{filename}\")\n",
        "\n",
        "- constructs a full, system-compatible file path pointing to the uploaded dataset within the Colab working directory.\n",
        "\n",
        "#print(f\"‚úÖ File uploaded successfully: {csv_path}\")\n",
        "\n",
        "- provides feedback confirming that the file upload was successful and shows where the file was saved.\n",
        "\n",
        "#df = pd.read_csv(csv_path)\n",
        "\n",
        "- loads the uploaded CSV file into a pandas DataFrame, preparing it for inspection and processing.\n",
        "\n",
        "# --- Validate columns ---\n",
        "\n",
        "#expected_cols = {'statement', 'status'}\n",
        "\n",
        "- defines the columns that must exist in the dataset to ensure it matches the expected structure for further steps.\n",
        "\n",
        "#assert expected_cols.issubset(df.columns), f\"‚ùå Missing required columns: {expected_cols - set(df.columns)}\"\n",
        "\n",
        "- verifies that all required columns are present in the dataset; if not, the code stops and reports which ones are missing.\n",
        "\n",
        "# --- Clean ---\n",
        "\n",
        "#df = df.dropna(subset=['statement', 'status']).copy()\n",
        "\n",
        "- deletes any rows containing missing values in the ‚Äòstatement‚Äô or ‚Äòstatus‚Äô columns to maintain data consistency.\n",
        "\n",
        "#df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "- converts all entries in the ‚Äòstatement‚Äô column into string type to prevent formatting or type errors later in processing.\n",
        "\n",
        "# --- Encode text labels into integers ---\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "- brings in a class from scikit-learn that converts categorical text labels into numerical form for model compatibility.\n",
        "\n",
        "#le = LabelEncoder()\n",
        "\n",
        "- initializes the LabelEncoder, preparing it to map text categories into numeric codes.\n",
        "\n",
        "#df['status_encoded'] = le.fit_transform(df['status'])\n",
        "\n",
        "- fits the encoder to the ‚Äòstatus‚Äô column and generates a new column containing the corresponding numeric label values.\n",
        "\n",
        "#print(\"üî§ Label encoding map:\")\n",
        "\n",
        "- prints a section heading to indicate that the label-to-code mapping will be shown next.\n",
        "\n",
        "#for label, code in zip(le.classes_, range(len(le.classes_))):\n",
        "\n",
        "- loops through each label and its encoded numeric representation to display the mapping relationship.\n",
        "  print(f\"  {code} ‚Üí {label}\")  - prints each numeric code and its associated label for verification.\n",
        "\n",
        "#df['status'] = df['status_encoded']\n",
        "\n",
        "- replaces the original ‚Äòstatus‚Äô column‚Äôs text labels with their corresponding numeric values.\n",
        "\n",
        "#df.drop(columns=['status_encoded'], inplace=True)\n",
        "\n",
        "- deletes the temporary ‚Äòstatus_encoded‚Äô column since the main ‚Äòstatus‚Äô column now contains the encoded values.\n",
        "\n",
        "#print(\"\\n‚úÖ Dataset loaded and label-encoded successfully!\")\n",
        "\n",
        "- outputs a confirmation message indicating that the dataset has been fully cleaned and encoded without errors.\n",
        "\n",
        "#print(df['status'].value_counts(dropna=False))\n",
        "\n",
        "- displays a frequency count of each encoded label, helping verify that the encoding process was applied correctly.\n",
        "\n",
        "#df.head(3)\n",
        "\n",
        "- shows the first three rows of the cleaned and processed dataset to confirm that all transformations were applied successfully.\n"
      ],
      "metadata": {
        "id": "UKbddZcLB-e5"
      },
      "id": "UKbddZcLB-e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CMBpEom1hZ2M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "CMBpEom1hZ2M",
        "outputId": "24b01f44-44e6-4c5a-d7dd-c3e3771783ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ca5694a-4db0-4c95-ae15-f73a79d1e54a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ca5694a-4db0-4c95-ae15-f73a79d1e54a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Combined Data.csv to Combined Data.csv\n",
            "‚úÖ File uploaded successfully: /content/Combined Data.csv\n",
            "üî§ Label encoding map:\n",
            "  0 ‚Üí Anxiety\n",
            "  1 ‚Üí Bipolar\n",
            "  2 ‚Üí Depression\n",
            "  3 ‚Üí Normal\n",
            "  4 ‚Üí Personality disorder\n",
            "  5 ‚Üí Stress\n",
            "  6 ‚Üí Suicidal\n",
            "\n",
            "‚úÖ Dataset loaded and label-encoded successfully!\n",
            "status\n",
            "3    16343\n",
            "2    15404\n",
            "6    10652\n",
            "0     3841\n",
            "1     2777\n",
            "5     2587\n",
            "4     1077\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                          statement  status\n",
              "0           0                                         oh my gosh       0\n",
              "1           1  trouble sleeping, confused mind, restless hear...       0\n",
              "2           2  All wrong, back off dear, forward doubt. Stay ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39931c0e-fa48-4c02-b6c7-a2e60a43cd0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39931c0e-fa48-4c02-b6c7-a2e60a43cd0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39931c0e-fa48-4c02-b6c7-a2e60a43cd0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39931c0e-fa48-4c02-b6c7-a2e60a43cd0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66c1f7bd-b706-4ccb-9276-78bafc9f0e65\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66c1f7bd-b706-4ccb-9276-78bafc9f0e65')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66c1f7bd-b706-4ccb-9276-78bafc9f0e65 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52681,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15235,\n        \"min\": 0,\n        \"max\": 53042,\n        \"num_unique_values\": 52681,\n        \"samples\": [\n          3008,\n          44705,\n          50186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51073,\n        \"samples\": [\n          \"he's been a chain smoker for 30 years.\",\n          \"Dependence on therapist I attend IOP groups and individual therapy sessions at the same place, my therapist who I have worked with on and off for a year and a couple months just told me today that she is leaving soon and I am heartbroken. I love my therapist and I don't know how I am going to keep progressing without her. There will be a replacement for her but idk what to do, I don't want a different therapist. :(\",\n          \"These feelings constantly come back. Someone from my past that hurt me came back a month ago and once again disrespected me and i just feel like shit. Idk why these feelings keep resurfacing but it just hurts. I do not want to be over dramatic but Its hurts when you were nothing but loving/kind to someone and they disrespect you. I just hate feeling like this, feeling like i cannot trust anyone or that no one would ever truly love me unless i have something to offer. I am always worried about my looks and its just making me depressed. I really do not feel like i fit in with the world I am just here. Idk what my next step should be to get help but I am really going through it. (Yes I am in therapy) but how do i help myself ? I have been depressed/anxious for years and most day i do not even leave my house. But nobody around me seems to care and honestly I am tired of feeling this way. But at the same time i do not want to give up on myself bc i feel like I am here to be somebody great. I am just trying to find my way right now. It keeps coming back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# --- Load Dataset (Upload version, auto-encodes text labels) ---\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Automatically pick the first uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "csv_path = Path(f\"/content/{filename}\")\n",
        "\n",
        "print(f\"‚úÖ File uploaded successfully: {csv_path}\")\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# --- Validate columns ---\n",
        "expected_cols = {'statement', 'status'}\n",
        "assert expected_cols.issubset(df.columns), f\"‚ùå Missing required columns: {expected_cols - set(df.columns)}\"\n",
        "\n",
        "# --- Clean ---\n",
        "df = df.dropna(subset=['statement', 'status']).copy()\n",
        "df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "# --- Encode text labels into integers ---\n",
        "# This maps each unique label (like 'Anxiety', 'Stress', etc.) to a numeric ID\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['status_encoded'] = le.fit_transform(df['status'])\n",
        "\n",
        "# Optional: print mapping for your reference\n",
        "print(\"üî§ Label encoding map:\")\n",
        "for label, code in zip(le.classes_, range(len(le.classes_))):\n",
        "    print(f\"  {code} ‚Üí {label}\")\n",
        "\n",
        "# Replace 'status' with the encoded version\n",
        "df['status'] = df['status_encoded']\n",
        "df.drop(columns=['status_encoded'], inplace=True)\n",
        "\n",
        "print(\"\\n‚úÖ Dataset loaded and label-encoded successfully!\")\n",
        "print(df['status'].value_counts(dropna=False))\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymAj-xUdhZ2M"
      },
      "source": [
        "## 2) Baseline Models (TF‚ÄëIDF + Linear)"
      ],
      "id": "ymAj-xUdhZ2M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Baseline Models (TF-IDF + Linear, supports multi-class) ---\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "‚Äì divides the dataset into separate subsets for training and validation purposes\n",
        "\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "‚Äì transforms raw text into numerical representations using the TF-IDF method\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "‚Äì loads the logistic regression algorithm used for text classification\n",
        "\n",
        "#from sklearn.svm import LinearSVC\n",
        "‚Äì loads the linear support vector machine classifier for categorizing text\n",
        "\n",
        "#from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "‚Äì provides built-in functions to measure model performance using common evaluation metrics\n",
        "\n",
        "#import numpy as np\n",
        "‚Äì supports efficient numerical calculations and operations on arrays\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_test_split(\n",
        "\n",
        "df['statement'].values,\n",
        "df['status'].values,\n",
        "test_size=0.2,\n",
        "random_state=42,\n",
        "stratify=df['status'].values\n",
        "\n",
        "#)\n",
        "‚Äì separates the dataset into 80% training and 20% validation samples while maintaining balanced class distribution\n",
        "\n",
        "#tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=40000)\n",
        "‚Äì builds a TF-IDF model that captures single words and two-word phrases, ignoring rare terms and limiting total features to 40,000\n",
        "\n",
        "#Xtr = tfidf.fit_transform(X_train)\n",
        "‚Äì learns vocabulary patterns from the training set and converts text into TF-IDF feature vectors\n",
        "\n",
        "#Xva = tfidf.transform(X_val)\n",
        "‚Äì applies the trained TF-IDF transformation to the validation set without retraining\n",
        "\n",
        "#num_classes = len(np.unique(y_train))\n",
        "‚Äì determines how many distinct categories or labels exist in the dataset\n",
        "\n",
        "#avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "‚Äì automatically chooses whether to use binary or weighted averaging based on the number of classes\n",
        "\n",
        "#print(f\"Detected {num_classes} classes ‚Üí using average='{avg_type}' for metrics.\\n\")\n",
        "‚Äì outputs the number of identified classes and indicates which averaging method will be applied for evaluation\n",
        "\n",
        "--- Baseline 1: Logistic Regression ---\n",
        "\n",
        "#logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "‚Äì creates a logistic regression model configured to balance uneven class frequencies and allow more training iterations\n",
        "\n",
        "#logreg.fit(Xtr, y_train)\n",
        "‚Äì trains the logistic regression classifier using the prepared TF-IDF features and corresponding labels\n",
        "\n",
        "#pred_lr = logreg.predict(Xva)\n",
        "‚Äì produces predictions on unseen validation data using the trained logistic regression model\n",
        "\n",
        "#p, r, f, _ = precision_recall_fscore_support(y_val, pred_lr, average=avg_type)\n",
        "‚Äì calculates the precision, recall, and F1-score metrics according to the averaging method chosen\n",
        "\n",
        "#acc = accuracy_score(y_val, pred_lr)\n",
        "‚Äì evaluates how often the logistic regression model predicted the correct label\n",
        "\n",
        "#print(f\"[Baseline-LR] Acc={acc:.3f} P={p:.3f} R={r:.3f} F1={f:.3f}\")\n",
        "‚Äì prints the accuracy, precision, recall, and F1-score results for the logistic regression model\n",
        "\n",
        "--- Baseline 2: Linear SVM ---\n",
        "\n",
        "#svm = LinearSVC(class_weight=\"balanced\")\n",
        "‚Äì initializes a linear SVM model that compensates for class imbalance during training\n",
        "\n",
        "#svm.fit(Xtr, y_train)\n",
        "‚Äì fits the SVM classifier using the TF-IDF features from the training data\n",
        "\n",
        "#pred_svm = svm.predict(Xva)\n",
        "‚Äì predicts the validation set labels using the trained SVM model\n",
        "\n",
        "#p, r, f, _ = precision_recall_fscore_support(y_val, pred_svm, average=avg_type)\n",
        "‚Äì computes precision, recall, and F1-score for the SVM‚Äôs predictions based on the selected averaging mode\n",
        "\n",
        "#acc = accuracy_score(y_val, pred_svm)\n",
        "‚Äì determines the SVM model‚Äôs accuracy across all validation examples\n",
        "\n",
        "#print(f\"[Baseline-SVM] Acc={acc:.3f} P={p:.3f} R={r:.3f} F1={f:.3f}\")\n",
        "‚Äì displays the accuracy, precision, recall, and F1-score achieved by the SVM baseline model\n"
      ],
      "metadata": {
        "id": "xNWyoNu3CBhm"
      },
      "id": "xNWyoNu3CBhm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k4IjGl_JhZ2M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4IjGl_JhZ2M",
        "outputId": "ae4c8e5c-bb92-4e2f-b370-9c956c94ba2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 7 classes ‚Üí using average='weighted' for metrics.\n",
            "\n",
            "[Baseline-LR] Acc=0.778  P=0.787  R=0.778  F1=0.777\n",
            "[Baseline-SVM] Acc=0.782  P=0.779  R=0.782  F1=0.780\n"
          ]
        }
      ],
      "source": [
        "# --- Baseline Models (TF-IDF + Linear, supports multi-class) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Train/validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['statement'].values,\n",
        "    df['status'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['status'].values\n",
        ")\n",
        "\n",
        "# Convert raw text into TF-IDF features\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=40000)\n",
        "Xtr = tfidf.fit_transform(X_train)\n",
        "Xva = tfidf.transform(X_val)\n",
        "\n",
        "# Detect if this is binary or multiclass\n",
        "num_classes = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "print(f\"Detected {num_classes} classes ‚Üí using average='{avg_type}' for metrics.\\n\")\n",
        "\n",
        "# --- Baseline 1: Logistic Regression ---\n",
        "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "logreg.fit(Xtr, y_train)\n",
        "pred_lr = logreg.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_lr, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_lr)\n",
        "print(f\"[Baseline-LR] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n",
        "\n",
        "# --- Baseline 2: Linear SVM ---\n",
        "svm = LinearSVC(class_weight=\"balanced\")\n",
        "svm.fit(Xtr, y_train)\n",
        "pred_svm = svm.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_svm, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_svm)\n",
        "print(f\"[Baseline-SVM] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xic-iii4hZ2N"
      },
      "source": [
        "## 3) Pre‚ÄëTrained Models (Tokenization and Dataset Prep)"
      ],
      "id": "xic-iii4hZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Transformer Backbone and Tokenization Setup ---\n",
        "\n",
        "#CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "‚Äì specifies the pretrained ClinicalBERT model, which is optimized for understanding clinical and medical language\n",
        "\n",
        "#DISTIL_BERT = \"distilbert-base-uncased\"\n",
        "‚Äì specifies the lightweight DistilBERT model designed for faster and more efficient fine-tuning compared to larger transformer models\n",
        "\n",
        "#BACKBONE = CLINICAL_BERT\n",
        "‚Äì assigns ClinicalBERT as the main transformer model to be used for this experiment\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "‚Äì loads the tokenizer associated with the selected transformer model to ensure text encoding consistency\n",
        "\n",
        "#def tokenize_texts(texts, max_length=128):\n",
        "‚Äì defines a reusable function that converts a collection of raw text samples into tokenized sequences suitable for the model\n",
        "    #return tokenizer(\n",
        "      list(texts),‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚Äì transforms the input texts into a list format\n",
        "      padding=True,‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚Äì automatically pads all sequences to the same length\n",
        "      truncation=True,‚ÄÉ‚ÄÉ‚ÄÉ‚Äì shortens sequences that exceed the specified maximum length\n",
        "      max_length=max_length,‚ÄÉ‚Äì defines the limit for each tokenized text sequence\n",
        "      return_tensors=\"pt\"‚ÄÉ‚ÄÉ‚Äì outputs data as PyTorch-compatible tensors\n",
        "    )\n",
        "‚Äì applies the tokenizer configuration to the texts and produces ready-to-use numerical tensors\n",
        "\n",
        "#train_enc = tokenize_texts(X_train)\n",
        "‚Äì processes and encodes all training sentences into model-readable token IDs and attention masks\n",
        "\n",
        "#val_enc = tokenize_texts(X_val)\n",
        "‚Äì applies the same tokenization steps to the validation set to maintain consistency with the training data\n",
        "\n",
        "#train_ds = Dataset.from_dict({\n",
        "\n",
        "\"input_ids\": train_enc[\"input_ids\"],\n",
        "\"attention_mask\": train_enc[\"attention_mask\"],\n",
        "\"labels\": torch.tensor(y_train)\n",
        "\n",
        "#})\n",
        "‚Äì builds a structured Hugging Face dataset for the training portion, including encoded inputs and their respective labels\n",
        "\n",
        "#val_ds = Dataset.from_dict({\n",
        "\n",
        "\"input_ids\": val_enc[\"input_ids\"],\n",
        "\"attention_mask\": val_enc[\"attention_mask\"],\n",
        "\"labels\": torch.tensor(y_val)\n",
        "\n",
        "#})\n",
        "‚Äì constructs a matching dataset object for the validation data with identical field structure\n",
        "\n",
        "#len(train_ds), len(val_ds)\n",
        "‚Äì verifies and displays how many records are contained within the training and validation datasets"
      ],
      "metadata": {
        "id": "SBeklvMECK6W"
      },
      "id": "SBeklvMECK6W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CJsRDxIlhZ2N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CJsRDxIlhZ2N",
        "outputId": "dc4a0101-d7c8-4d91-a433-531b116fdb7b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2833020375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Tokenize train/validation splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mval_enc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtokenize_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Choose your checkpoints.\n",
        "# We include ClinicalBERT (for clinical text) and DistilBERT (fast baseline).\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "# Pick one as the default backbone for experiments below.\n",
        "BACKBONE = CLINICAL_BERT\n",
        "\n",
        "# Initialize tokenizer for the chosen backbone\n",
        "tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "\n",
        "# Helper to tokenize a pandas series with per-line comments\n",
        "def tokenize_texts(texts, max_length=128):\n",
        "    # Apply the tokenizer: returns dict with input_ids and attention_mask\n",
        "    return tokenizer(\n",
        "        list(texts),                 # a Python list of strings\n",
        "        padding=True,                # pad to the longest in the batch\n",
        "        truncation=True,             # cut off text exceeding max_length\n",
        "        max_length=max_length,       # cap sequence length\n",
        "        return_tensors=\"pt\"          # return PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize train/validation splits\n",
        "train_enc = tokenize_texts(X_train)\n",
        "val_enc   = tokenize_texts(X_val)\n",
        "\n",
        "# Wrap into HF Datasets with labels\n",
        "train_ds = Dataset.from_dict({\n",
        "    \"input_ids\": train_enc[\"input_ids\"],\n",
        "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_train)\n",
        "})\n",
        "val_ds = Dataset.from_dict({\n",
        "    \"input_ids\": val_enc[\"input_ids\"],\n",
        "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_val)\n",
        "})\n",
        "\n",
        "len(train_ds), len(val_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A6SNywxhZ2N"
      },
      "source": [
        "## 4) Training of Data (Trainer utilities and metrics)"
      ],
      "id": "2A6SNywxhZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric function for the Trainer: computes Accuracy, Precision, Recall, F1\n",
        "\n",
        "‚Äì defines a function used by the Trainer to evaluate model performance through key metrics such as accuracy, precision, recall, and F1-score\n",
        "\n",
        "eval_pred is a tuple of (logits, labels)\n",
        "\n",
        "‚Äì indicates that the function receives two components: the model‚Äôs raw predictions (logits) and the actual ground-truth labels (labels)\n",
        "\n",
        "logits, labels = eval_pred\n",
        "\n",
        "‚Äì unpacks the tuple into separate variables representing predicted outputs and true labels\n",
        "\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "‚Äì selects the class with the highest predicted probability for each input sample\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "\n",
        "‚Äì calculates precision, recall, and F1-score across all predictions using a binary averaging scheme\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "\n",
        "‚Äì measures the overall proportion of correct predictions made by the model\n",
        "\n",
        "return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "‚Äì returns the computed metrics in a dictionary format for reporting and monitoring during training\n",
        "\n",
        "Optional: class weights for imbalanced datasets\n",
        "\n",
        "‚Äì introduces a section that handles uneven class distributions by adjusting their relative training importance\n",
        "\n",
        "Compute weights inversely proportional to class frequencies\n",
        "\n",
        "‚Äì derives weight values where less frequent classes receive higher importance in the loss function\n",
        "\n",
        "pos = (y_train == 1).sum()\n",
        "\n",
        "‚Äì counts how many samples belong to the positive class in the training data\n",
        "\n",
        "neg = (y_train == 0).sum()\n",
        "\n",
        "‚Äì counts how many samples belong to the negative class in the training data\n",
        "\n",
        "w_pos = neg / max(pos, 1) # weight for positive class\n",
        "\n",
        "‚Äì assigns a weight to the positive class that is inversely proportional to its frequency to counter class imbalance\n",
        "\n",
        "w_neg = 1.0 # keep negative as baseline\n",
        "\n",
        "‚Äì keeps the negative class weight as the standard reference (baseline weight of 1.0)\n",
        "\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float).to(device)\n",
        "\n",
        "‚Äì converts both class weights into a PyTorch tensor and transfers them to the active computing device (CPU or GPU)\n",
        "\n",
        "#print(f\"Class weights (neg, pos): {class_weights.tolist()}\")\n",
        "‚Äì outputs the computed class weights for verification and transparency\n",
        "\n",
        "Custom Trainer that injects weighted loss\n",
        "\n",
        "‚Äì defines a subclass of the Hugging Face Trainer that incorporates class-weighted loss during backpropagation\n",
        "\n",
        "#from torch.nn import CrossEntropyLoss\n",
        "‚Äì imports the cross-entropy loss function, which is standard for classification tasks\n",
        "\n",
        "#class WeightedTrainer(Trainer):\n",
        "‚Äì creates a custom training class that inherits properties and methods from the base Trainer class\n",
        "\n",
        "#def compute_loss(self, model, inputs, return_outputs=False):\n",
        "‚Äì overrides the default loss computation method to integrate the weighted loss function\n",
        "\n",
        "#labels = inputs.get(\"labels\")\n",
        "‚Äì extracts the true labels from the batch input dictionary\n",
        "\n",
        "#outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "‚Äì performs a forward pass through the model while excluding the labels from the input arguments\n",
        "\n",
        "#logits = outputs.get(\"logits\")\n",
        "‚Äì retrieves the predicted logits from the model output\n",
        "\n",
        "#loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "‚Äì initializes a cross-entropy loss function that applies the predefined class weights\n",
        "\n",
        "#loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "‚Äì computes the final weighted loss by comparing predicted logits and true labels across all samples\n",
        "\n",
        "#return (loss, outputs) if return_outputs else loss\n",
        "‚Äì returns both loss and model outputs (if requested), otherwise only the computed loss for training"
      ],
      "metadata": {
        "id": "rUDnzZ1_CMLD"
      },
      "id": "rUDnzZ1_CMLD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7qBrdq-yIspU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qBrdq-yIspU",
        "outputId": "5b4fd05e-9bc8-4449-959a-5218f2af3143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data split complete:\n",
            "Train size: 42144 | Validation size: 10537\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your cleaned & encoded dataframe is called df\n",
        "# with columns: 'statement' (text) and 'status' (numeric label)\n",
        "X = df['statement']\n",
        "y = df['status']\n",
        "\n",
        "# Split into 80% train, 20% validation (you can adjust ratio)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data split complete:\")\n",
        "print(f\"Train size: {len(X_train)} | Validation size: {len(X_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_4oBKl6hZ2N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_4oBKl6hZ2N",
        "outputId": "b2c731cf-0203-4be1-f5b5-9ec68c91006d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights (neg, pos): [1.0, 1.3836109638214111]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Metric function for the Trainer: computes Accuracy, Precision, Recall, F1\n",
        "def compute_metrics(eval_pred):\n",
        "    # eval_pred is a tuple of (logits, labels)\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Optional: class weights for imbalanced datasets\n",
        "# Compute weights inversely proportional to class frequencies\n",
        "pos = (y_train == 1).sum()\n",
        "neg = (y_train == 0).sum()\n",
        "w_pos = neg / max(pos, 1)   # weight for positive class\n",
        "w_neg = 1.0                 # keep negative as baseline\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float).to(device)\n",
        "print(f\"Class weights (neg, pos): {class_weights.tolist()}\" )\n",
        "\n",
        "# Custom Trainer that injects weighted loss\n",
        "from torch.nn import CrossEntropyLoss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvrjk1PlhZ2N"
      },
      "source": [
        "## 5) Fine‚Äëtuning (Three Experiments)"
      ],
      "id": "Dvrjk1PlhZ2N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* `# --- 5) Fine-tuning (Three Experiments) [version-compatible] ---`\n",
        "  ‚Äì runs three fine-tuning trials with settings that work across different Transformers versions.\n",
        "\n",
        "* `# 1) Metrics: binary vs multiclass handled automatically`\n",
        "  ‚Äì chooses the proper metric averaging based on whether the task is binary or multi-class.\n",
        "\n",
        "* `# 2) Class weights for imbalanced data (size == num_labels)`\n",
        "  ‚Äì builds a weight vector per class to address label imbalance.\n",
        "\n",
        "* `# Heuristic: inverse-frequency scaled to max=1.0 (safe for CE)`\n",
        "  ‚Äì uses inverse class frequency, normalized so the largest weight equals 1.0, suitable for cross-entropy.\n",
        "\n",
        "* `# 3) Helper: tokenizer already defined above. Re-tokenize per max_length`\n",
        "  ‚Äì re-encodes text using the existing tokenizer, honoring the given maximum sequence length.\n",
        "\n",
        "* `# 4) Version-compatible TrainingArguments factory`\n",
        "  ‚Äì creates TrainingArguments that adapt to both newer and older library versions.\n",
        "\n",
        "* `# Try modern signature first`\n",
        "  ‚Äì attempts to instantiate with contemporary argument names and options.\n",
        "\n",
        "* `# Fallback for older transformers (no evaluation_strategy/save_strategy)`\n",
        "  ‚Äì switches to legacy parameters when the newer ones aren‚Äôt supported.\n",
        "\n",
        "* `# do_eval=True  # legacy way to enable evaluation`\n",
        "  ‚Äì turns on evaluation using the older configuration style.\n",
        "\n",
        "* `# save_steps=500  # periodic saving`\n",
        "  ‚Äì saves checkpoints at fixed step intervals.\n",
        "\n",
        "* `# Re-tokenize for this max_length`\n",
        "  ‚Äì encodes the train/validation texts again for the chosen sequence length.\n",
        "\n",
        "* `# Load backbone with correct num_labels`\n",
        "  ‚Äì initializes the model with the appropriate number of output classes.\n",
        "\n",
        "* `# --- Define backbones (already set earlier) ---`\n",
        "  ‚Äì lists the model names used in the experiments.\n",
        "\n",
        "* `# Exp-A: ClinicalBERT, conservative LR, small batch`\n",
        "  ‚Äì first run: ClinicalBERT with a lower learning rate and batch size 16.\n",
        "\n",
        "* `# Exp-B: ClinicalBERT, slightly higher LR, more epochs`\n",
        "  ‚Äì second run: ClinicalBERT with a higher learning rate and an extra training epoch.\n",
        "\n",
        "* `# Exp-C: DistilBERT fast baseline`\n",
        "  ‚Äì third run: DistilBERT configured for a quicker baseline comparison.\n",
        "\n",
        "* `# Leaderboard`\n",
        "  ‚Äì prints a summary table ranking experiments by F1-score (with accuracy shown as well).\n"
      ],
      "metadata": {
        "id": "bYaD7RDrCPdp"
      },
      "id": "bYaD7RDrCPdp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LkYDOan1hZ2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ba6f60fe7cb44cd92d7c98cca0a6cc0",
            "48d0d13207dc4243985d103955ad4f10",
            "36d4db76c7de4e0f8b8e3daa4de17a5e",
            "0edae4f812a14e95bab49b89dc428c73",
            "1b64c260b8064a149c13e677aa7fc4ed",
            "9ae36ca4f029403ca1c3bc30f7d099a4",
            "e552a0be5c104eba9a8a7d018284ad67",
            "3e1c5662e8604f9f991e35aa20c36ccb",
            "ef285c23880749f2ab85297eb6f0a75b",
            "e7a8b577fb8a4081ae61fced53d895fa",
            "4f51d16be8d64181a4117074654c097d",
            "6096822f4acb41e2943d33b574e7f914",
            "3816d14891d44a5d916885ec5e6e6002",
            "125a63e81f114aac852cb6db07ad0c19",
            "754b162c62234982afe3261a2dd460bb",
            "ac85e4957b5f4e0997599d3409b819e9",
            "bf3058b5edbe412da6b19f82bf4f6287",
            "8ceff8b00eec4d7a97866cc31361f9e7",
            "ef5a75a8460549e4b3cf3852179673cd",
            "81c6f4d837824e7db4a0e98d20f42595",
            "97ec4a07e3644ca6b9d7edb01676068f",
            "abbcbec04a1f42f9a981020f9c03818c",
            "999794d9dc1f45579cd68b7448defe46",
            "cb899f7994c44e3ba8f5e502f2979d12",
            "7ab3e5fda5b14692aff869ec6bcaa7c7",
            "ccec06a293d14573be29ace5133709ba",
            "ac25cc9d9c4b48fe906110a088adc916",
            "93522690c527483986d1ce018f04f41b",
            "e9d18e9031ae48fd97234a20d42615ce",
            "ba037034a74841489175f491c76e9c7f",
            "15d8a61e45974dd9a9800e7c1b5b23b5",
            "db6cdf225abc4f489566b3ce46f5f7b8",
            "ffba3d41d2804daa8b10fe6bf9d9be5e",
            "eff2aa5df68d417eb1e1b63b025dd42f",
            "147cd739a7c54b53af129d7ed96401e0",
            "224b97ab877b4b3e9611c128d8aabc2f",
            "e3bc107e6b634be8b85d1337460c588f",
            "93401829fc4e4cbfaa170d013325a724",
            "d50950d22e7c45639459e5bd91998e35",
            "0a884bc575354b56b0e117e96b76bb0a",
            "cbaad6baed5f4ef89b300b5195c5eaab",
            "c7d17291b0fa49ecb3a4e8bbd0382bd4",
            "a29fcc61ae624f1a88a1e8d5b21c2f56",
            "b186f831705d4fbfbd5d1ec91d0176d5"
          ]
        },
        "id": "LkYDOan1hZ2O",
        "outputId": "4b1a4afa-d47e-448b-f05b-942dd4d2bd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Detected 7 classes ‚Üí metrics average='weighted'\n",
            "[Fine-tune] Class weights: [4.254474639892578, 5.886537551879883, 1.0609430074691772, 1.0, 15.16705322265625, 6.31594181060791, 1.5343269109725952]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba6f60fe7cb44cd92d7c98cca0a6cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6096822f4acb41e2943d33b574e7f914"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-1839706526.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Using legacy TrainingArguments fallback.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7902' max='7902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7902/7902 27:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.912600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.368300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.984600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.960300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.845400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.878500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.827600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.780500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.800800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.699700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.730300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.781700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.743100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.775100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.694700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.786600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.765500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.718000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.734300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.712400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.631300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.701100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.774800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.591500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.597100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.690800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.584400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.673500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.661500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.609700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.652300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.654400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.624900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.604700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.631000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.629500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.578800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.598500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.573400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.683800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.567900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.588700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.432500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.519400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.547000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.581500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.436500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.500500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.533800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.618100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.410800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.479200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.487800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.534300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.517500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.486400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.503500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.464700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.392000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.564500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.468600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.508800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.461100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.497600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.500400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.429400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.394200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.517800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.569800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.479000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.419000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.501000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.441400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.500600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.520800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.313400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.470200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.442800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.461900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.493500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.437300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.485100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.470400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.448500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.397400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.412500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.283800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.315500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.301000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.387400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.324300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.337800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.315400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.374300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.342400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.337000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.354300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.369500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.294000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.342300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.333400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.327800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.283300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.348400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.422800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.290900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.284000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.236300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.312300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.355700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.371500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.283800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.294400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.268500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.338700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.318100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.305100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.298600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.330800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.417700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.259600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.360700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.322000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.309400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.420800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.314700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='659' max='659' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [659/659 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> expA_clinicalbert_bs16_lr2e-5_ep3 results: {'eval_loss': 0.6153295040130615, 'eval_accuracy': 0.8131346683116637, 'eval_precision': 0.823821343602551, 'eval_recall': 0.8131346683116637, 'eval_f1': 0.8144655432016229, 'eval_runtime': 23.8221, 'eval_samples_per_second': 442.32, 'eval_steps_per_second': 27.663, 'epoch': 3.0}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-1839706526.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Using legacy TrainingArguments fallback.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10536' max='10536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10536/10536 41:57, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.611800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.390300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.185300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.121700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.999500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.918500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.831400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.761900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.856100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.803500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.776300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.793000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.695100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.703100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.752400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.805400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.579000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.827700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.724900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.741900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.661100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.625500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.755000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.687800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.700800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.661000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.647500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.638500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.664200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.648100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.646300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.663900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.623000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.639000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.745700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.560800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.474700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.527800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.414300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.482900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.521100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.518000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.542400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.444500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.499400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.554200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.548400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.560600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.475400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.409700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.513300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.413700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.552200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.504200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.503800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.416400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.471600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.452500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.552500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.438200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.478100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.475800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.565200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.495800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.366800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.448200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.415400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.470300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.484100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.459000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.472200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.460500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.488500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.465400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.385400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.502900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.306300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.305300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.386300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.343900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.314400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.300300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.371900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.369000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.298400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.309400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.296300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.312100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.285100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.305900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.389800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.333200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.234800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.213600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.302800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.406600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.353200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.259800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.314700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.242700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.289000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.355400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.309400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.239800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.262300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.308100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.345000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.274300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.368900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.201100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>0.192500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>0.214600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>0.222700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.168700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>0.175100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.209600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>0.163200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>0.199200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.158200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>0.178900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.194700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>0.212400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.166200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>0.133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>0.203600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>0.195000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.197500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>0.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.147400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>0.293600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.217900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9450</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.181300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9550</td>\n",
              "      <td>0.171100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.196400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9650</td>\n",
              "      <td>0.193800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.189900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9750</td>\n",
              "      <td>0.167700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.165600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9850</td>\n",
              "      <td>0.138000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9950</td>\n",
              "      <td>0.267100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.136800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10050</td>\n",
              "      <td>0.201800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10150</td>\n",
              "      <td>0.200300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.162000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10250</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10350</td>\n",
              "      <td>0.197200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.223800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10450</td>\n",
              "      <td>0.164400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.230600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='659' max='659' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [659/659 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> expB_clinicalbert_bs16_lr5e-5_ep4 results: {'eval_loss': 0.7305412292480469, 'eval_accuracy': 0.8230046502799658, 'eval_precision': 0.8262782454669647, 'eval_recall': 0.8230046502799658, 'eval_f1': 0.8236334762335898, 'eval_runtime': 23.9388, 'eval_samples_per_second': 440.163, 'eval_steps_per_second': 27.528, 'epoch': 4.0}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999794d9dc1f45579cd68b7448defe46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eff2aa5df68d417eb1e1b63b025dd42f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-1839706526.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Using legacy TrainingArguments fallback.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3951' max='3951' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3951/3951 11:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.606800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.549600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.479800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.327400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.313500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.101600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.106500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.983800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.955400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.927500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.911900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.928400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.887400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.876400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.821900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.826600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.867200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.808500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.771000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.832100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.761300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.717700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.730400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.813700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.794000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.724400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.697100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.658400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.701200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.692200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.703400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.674900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.715500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.688600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.680700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.639700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.717200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.739700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.682700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.676100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.722300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.625700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.618500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.618300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.538100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.526500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.599700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.597900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.563900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.575100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.520800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.576100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.505600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.556000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.495700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.498900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.610100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.501200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.554700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.668900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.576400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.604200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.514800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> expC_distilbert_bs32_lr3e-5_ep3 results: {'eval_loss': 0.6835536956787109, 'eval_accuracy': 0.7560975609756098, 'eval_precision': 0.7817777008346605, 'eval_recall': 0.7560975609756098, 'eval_f1': 0.7590166377377228, 'eval_runtime': 12.8813, 'eval_samples_per_second': 818.006, 'eval_steps_per_second': 25.618, 'epoch': 3.0}\n",
            "\n",
            "\n",
            "Leaderboard (by F1):\n",
            "expB_clinicalbert_bs16_lr5e-5_ep4    F1=0.8236  Acc=0.8230\n",
            "expA_clinicalbert_bs16_lr2e-5_ep3    F1=0.8145  Acc=0.8131\n",
            "expC_distilbert_bs32_lr3e-5_ep3      F1=0.7590  Acc=0.7561\n"
          ]
        }
      ],
      "source": [
        "# --- 5) Fine-tuning (Three Experiments) [version-compatible] ---\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Metrics: binary vs multiclass handled automatically\n",
        "num_labels = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "print(f\"[Fine-tune] Detected {num_labels} classes ‚Üí metrics average='{avg_type}'\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "# 2) Class weights for imbalanced data (size == num_labels)\n",
        "counts = np.bincount(y_train, minlength=num_labels)\n",
        "# Heuristic: inverse-frequency scaled to max=1.0 (safe for CE)\n",
        "weights = counts.max() / np.maximum(counts, 1)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "print(f\"[Fine-tune] Class weights: {class_weights.tolist()}\")\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 3) Helper: tokenizer already defined above. Re-tokenize per max_length\n",
        "def tokenize_texts(texts, max_length=160):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# 4) Version-compatible TrainingArguments factory\n",
        "import inspect\n",
        "\n",
        "def make_training_args(name, batch_size, lr, epochs, weight_decay, warmup_ratio):\n",
        "    kwargs_modern = dict(\n",
        "        output_dir=f\"./runs/{name}\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[]\n",
        "    )\n",
        "    try:\n",
        "        # Try modern signature first\n",
        "        return TrainingArguments(**kwargs_modern)\n",
        "    except TypeError:\n",
        "        # Fallback for older transformers (no evaluation_strategy/save_strategy)\n",
        "        print(\"[Fine-tune] Using legacy TrainingArguments fallback.\")\n",
        "        kwargs_legacy = dict(\n",
        "            output_dir=f\"./runs/{name}\",\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            learning_rate=lr,\n",
        "            num_train_epochs=epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            logging_steps=50,\n",
        "            do_eval=True,          # legacy way to enable evaluation\n",
        "            save_steps=500,        # periodic saving\n",
        "            overwrite_output_dir=True,\n",
        "            fp16=torch.cuda.is_available()\n",
        "        )\n",
        "        return TrainingArguments(**kwargs_legacy)\n",
        "\n",
        "def run_experiment(name, backbone, batch_size=16, lr=2e-5, epochs=3,\n",
        "                   weight_decay=0.01, warmup_ratio=0.1, max_length=160):\n",
        "    # Re-tokenize for this max_length\n",
        "    tr = tokenize_texts(X_train, max_length=max_length)\n",
        "    va = tokenize_texts(X_val,   max_length=max_length)\n",
        "\n",
        "    train_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": tr[\"input_ids\"],\n",
        "        \"attention_mask\": tr[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_train.to_numpy(), dtype=torch.long)   # <-- use .to_numpy()\n",
        "    })\n",
        "    val_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": va[\"input_ids\"],\n",
        "        \"attention_mask\": va[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_val.to_numpy(), dtype=torch.long)     # <-- use .to_numpy()\n",
        "    })\n",
        "\n",
        "\n",
        "    # Load backbone with correct num_labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        backbone, num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    args = make_training_args(\n",
        "        name=name, batch_size=batch_size, lr=lr, epochs=epochs,\n",
        "        weight_decay=weight_decay, warmup_ratio=warmup_ratio\n",
        "    )\n",
        "\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds_local,\n",
        "        eval_dataset=val_ds_local,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"\\n>>> {name} results: {metrics}\\n\")\n",
        "    return metrics, trainer\n",
        "\n",
        "# --- Define backbones (already set earlier) ---\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "results = OrderedDict()\n",
        "\n",
        "# Exp-A: ClinicalBERT, conservative LR, small batch\n",
        "results['expA_clinicalbert_bs16_lr2e-5_ep3'] = run_experiment(\n",
        "    name=\"expA_clinicalbert_bs16_lr2e-5_ep3\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=2e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-B: ClinicalBERT, slightly higher LR, more epochs\n",
        "results['expB_clinicalbert_bs16_lr5e-5_ep4'] = run_experiment(\n",
        "    name=\"expB_clinicalbert_bs16_lr5e-5_ep4\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=5e-5, epochs=4,\n",
        "    weight_decay=0.01, warmup_ratio=0.06, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-C: DistilBERT fast baseline\n",
        "results['expC_distilbert_bs32_lr3e-5_ep3'] = run_experiment(\n",
        "    name=\"expC_distilbert_bs32_lr3e-5_ep3\",\n",
        "    backbone=DISTIL_BERT,\n",
        "    batch_size=32, lr=3e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=128\n",
        ")\n",
        "\n",
        "# Leaderboard\n",
        "board = []\n",
        "for k,(m,_t) in results.items():\n",
        "    board.append((k, m.get('eval_f1', float('nan')), m.get('eval_accuracy', float('nan'))))\n",
        "board = sorted(board, key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nLeaderboard (by F1):\")\n",
        "for name, f1, acc in board:\n",
        "    print(f\"{name:35s}  F1={f1:.4f}  Acc={acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Record all experiment results to Excel log file\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Create a new workbook\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Experiment_Logs\"\n",
        "\n",
        "# Define header style\n",
        "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "header_font = Font(bold=True, color=\"FFFFFF\")\n",
        "\n",
        "# Define headers\n",
        "headers = [\n",
        "    \"Experiment_ID\",\n",
        "    \"Model_Backbone\",\n",
        "    \"Batch_Size\",\n",
        "    \"Learning_Rate\",\n",
        "    \"Epochs\",\n",
        "    \"Weight_Decay\",\n",
        "    \"Warmup_Ratio\",\n",
        "    \"Max_Length\",\n",
        "    \"Accuracy\",\n",
        "    \"F1_Score\",\n",
        "    \"Precision\",\n",
        "    \"Recall\"\n",
        "]\n",
        "\n",
        "# Write headers\n",
        "for col_idx, header in enumerate(headers, 1):\n",
        "    cell = ws.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "# Function to parse experiment name and extract hyperparameters\n",
        "def parse_experiment_name(exp_name):\n",
        "    \"\"\"Extract hyperparameters from experiment name\"\"\"\n",
        "    params = {\n",
        "        \"backbone\": \"Unknown\",\n",
        "        \"batch_size\": None,\n",
        "        \"learning_rate\": None,\n",
        "        \"epochs\": None\n",
        "    }\n",
        "\n",
        "    # Extract backbone\n",
        "    if \"clinicalbert\" in exp_name.lower():\n",
        "        params[\"backbone\"] = \"ClinicalBERT\"\n",
        "    elif \"distilbert\" in exp_name.lower():\n",
        "        params[\"backbone\"] = \"DistilBERT\"\n",
        "\n",
        "    # Extract batch size (bs16, bs32, etc.)\n",
        "    bs_match = re.search(r'bs(\\d+)', exp_name.lower())\n",
        "    if bs_match:\n",
        "        params[\"batch_size\"] = int(bs_match.group(1))\n",
        "\n",
        "    # Extract learning rate (lr2e-5, lr5e-5, etc.)\n",
        "    lr_match = re.search(r'lr([\\d.e-]+)', exp_name.lower())\n",
        "    if lr_match:\n",
        "        lr_str = lr_match.group(1)\n",
        "        # Convert scientific notation string to float\n",
        "        if 'e' in lr_str:\n",
        "            base, exp = lr_str.split('e')\n",
        "            params[\"learning_rate\"] = float(base) * (10 ** int(exp))\n",
        "        else:\n",
        "            params[\"learning_rate\"] = float(lr_str)\n",
        "\n",
        "    # Extract epochs (ep3, ep4, etc.)\n",
        "    ep_match = re.search(r'ep(\\d+)', exp_name.lower())\n",
        "    if ep_match:\n",
        "        params[\"epochs\"] = int(ep_match.group(1))\n",
        "\n",
        "    return params\n",
        "\n",
        "# Store experiment configurations (you may need to adjust these based on your actual runs)\n",
        "experiment_configs = {\n",
        "    \"expA_clinicalbert_bs16_lr2e-5_ep3\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"max_length\": 160\n",
        "    },\n",
        "    \"expB_clinicalbert_bs16_lr5e-5_ep4\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.06,\n",
        "        \"max_length\": 160\n",
        "    },\n",
        "    \"expC_distilbert_bs32_lr3e-5_ep3\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"max_length\": 128\n",
        "    }\n",
        "}\n",
        "\n",
        "# Write experiment data\n",
        "row = 2\n",
        "for exp_name, (metrics, trainer) in results.items():\n",
        "    # Parse experiment name\n",
        "    parsed = parse_experiment_name(exp_name)\n",
        "    config = experiment_configs.get(exp_name, {})\n",
        "\n",
        "    # Write data\n",
        "    ws.cell(row=row, column=1, value=exp_name)  # Experiment_ID\n",
        "    ws.cell(row=row, column=2, value=parsed[\"backbone\"])  # Model_Backbone\n",
        "    ws.cell(row=row, column=3, value=parsed[\"batch_size\"])  # Batch_Size\n",
        "    ws.cell(row=row, column=4, value=parsed[\"learning_rate\"])  # Learning_Rate\n",
        "    ws.cell(row=row, column=5, value=parsed[\"epochs\"])  # Epochs\n",
        "    ws.cell(row=row, column=6, value=config.get(\"weight_decay\", \"N/A\"))  # Weight_Decay\n",
        "    ws.cell(row=row, column=7, value=config.get(\"warmup_ratio\", \"N/A\"))  # Warmup_Ratio\n",
        "    ws.cell(row=row, column=8, value=config.get(\"max_length\", \"N/A\"))  # Max_Length\n",
        "    ws.cell(row=row, column=9, value=metrics.get(\"eval_accuracy\", \"N/A\"))  # Accuracy\n",
        "    ws.cell(row=row, column=10, value=metrics.get(\"eval_f1\", \"N/A\"))  # F1_Score\n",
        "    ws.cell(row=row, column=11, value=metrics.get(\"eval_precision\", \"N/A\"))  # Precision\n",
        "    ws.cell(row=row, column=12, value=metrics.get(\"eval_recall\", \"N/A\"))  # Recall\n",
        "\n",
        "    row += 1\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min(max_length + 2, 30)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save the file\n",
        "excel_filename = f\"Exercise_F2_Experiment_Logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "wb.save(excel_filename)\n",
        "\n",
        "print(f\"‚úÖ Experiment logs saved to: {excel_filename}\")\n",
        "print(f\"   Total experiments logged: {len(results)}\")\n",
        "print(f\"   Columns: {', '.join(headers)}\")\n",
        "\n",
        "# Automatically download the file\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(excel_filename)\n",
        "    print(f\"‚úÖ File automatically downloaded: {excel_filename}\")\n",
        "except ImportError:\n",
        "    print(\"Note: Not running in Google Colab. File saved locally.\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not auto-download. File saved at: {excel_filename}\")\n",
        "    print(f\"   Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "GqC_w9j4MCOg",
        "outputId": "7851b232-164d-429d-838a-2f059007dafa"
      },
      "id": "GqC_w9j4MCOg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Experiment logs saved to: Exercise_F2_Experiment_Logs_20251108_112032.xlsx\n",
            "   Total experiments logged: 3\n",
            "   Columns: Experiment_ID, Model_Backbone, Batch_Size, Learning_Rate, Epochs, Weight_Decay, Warmup_Ratio, Max_Length, Accuracy, F1_Score, Precision, Recall\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d3738d4-98ab-4b5b-9482-9a1786944367\", \"Exercise_F2_Experiment_Logs_20251108_112032.xlsx\", 5517)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ File automatically downloaded: Exercise_F2_Experiment_Logs_20251108_112032.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSTDHJX1hZ2O"
      },
      "source": [
        "## 6) Eval (Pick Best and Run Inference)"
      ],
      "id": "MSTDHJX1hZ2O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `# Select the best run from 'results' dict above`\n",
        "  Introduces the section that will pick the highest-scoring experiment.\n",
        "\n",
        "* `best_name, best_f1 = None, -1.0`\n",
        "  Initializes the current ‚Äúbest‚Äù run name to nothing and its F1 to a very low value.\n",
        "\n",
        "* `best_trainer = None`\n",
        "  Placeholder for the Trainer object of the best run.\n",
        "\n",
        "* `for name,(metrics, trainer) in results.items():`\n",
        "  Loops through each experiment entry, unpacking its metrics and Trainer.\n",
        "\n",
        "* `    if metrics['eval_f1'] > best_f1:`\n",
        "  Checks if this experiment‚Äôs F1 beats the current best.\n",
        "\n",
        "* `        best_f1 = metrics['eval_f1']`\n",
        "  Updates the best F1 score.\n",
        "\n",
        "* `        best_name = name`\n",
        "  Records the winning experiment‚Äôs name.\n",
        "\n",
        "* `        best_trainer = trainer`\n",
        "  Stores the Trainer tied to the winning run.\n",
        "\n",
        "* `print(f\"Best run: {best_name} with F1={best_f1:.4f}\")`\n",
        "  Prints which run won and its F1 rounded to four decimals.\n",
        "\n",
        "* `# Save the best model for reuse`\n",
        "  Marks the section that persists the best model and tokenizer.\n",
        "\n",
        "* `save_dir = f\"./best_model_{best_name}\"`\n",
        "  Builds a folder path named after the best run.\n",
        "\n",
        "* `best_trainer.save_model(save_dir)`\n",
        "  Saves model weights and config to that folder.\n",
        "\n",
        "* `tokenizer.save_pretrained(save_dir)`\n",
        "  Saves the tokenizer files to the same folder.\n",
        "\n",
        "* `# Simple inference helper`\n",
        "  Introduces a convenience function for making predictions later.\n",
        "\n",
        "* `def predict(texts, model_dir=save_dir):`\n",
        "  Starts a function that takes raw texts and an optional model path.\n",
        "\n",
        "* `    tok = AutoTokenizer.from_pretrained(model_dir)`\n",
        "  Loads the tokenizer from the saved folder.\n",
        "\n",
        "* `    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)`\n",
        "  Loads the saved classifier and moves it to CPU/GPU.\n",
        "\n",
        "* `    enc = tok(list(texts), padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)`\n",
        "  Tokenizes the input texts, pads and truncates to length 160, returns PyTorch tensors, and moves them to the device.\n",
        "\n",
        "* `    with torch.no_grad():`\n",
        "  Disables gradient tracking for faster, memory-light inference.\n",
        "\n",
        "* `        logits = mdl(**enc).logits`\n",
        "  Runs the model forward pass and grabs raw class scores.\n",
        "\n",
        "* `    pred = torch.argmax(logits, dim=-1).cpu().numpy()`\n",
        "  Converts logits to predicted class IDs and moves them to NumPy.\n",
        "\n",
        "* `    prob = torch.softmax(logits, dim=-1).cpu().numpy()[:,1]`\n",
        "  Turns logits into probabilities and selects the column for class 1.\n",
        "\n",
        "* `    return pred, prob`\n",
        "  Returns predicted labels and their positive-class probabilities.\n",
        "\n",
        "* `# Demo predictions on a few samples`\n",
        "  Starts a small test to show the function in action.\n",
        "\n",
        "* `samples = [`\n",
        "  Opens a list of example texts.\n",
        "\n",
        "* `    \"I feel calm and in control today.\",`\n",
        "  Sample 1: likely not stressed.\n",
        "\n",
        "* `    \"My chest is tight and I cannot focus, I think I am very stressed.\",`\n",
        "  Sample 2: likely stressed.\n",
        "\n",
        "* `    \"Workload is heavy but manageable so far.\"`\n",
        "  Sample 3: borderline but manageable tone.\n",
        "\n",
        "* `]`\n",
        "  Closes the list of samples.\n",
        "\n",
        "* `pred, prob = predict(samples)`\n",
        "  Runs inference on the samples, returning labels and probabilities.\n",
        "\n",
        "* `for s, y, p in zip(samples, pred, prob):`\n",
        "  Iterates over each sample with its predicted label and probability.\n",
        "\n",
        "* `    lab = \"stressed(1)\" if y==1 else \"not-stressed(0)\"`\n",
        "  Converts numeric label to a readable string.\n",
        "\n",
        "* `    print(f\"[{lab}  p={p:.3f}]  {s}\")`\n",
        "  Prints the label, probability (to three decimals), and the original text.\n"
      ],
      "metadata": {
        "id": "SAA1gEu1CTdp"
      },
      "id": "SAA1gEu1CTdp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24E_Tay_hZ2O",
      "metadata": {
        "id": "24E_Tay_hZ2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e33687b-710c-4685-8e34-29c24c995cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best run: expB_clinicalbert_bs16_lr5e-5_ep4 with F1=0.8236\n",
            "[not‚Äëstressed(0)  p=0.001]  I feel calm and in control today.\n",
            "[not‚Äëstressed(0)  p=0.001]  My chest is tight and I cannot focus, I think I am very stressed.\n",
            "[not‚Äëstressed(0)  p=0.007]  Workload is heavy but manageable so far.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Select the best run from 'results' dict above\n",
        "best_name, best_f1 = None, -1.0\n",
        "best_trainer = None\n",
        "for name,(metrics, trainer) in results.items():\n",
        "    if metrics['eval_f1'] > best_f1:\n",
        "        best_f1 = metrics['eval_f1']\n",
        "        best_name = name\n",
        "        best_trainer = trainer\n",
        "\n",
        "print(f\"Best run: {best_name} with F1={best_f1:.4f}\")\n",
        "\n",
        "# Save the best model for reuse\n",
        "save_dir = f\"./best_model_{best_name}\"\n",
        "best_trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# Simple inference helper\n",
        "def predict(texts, model_dir=save_dir):\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)\n",
        "    enc = tok(list(texts), padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "    pred = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "    prob = torch.softmax(logits, dim=-1).cpu().numpy()[:,1]\n",
        "    return pred, prob\n",
        "\n",
        "# Demo predictions on a few samples\n",
        "samples = [\n",
        "    \"I feel calm and in control today.\",\n",
        "    \"My chest is tight and I cannot focus, I think I am very stressed.\",\n",
        "    \"Workload is heavy but manageable so far.\"\n",
        "]\n",
        "pred, prob = predict(samples)\n",
        "for s, y, p in zip(samples, pred, prob):\n",
        "    lab = \"stressed(1)\" if y==1 else \"not‚Äëstressed(0)\"\n",
        "    print(f\"[{lab}  p={p:.3f}]  {s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60280a27",
      "metadata": {
        "id": "60280a27"
      },
      "source": [
        "# Exercise F3: Automated Hyperparameter Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I install the packages needed for automated hyperparameter optimization. The command uses pip to install multiple libraries at once.\n",
        "\n",
        "The `!pip install` syntax runs a shell command in Jupyter notebooks. I specify the package names separated by spaces. The `-U` flag updates packages to their latest versions. The `-q` flag runs the installation quietly to reduce output noise.\n",
        "\n",
        "I install transformers for model training and tokenization, datasets for efficient data handling, accelerate for faster training, ray with the tune extension for distributed hyperparameter search, optuna as the optimization backend, and openpyxl for creating Excel files.\n",
        "\n",
        "The command installs all packages in one line. This ensures I have everything needed before running the optimization code."
      ],
      "metadata": {
        "id": "1DKRMdyUmm_5"
      },
      "id": "1DKRMdyUmm_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d70dbc7",
      "metadata": {
        "id": "8d70dbc7"
      },
      "outputs": [],
      "source": [
        "# Install required packages for hyperparameter optimization\n",
        "!pip install transformers datasets accelerate ray[tune] optuna openpyxl -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I prepare my environment for automated hyperparameter tuning. This cell imports libraries, sets up the model, and prepares data structures.\n",
        "\n",
        "### Import Statements\n",
        "\n",
        "I import time to track execution duration. I import json for data serialization. I import datetime to create timestamps. I import Workbook, Font, PatternFill, and Alignment from openpyxl to create formatted Excel files.\n",
        "\n",
        "I import torch for tensor operations and device management. I import numpy as np for numerical computations. I import AutoModelForSequenceClassification and AutoTokenizer from transformers to load pre-trained models. I import TrainingArguments and Trainer for model training. I import set_seed for reproducibility.\n",
        "\n",
        "I import Dataset from the datasets library to wrap my data efficiently. I import accuracy_score and precision_recall_fscore_support from sklearn.metrics to calculate evaluation metrics.\n",
        "\n",
        "### Setting Random Seed\n",
        "\n",
        "I call `set_seed(42)` to make results reproducible. This sets the random seed for Python, NumPy, PyTorch, and other libraries. The number 42 is arbitrary but consistent.\n",
        "\n",
        "### Device Configuration\n",
        "\n",
        "I create a device variable using `torch.device()`. The conditional checks if CUDA is available. If a GPU exists, it uses \"cuda\". Otherwise, it uses \"cpu\". I print the device so I know what hardware I am using.\n",
        "\n",
        "### Model and Tokenizer Setup\n",
        "\n",
        "I set CLINICAL_BERT to the model identifier string \"emilyalsentzer/Bio_ClinicalBERT\". This is the same model from Exercise F2. I call `AutoTokenizer.from_pretrained()` with this identifier to load the tokenizer. The tokenizer converts text into token IDs that the model understands.\n",
        "\n",
        "### Class Detection\n",
        "\n",
        "I calculate the number of unique labels in y_train using `np.unique()`. I store this in num_labels. I set avg_type to \"binary\" if num_labels equals 2, otherwise \"weighted\". This determines how sklearn calculates metrics for multi-class problems. I print the detected number of classes and the averaging method.\n",
        "\n",
        "### Tokenization Function\n",
        "\n",
        "I define a function called `tokenize_texts` that takes texts and an optional max_length parameter. The function calls the tokenizer with the text list. The padding parameter set to True adds padding tokens to make sequences the same length. The truncation parameter set to True cuts off text longer than max_length. The max_length parameter limits sequence length to 160 tokens. The return_tensors parameter set to \"pt\" returns PyTorch tensors instead of lists.\n",
        "\n",
        "The function returns a dictionary with input_ids and attention_mask tensors. These represent token IDs and which tokens to attend to.\n",
        "\n",
        "### Creating Datasets\n",
        "\n",
        "I call `tokenize_texts()` on X_train and X_val to create train_enc and val_enc. These contain tokenized input data.\n",
        "\n",
        "I create train_ds using `Dataset.from_dict()`. I pass a dictionary with three keys. The \"input_ids\" key contains the token IDs from train_enc. The \"attention_mask\" key contains the attention masks from train_enc. The \"labels\" key contains y_train converted to a PyTorch tensor with long integer type.\n",
        "\n",
        "I create val_ds the same way using val_enc and y_val. The Dataset class wraps the data in a format the Trainer expects.\n",
        "\n",
        "### Computing Class Weights\n",
        "\n",
        "I use `np.bincount()` to count occurrences of each class label in y_train. The minlength parameter ensures the array has at least num_labels elements. I store counts in a variable.\n",
        "\n",
        "I calculate weights by dividing the maximum count by each individual count. The `np.maximum()` function ensures no division by zero. This creates inverse frequency weights where minority classes get higher weights.\n",
        "\n",
        "I convert weights to a PyTorch tensor with float32 dtype. I move it to the device so it matches where the model runs. These weights balance the loss function during training.\n",
        "\n",
        "### Metrics Function\n",
        "\n",
        "I define `compute_metrics()` that takes eval_pred as input. The eval_pred parameter is a tuple containing logits and labels from model evaluation.\n",
        "\n",
        "I unpack logits and labels from the tuple. I use `np.argmax()` on logits along the last axis to get predicted class indices. This finds the class with the highest probability for each sample.\n",
        "\n",
        "I call `precision_recall_fscore_support()` with labels and predictions. I set average to avg_type which handles binary or multi-class cases. The function returns precision, recall, F1 score, and support counts. I use underscore to ignore support.\n",
        "\n",
        "I call `accuracy_score()` to calculate accuracy. I return a dictionary with accuracy, precision, recall, and f1 keys. The Trainer uses this function during evaluation.\n",
        "\n",
        "### Weighted Trainer Class\n",
        "\n",
        "I import CrossEntropyLoss from torch.nn. This is the loss function I use for classification.\n",
        "\n",
        "I define a class called WeightedTrainer that inherits from Trainer. This extends the base Trainer with custom loss computation.\n",
        "\n",
        "I define the `compute_loss()` method that overrides the parent method. The method takes model, inputs, return_outputs, and keyword arguments.\n",
        "\n",
        "I extract labels from the inputs dictionary using `.get()`. I create a filtered dictionary that excludes labels from inputs. I pass this filtered dictionary to the model to get outputs. The model returns logits in the outputs dictionary.\n",
        "\n",
        "I create a CrossEntropyLoss instance with the class_weights parameter. This applies the weights during loss calculation.\n",
        "\n",
        "I reshape logits using `.view(-1, model.config.num_labels)`. The -1 dimension lets PyTorch infer the batch size. I reshape labels using `.view(-1)` to flatten them. I compute loss using the loss function.\n",
        "\n",
        "I return loss and outputs if return_outputs is True, otherwise just loss. This matches the expected Trainer interface.\n",
        "\n",
        "### Completion Message\n",
        "\n",
        "I print a success message indicating the setup is complete. This confirms all components are ready for hyperparameter optimization."
      ],
      "metadata": {
        "id": "sVCQkYiWAtm1"
      },
      "id": "sVCQkYiWAtm1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343e5038",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "9f1d0cdaf24a44da9cb46f18dba4472e",
            "36435456910146b8a6e81063cc4d4a2c",
            "faf1b1bc620047b69bcf98f5414e6cb4",
            "f1655280c6594305bb464fa45b9353c2",
            "e893cfa2279b412283d182362cf8ccf4",
            "edef40bdde744175953db1868655544c",
            "1163a92422254997b00c18b226777a18",
            "e5db71f7f9744cc5b528c2e6bb1bb005",
            "2c1d2db435e443e09cf79f039cd15895",
            "9f33e1990bca41c4a466664bc5702ee7",
            "54480187dfe14ccbb342d776de773ce9",
            "108304913e1247f9bd4e55e7604879e5",
            "ef73ee4716e04b39a5e6ec83ca098134",
            "c60010d438b84d028f7396c41c9b3080",
            "879e024698e74051b6e3ef539bc84cd9",
            "0ac26a23895546f89cabca752fd6d544",
            "dc38b5222eb04b05ae1ce3abc1eb82eb",
            "53c9e5eb4bb648e0a7a4bf06b39a865a",
            "99db89e25f4c4201a226a6caf6480638",
            "5bcd2dc7b3ab47e4b213c29f922ebadc",
            "38b293c32fd146b883279cb6fc71996d",
            "6aaa2eed39354362947d7387cce4b190"
          ]
        },
        "id": "343e5038",
        "outputId": "9a9aeac2-2830-4351-dfdd-1b8519f28bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f1d0cdaf24a44da9cb46f18dba4472e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "108304913e1247f9bd4e55e7604879e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2712835240.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Number of classes (from Exercise F2 - using same y_train variable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mavg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {num_labels} classes ‚Üí using average='{avg_type}' for metrics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Exercise F3: Setup for Automated Hyperparameter Optimization\n",
        "# ============================================================================\n",
        "# IMPORTANT: This exercise uses the SAME data and model from Exercise F2:\n",
        "#   - Same model: ClinicalBERT (emilyalsentzer/Bio_ClinicalBERT)\n",
        "#   - Same data splits: X_train, X_val, y_train, y_val (from Exercise F2)\n",
        "#   - Same class weights and metrics computation\n",
        "#   - Only difference: Using automated hyperparameter optimization\n",
        "# ============================================================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model and tokenizer setup (using ClinicalBERT from Exercise F2)\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "\n",
        "# Number of classes (from Exercise F2 - using same y_train variable)\n",
        "num_labels = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "print(f\"Detected {num_labels} classes ‚Üí using average='{avg_type}' for metrics\")\n",
        "\n",
        "# Tokenize datasets (reusing SAME X_train, X_val, y_train, y_val from Exercise F2)\n",
        "def tokenize_texts(texts, max_length=160):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_enc = tokenize_texts(X_train, max_length=160)\n",
        "val_enc = tokenize_texts(X_val, max_length=160)\n",
        "\n",
        "train_ds = Dataset.from_dict({\n",
        "    \"input_ids\": train_enc[\"input_ids\"],\n",
        "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
        "})\n",
        "\n",
        "val_ds = Dataset.from_dict({\n",
        "    \"input_ids\": val_enc[\"input_ids\"],\n",
        "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_val.to_numpy(), dtype=torch.long)\n",
        "})\n",
        "\n",
        "# Compute class weights (from Exercise F2)\n",
        "counts = np.bincount(y_train, minlength=num_labels)\n",
        "weights = counts.max() / np.maximum(counts, 1)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "\n",
        "# Metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "# Weighted Trainer class\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print(\"‚úÖ Exercise F3 setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863ffde6",
      "metadata": {
        "id": "863ffde6"
      },
      "source": [
        "### F3.2: Random Search Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I implement Random Search to find optimal hyperparameters. This cell defines the search space and executes the optimization.\n",
        "\n",
        "### Model Initialization Function\n",
        "\n",
        "I define a function called `model_init()` that creates a fresh model for each trial. This function takes no parameters but returns a model instance.\n",
        "\n",
        "I call `AutoModelForSequenceClassification.from_pretrained()` with two arguments. The first argument is CLINICAL_BERT which is the model identifier string. The second argument is num_labels which sets the number of output classes.\n",
        "\n",
        "I call `.to(device)` on the model to move it to the appropriate device. If CUDA is available, it moves to GPU. Otherwise, it stays on CPU.\n",
        "\n",
        "I return the model instance. The hyperparameter_search method calls this function for each trial. This ensures each trial starts with identical initial weights, making comparisons fair.\n",
        "\n",
        "### Hyperparameter Space Definition\n",
        "\n",
        "I define a function called `random_search_hp_space()` that takes a trial parameter. The trial object comes from Optuna and suggests hyperparameter values.\n",
        "\n",
        "I call `trial.suggest_float()` for learning_rate. I pass the parameter name as a string \"learning_rate\". I set the minimum to 1e-5 and maximum to 3e-5. The log parameter set to True samples on a logarithmic scale. This is appropriate for learning rates which vary over orders of magnitude.\n",
        "\n",
        "I call `trial.suggest_categorical()` for per_device_train_batch_size. I pass the parameter name as a string. I provide a list of discrete options [8, 16]. The function randomly picks one of these values.\n",
        "\n",
        "I call `trial.suggest_float()` for weight_decay. I set the range from 0.0 to 0.01. I do not use log scale since weight decay is linear.\n",
        "\n",
        "I call `trial.suggest_int()` for num_train_epochs. I set both minimum and maximum to 2. This keeps training fast while still allowing the model to learn.\n",
        "\n",
        "I return a dictionary with all four hyperparameters. The keys match the parameter names that TrainingArguments expects.\n",
        "\n",
        "### Training Arguments Configuration\n",
        "\n",
        "I create a TrainingArguments object called random_training_args. I set output_dir to \"./random_search_results\" where checkpoints save. I set eval_strategy to \"epoch\" to evaluate after each epoch. I set save_strategy to \"epoch\" to save checkpoints after each epoch.\n",
        "\n",
        "I set load_best_model_at_end to True to keep the best performing model. I set metric_for_best_model to \"f1\" to optimize for F1 score. I set greater_is_better to True since higher F1 is better.\n",
        "\n",
        "I set fp16 to the result of `torch.cuda.is_available()` to use half precision if GPU is available. I set report_to to \"none\" to disable external logging services.\n",
        "\n",
        "I set warmup_steps to 500 to gradually increase learning rate at the start. I set logging_steps to 100 to print progress every 100 steps.\n",
        "\n",
        "### Trainer Initialization\n",
        "\n",
        "I create a WeightedTrainer instance called random_trainer. I pass model_init as a function reference, not a model instance. This lets the trainer create a fresh model for each trial.\n",
        "\n",
        "I pass random_training_args as the args parameter. I pass train_ds and val_ds as the datasets. I pass compute_metrics as the metrics function. I pass tokenizer for text processing.\n",
        "\n",
        "### Execution Tracking\n",
        "\n",
        "I print messages indicating Random Search is starting. I print that it will run 6 trials. I print that it explores continuous ranges efficiently.\n",
        "\n",
        "I call `time.time()` to record the start time. I store this in random_start_time.\n",
        "\n",
        "### Running Hyperparameter Search\n",
        "\n",
        "I call `hyperparameter_search()` on the trainer. I set backend to \"optuna\" to use Optuna for optimization. I pass random_search_hp_space as the hp_space parameter. This function defines which hyperparameters to optimize.\n",
        "\n",
        "I set direction to \"maximize\" since I want the highest F1 score. I set n_trials to 6 to run six different hyperparameter combinations.\n",
        "\n",
        "The method returns the best trial object. I store this in random_best_trial.\n",
        "\n",
        "### Time Calculation\n",
        "\n",
        "I call `time.time()` again to get the end time. I store this in random_end_time. I subtract random_start_time from random_end_time to get the total duration. I store this in random_total_time.\n",
        "\n",
        "### Results Display\n",
        "\n",
        "I print a completion message with the total time formatted to two decimal places. I check if random_best_trial exists. If it does, I print the trial object. I extract hyperparameters using the `.hyperparameters` attribute. I store these in random_best_hps.\n",
        "\n",
        "I loop through the hyperparameters dictionary using `.items()`. I print each key and value pair. I print the best F1 score using the `.objective` attribute.\n",
        "\n",
        "If random_best_trial does not exist, I print an error message and set random_best_hps to an empty dictionary. This prevents errors in later cells.\n"
      ],
      "metadata": {
        "id": "JvUAakaJBJL1"
      },
      "id": "JvUAakaJBJL1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311cbad7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "311cbad7",
        "outputId": "588ea963-4236-4d4c-aa6b-7812ce5c4a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1283968438.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  random_trainer = WeightedTrainer(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-11-08 13:08:52,516] A new study created in memory with name: no-name-a78bbfa1-9212-468c-8194-d81885a1b331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Random Search ---\n",
            "Random Search will sample 6 trials from the hyperparameter space\n",
            "This allows exploration of continuous ranges efficiently.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10536' max='10536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10536/10536 22:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.509000</td>\n",
              "      <td>0.625845</td>\n",
              "      <td>0.798045</td>\n",
              "      <td>0.801310</td>\n",
              "      <td>0.798045</td>\n",
              "      <td>0.797731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.470800</td>\n",
              "      <td>0.599975</td>\n",
              "      <td>0.811806</td>\n",
              "      <td>0.820123</td>\n",
              "      <td>0.811806</td>\n",
              "      <td>0.812609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 13:31:35,225] Trial 0 finished with value: 3.256344032885604 and parameters: {'learning_rate': 1.7108216142611804e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.009677289952248508, 'num_train_epochs': 2}. Best is trial 0 with value: 3.256344032885604.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 16:12, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>0.590603</td>\n",
              "      <td>0.796147</td>\n",
              "      <td>0.799588</td>\n",
              "      <td>0.796147</td>\n",
              "      <td>0.796199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.331800</td>\n",
              "      <td>0.539433</td>\n",
              "      <td>0.809718</td>\n",
              "      <td>0.822356</td>\n",
              "      <td>0.809718</td>\n",
              "      <td>0.810934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 13:47:52,115] Trial 1 finished with value: 3.2527265840624726 and parameters: {'learning_rate': 2.853743439192109e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.006042395220084231, 'num_train_epochs': 2}. Best is trial 0 with value: 3.256344032885604.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5269' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 13:55, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.642700</td>\n",
              "      <td>0.610374</td>\n",
              "      <td>0.788839</td>\n",
              "      <td>0.797406</td>\n",
              "      <td>0.788839</td>\n",
              "      <td>0.791190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1149' max='1318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1149/1318 00:23 < 00:03, 48.08 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Random Search Implementation\n",
        "# This randomly samples from the hyperparameter space\n",
        "\n",
        "def random_search_hp_space(trial):\n",
        "    \"\"\"\n",
        "    Define the hyperparameter space for Random Search.\n",
        "    Random Search samples RANDOMLY from continuous/discrete ranges.\n",
        "    \"\"\"\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 3e-5, log=True)  # Lower range\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16])  # Smaller batches\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.01)  # Same (already low)\n",
        "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 2, 2)  # Keep 2 epochs for speed\n",
        "\n",
        "    return {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"num_train_epochs\": num_train_epochs,\n",
        "    }\n",
        "\n",
        "# Training arguments template (same as grid search)\n",
        "random_training_args = TrainingArguments(\n",
        "    output_dir=\"./random_search_results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    warmup_steps=500,\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "# Initialize trainer for random search\n",
        "random_trainer = WeightedTrainer(\n",
        "    model_init=model_init,\n",
        "    args=random_training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"--- Starting Random Search ---\")\n",
        "print(\"Random Search will sample 6 trials from the hyperparameter space\")\n",
        "print(\"This allows exploration of continuous ranges efficiently.\\n\")\n",
        "\n",
        "# Track start time\n",
        "random_start_time = time.time()\n",
        "\n",
        "# Execute Random Search\n",
        "# Use same number of trials as grid search for fair comparison\n",
        "random_best_trial = random_trainer.hyperparameter_search(\n",
        "    backend=\"optuna\",\n",
        "    hp_space=random_search_hp_space,\n",
        "    direction=\"maximize\",\n",
        "    n_trials=6,  # Same number of trials as grid search for fair comparison\n",
        ")\n",
        "\n",
        "random_end_time = time.time()\n",
        "random_total_time = random_end_time - random_start_time\n",
        "\n",
        "print(f\"\\n--- Random Search Complete (Time: {random_total_time:.2f} seconds) ---\")\n",
        "print(\"\\nBEST HYPERPARAMETERS FROM RANDOM SEARCH:\")\n",
        "if random_best_trial:\n",
        "    print(random_best_trial)\n",
        "    random_best_hps = random_best_trial.hyperparameters\n",
        "    print(\"\\nBest Hyperparameters:\")\n",
        "    for key, value in random_best_hps.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    print(f\"\\nBest F1 Score: {random_best_trial.objective:.4f}\")\n",
        "else:\n",
        "    print(\"Random search failed or no best trial found.\")\n",
        "    random_best_hps = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bbe7cc",
      "metadata": {
        "id": "e4bbe7cc"
      },
      "source": [
        "### F3.3: Extract All Trial Results and Log to Excel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I implement Random Search to find optimal hyperparameters. This cell defines the search space and executes the optimization.\n",
        "\n",
        "### Model Initialization Function\n",
        "\n",
        "I define a function called `model_init()` that creates a fresh model for each trial. This function takes no parameters but returns a model instance.\n",
        "\n",
        "I call `AutoModelForSequenceClassification.from_pretrained()` with two arguments. The first argument is CLINICAL_BERT which is the model identifier string. The second argument is num_labels which sets the number of output classes.\n",
        "\n",
        "I call `.to(device)` on the model to move it to the appropriate device. If CUDA is available, it moves to GPU. Otherwise, it stays on CPU.\n",
        "\n",
        "I return the model instance. The hyperparameter_search method calls this function for each trial. This ensures each trial starts with identical initial weights, making comparisons fair.\n",
        "\n",
        "### Hyperparameter Space Definition\n",
        "\n",
        "I define a function called `random_search_hp_space()` that takes a trial parameter. The trial object comes from Optuna and suggests hyperparameter values.\n",
        "\n",
        "I call `trial.suggest_float()` for learning_rate. I pass the parameter name as a string \"learning_rate\". I set the minimum to 1e-5 and maximum to 3e-5. The log parameter set to True samples on a logarithmic scale. This is appropriate for learning rates which vary over orders of magnitude.\n",
        "\n",
        "I call `trial.suggest_categorical()` for per_device_train_batch_size. I pass the parameter name as a string. I provide a list of discrete options [8, 16]. The function randomly picks one of these values.\n",
        "\n",
        "I call `trial.suggest_float()` for weight_decay. I set the range from 0.0 to 0.01. I do not use log scale since weight decay is linear.\n",
        "\n",
        "I call `trial.suggest_int()` for num_train_epochs. I set both minimum and maximum to 2. This keeps training fast while still allowing the model to learn.\n",
        "\n",
        "I return a dictionary with all four hyperparameters. The keys match the parameter names that TrainingArguments expects.\n",
        "\n",
        "### Training Arguments Configuration\n",
        "\n",
        "I create a TrainingArguments object called random_training_args. I set output_dir to \"./random_search_results\" where checkpoints save. I set eval_strategy to \"epoch\" to evaluate after each epoch. I set save_strategy to \"epoch\" to save checkpoints after each epoch.\n",
        "\n",
        "I set load_best_model_at_end to True to keep the best performing model. I set metric_for_best_model to \"f1\" to optimize for F1 score. I set greater_is_better to True since higher F1 is better.\n",
        "\n",
        "I set fp16 to the result of `torch.cuda.is_available()` to use half precision if GPU is available. I set report_to to \"none\" to disable external logging services.\n",
        "\n",
        "I set warmup_steps to 500 to gradually increase learning rate at the start. I set logging_steps to 100 to print progress every 100 steps.\n",
        "\n",
        "### Trainer Initialization\n",
        "\n",
        "I create a WeightedTrainer instance called random_trainer. I pass model_init as a function reference, not a model instance. This lets the trainer create a fresh model for each trial.\n",
        "\n",
        "I pass random_training_args as the args parameter. I pass train_ds and val_ds as the datasets. I pass compute_metrics as the metrics function. I pass tokenizer for text processing.\n",
        "\n",
        "### Execution Tracking\n",
        "\n",
        "I print messages indicating Random Search is starting. I print that it will run 6 trials. I print that it explores continuous ranges efficiently.\n",
        "\n",
        "I call `time.time()` to record the start time. I store this in random_start_time.\n",
        "\n",
        "### Running Hyperparameter Search\n",
        "\n",
        "I call `hyperparameter_search()` on the trainer. I set backend to \"optuna\" to use Optuna for optimization. I pass random_search_hp_space as the hp_space parameter. This function defines which hyperparameters to optimize.\n",
        "\n",
        "I set direction to \"maximize\" since I want the highest F1 score. I set n_trials to 6 to run six different hyperparameter combinations.\n",
        "\n",
        "The method returns the best trial object. I store this in random_best_trial.\n",
        "\n",
        "### Time Calculation\n",
        "\n",
        "I call `time.time()` again to get the end time. I store this in random_end_time. I subtract random_start_time from random_end_time to get the total duration. I store this in random_total_time.\n",
        "\n",
        "### Results Display\n",
        "\n",
        "I print a completion message with the total time formatted to two decimal places. I check if random_best_trial exists. If it does, I print the trial object. I extract hyperparameters using the `.hyperparameters` attribute. I store these in random_best_hps.\n",
        "\n",
        "I loop through the hyperparameters dictionary using `.items()`. I print each key and value pair. I print the best F1 score using the `.objective` attribute.\n",
        "\n",
        "If random_best_trial does not exist, I print an error message and set random_best_hps to an empty dictionary. This prevents errors in later cells.\n"
      ],
      "metadata": {
        "id": "U4VEctTDNlJg"
      },
      "id": "U4VEctTDNlJg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2885c88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "a2885c88",
        "outputId": "fc61e665-e444-4d16-b82c-b8e7b56caa3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing Random Search results for Excel logging...\n",
            "Note: Individual trial extraction may be limited by transformers library.\n",
            "Best trial results will be logged to Excel with full metrics.\n",
            "Creating summary and Excel log sheet...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random_best_trial' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1257476675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Random Search Summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mrandom_best_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     summary_data.append({\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m\"Search_Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Random Search (Automated)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random_best_trial' is not defined"
          ]
        }
      ],
      "source": [
        "# Prepare Random Search results for Excel logging\n",
        "# Note: Individual trial extraction is limited by transformers library\n",
        "# We'll log the best trial results with full metrics\n",
        "\n",
        "print(\"Preparing Random Search results for Excel logging...\")\n",
        "print(\"Note: Individual trial extraction may be limited by transformers library.\")\n",
        "print(\"Best trial results will be logged to Excel with full metrics.\")\n",
        "print(\"Creating summary and Excel log sheet...\")\n",
        "\n",
        "# Create summary data for Excel logging\n",
        "# Since we can't easily extract all individual trials from hyperparameter_search,\n",
        "# we'll create a summary with the best Random Search results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create summary data for Excel\n",
        "summary_data = []\n",
        "\n",
        "# Random Search Summary\n",
        "if random_best_trial:\n",
        "    summary_data.append({\n",
        "        \"Search_Type\": \"Random Search (Automated)\",\n",
        "        \"Best_F1_Score\": random_best_trial.objective,\n",
        "        \"Best_Learning_Rate\": random_best_hps.get(\"learning_rate\", \"N/A\"),\n",
        "        \"Best_Batch_Size\": random_best_hps.get(\"per_device_train_batch_size\", \"N/A\"),\n",
        "        \"Best_Weight_Decay\": random_best_hps.get(\"weight_decay\", \"N/A\"),\n",
        "        \"Best_Epochs\": random_best_hps.get(\"num_train_epochs\", \"N/A\"),\n",
        "        \"Total_Trials\": 6,  # Updated for fast config\n",
        "        \"Total_Time_Seconds\": random_total_time,\n",
        "        \"Time_Per_Trial_Seconds\": random_total_time / 6,\n",
        "        \"Strategy\": \"Random Sampling - Continuous ranges\",\n",
        "        \"Member_Number\": MEMBER_NUMBER\n",
        "    })\n",
        "\n",
        "if summary_data:\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(\"\\n=== RANDOM SEARCH SUMMARY ===\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    print(\"\\nNote: This will be compared to Exercise F2 manual experiments in the Excel file.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Random Search did not complete. Please run Random Search first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code section, I create an Excel workbook using Workbook() and set ws.title to name the sheet. I define styling with PatternFill() and Font(), then use enumerate() to loop through headers, writing each with ws.cell() and applying Alignment(). I record best trial data in row 2 using ws.cell(), extracting values with .get() and formatting timestamps with datetime.now().strftime(). I create a second sheet using wb.create_sheet(), build a comparison_data list with .append(), calculate efficiency with conditional logic, then write data using nested enumerate() loops. I add notes by incrementing notes_row and setting .font property, implement auto-width adjustment by iterating through ws.columns with try-except and setting ws.column_dimensions[col_letter].width. Finally, I generate filename with f-string, save with wb.save(), and use try-except blocks to handle files.download() with ImportError exceptions."
      ],
      "metadata": {
        "id": "KZkAd0NhDmU1"
      },
      "id": "KZkAd0NhDmU1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273a6e28",
      "metadata": {
        "id": "273a6e28"
      },
      "outputs": [],
      "source": [
        "# Create Excel log sheet for Random Search only\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"F3_Random_Search_Results\"\n",
        "\n",
        "# Header styling\n",
        "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "header_font = Font(bold=True, color=\"FFFFFF\")\n",
        "\n",
        "# Write headers\n",
        "headers = [\n",
        "    \"Member\", \"Trial #\", \"Learning Rate\", \"Batch Size\", \"Weight Decay\",\n",
        "    \"Epochs\", \"F1 Score\", \"Accuracy\", \"Precision\", \"Recall\",\n",
        "    \"Training Time (s)\", \"Timestamp\"\n",
        "]\n",
        "\n",
        "for col_idx, header in enumerate(headers, 1):\n",
        "    cell = ws.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "row = 2\n",
        "\n",
        "# Add Random Search best result\n",
        "if random_best_trial:\n",
        "    ws.cell(row=row, column=1, value=f\"Member {MEMBER_NUMBER}\")  # Use member number from config\n",
        "    ws.cell(row=row, column=2, value=\"Best\")\n",
        "    ws.cell(row=row, column=3, value=random_best_hps.get(\"learning_rate\", \"N/A\"))\n",
        "    ws.cell(row=row, column=4, value=random_best_hps.get(\"per_device_train_batch_size\", \"N/A\"))\n",
        "    ws.cell(row=row, column=5, value=random_best_hps.get(\"weight_decay\", \"N/A\"))\n",
        "    ws.cell(row=row, column=6, value=random_best_hps.get(\"num_train_epochs\", \"N/A\"))\n",
        "    ws.cell(row=row, column=7, value=random_best_trial.objective)\n",
        "    ws.cell(row=row, column=11, value=random_total_time)\n",
        "    ws.cell(row=row, column=12, value=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "    row += 1\n",
        "\n",
        "# Add comparison sheet (Random Search vs Exercise F2)\n",
        "ws2 = wb.create_sheet(\"Comparison_Analysis\")\n",
        "\n",
        "comparison_headers = [\n",
        "    \"Metric\", \"Random Search (Automated)\", \"Exercise F2 (Manual)\", \"Notes\"\n",
        "]\n",
        "\n",
        "for col_idx, header in enumerate(comparison_headers, 1):\n",
        "    cell = ws2.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "# Comparison data (you'll need to add Exercise F2 best F1 score manually)\n",
        "comparison_data = []\n",
        "\n",
        "if random_best_trial:\n",
        "    comparison_data.append([\n",
        "        \"Best F1 Score\",\n",
        "        f\"{random_best_trial.objective:.4f}\",\n",
        "        \"Add Exercise F2 best F1 here\",\n",
        "        \"Random Search uses automated optimization\"\n",
        "    ])\n",
        "\n",
        "    comparison_data.append([\n",
        "        \"Total Time (seconds)\",\n",
        "        f\"{random_total_time:.2f}\",\n",
        "        \"Add Exercise F2 total time here\",\n",
        "        \"Time for 6 automated trials\"\n",
        "    ])\n",
        "\n",
        "    # Efficiency\n",
        "    random_efficiency = random_best_trial.objective / random_total_time if random_total_time > 0 else 0\n",
        "    comparison_data.append([\n",
        "        \"Efficiency (F1/Time)\",\n",
        "        f\"{random_efficiency:.6f}\",\n",
        "        \"Calculate from F2\",\n",
        "        \"Higher is better\"\n",
        "    ])\n",
        "\n",
        "# Write comparison data\n",
        "for row_idx, data in enumerate(comparison_data, 2):\n",
        "    for col_idx, value in enumerate(data, 1):\n",
        "        ws2.cell(row=row_idx, column=col_idx, value=value)\n",
        "\n",
        "# Add analysis notes\n",
        "notes_row = len(comparison_data) + 3\n",
        "ws2.cell(row=notes_row, column=1, value=\"Analysis Notes:\").font = Font(bold=True)\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"1. Random Search uses automated hyperparameter optimization\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"2. Exercise F2 used manual hyperparameter tuning\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"3. Random Search can explore continuous hyperparameter ranges\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"4. Efficiency = Best F1 Score / Total Time\")\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min(max_length + 2, 30)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "excel_filename = f\"Exercise_F3_Random_Search{MEMBER_NUMBER}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "wb.save(excel_filename)\n",
        "\n",
        "print(f\"\\n‚úÖ Excel log saved: {excel_filename}\")\n",
        "print(f\"   - Sheet 1: F3_Random_Search_Results\")\n",
        "print(f\"   - Sheet 2: Comparison_Analysis (vs Exercise F2)\")\n",
        "\n",
        "# Automatically download the file\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(excel_filename)\n",
        "    print(f\"‚úÖ File automatically downloaded: {excel_filename}\")\n",
        "except ImportError:\n",
        "    print(\"Note: Not running in Google Colab. File saved locally.\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not auto-download. File saved at: {excel_filename}\")\n",
        "    print(f\"   Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ba6f60fe7cb44cd92d7c98cca0a6cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48d0d13207dc4243985d103955ad4f10",
              "IPY_MODEL_36d4db76c7de4e0f8b8e3daa4de17a5e",
              "IPY_MODEL_0edae4f812a14e95bab49b89dc428c73"
            ],
            "layout": "IPY_MODEL_1b64c260b8064a149c13e677aa7fc4ed"
          }
        },
        "48d0d13207dc4243985d103955ad4f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae36ca4f029403ca1c3bc30f7d099a4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e552a0be5c104eba9a8a7d018284ad67",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "36d4db76c7de4e0f8b8e3daa4de17a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1c5662e8604f9f991e35aa20c36ccb",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef285c23880749f2ab85297eb6f0a75b",
            "value": 435778770
          }
        },
        "0edae4f812a14e95bab49b89dc428c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a8b577fb8a4081ae61fced53d895fa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f51d16be8d64181a4117074654c097d",
            "value": "‚Äá436M/436M‚Äá[00:07&lt;00:00,‚Äá65.9MB/s]"
          }
        },
        "1b64c260b8064a149c13e677aa7fc4ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae36ca4f029403ca1c3bc30f7d099a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e552a0be5c104eba9a8a7d018284ad67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1c5662e8604f9f991e35aa20c36ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef285c23880749f2ab85297eb6f0a75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7a8b577fb8a4081ae61fced53d895fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f51d16be8d64181a4117074654c097d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6096822f4acb41e2943d33b574e7f914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3816d14891d44a5d916885ec5e6e6002",
              "IPY_MODEL_125a63e81f114aac852cb6db07ad0c19",
              "IPY_MODEL_754b162c62234982afe3261a2dd460bb"
            ],
            "layout": "IPY_MODEL_ac85e4957b5f4e0997599d3409b819e9"
          }
        },
        "3816d14891d44a5d916885ec5e6e6002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3058b5edbe412da6b19f82bf4f6287",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8ceff8b00eec4d7a97866cc31361f9e7",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "125a63e81f114aac852cb6db07ad0c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef5a75a8460549e4b3cf3852179673cd",
            "max": 435755888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81c6f4d837824e7db4a0e98d20f42595",
            "value": 435755888
          }
        },
        "754b162c62234982afe3261a2dd460bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ec4a07e3644ca6b9d7edb01676068f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_abbcbec04a1f42f9a981020f9c03818c",
            "value": "‚Äá436M/436M‚Äá[00:06&lt;00:00,‚Äá165MB/s]"
          }
        },
        "ac85e4957b5f4e0997599d3409b819e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3058b5edbe412da6b19f82bf4f6287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ceff8b00eec4d7a97866cc31361f9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef5a75a8460549e4b3cf3852179673cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c6f4d837824e7db4a0e98d20f42595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ec4a07e3644ca6b9d7edb01676068f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbcbec04a1f42f9a981020f9c03818c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "999794d9dc1f45579cd68b7448defe46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb899f7994c44e3ba8f5e502f2979d12",
              "IPY_MODEL_7ab3e5fda5b14692aff869ec6bcaa7c7",
              "IPY_MODEL_ccec06a293d14573be29ace5133709ba"
            ],
            "layout": "IPY_MODEL_ac25cc9d9c4b48fe906110a088adc916"
          }
        },
        "cb899f7994c44e3ba8f5e502f2979d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93522690c527483986d1ce018f04f41b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e9d18e9031ae48fd97234a20d42615ce",
            "value": "config.json:‚Äá100%"
          }
        },
        "7ab3e5fda5b14692aff869ec6bcaa7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba037034a74841489175f491c76e9c7f",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15d8a61e45974dd9a9800e7c1b5b23b5",
            "value": 483
          }
        },
        "ccec06a293d14573be29ace5133709ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6cdf225abc4f489566b3ce46f5f7b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ffba3d41d2804daa8b10fe6bf9d9be5e",
            "value": "‚Äá483/483‚Äá[00:00&lt;00:00,‚Äá45.0kB/s]"
          }
        },
        "ac25cc9d9c4b48fe906110a088adc916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93522690c527483986d1ce018f04f41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d18e9031ae48fd97234a20d42615ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba037034a74841489175f491c76e9c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d8a61e45974dd9a9800e7c1b5b23b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db6cdf225abc4f489566b3ce46f5f7b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffba3d41d2804daa8b10fe6bf9d9be5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eff2aa5df68d417eb1e1b63b025dd42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_147cd739a7c54b53af129d7ed96401e0",
              "IPY_MODEL_224b97ab877b4b3e9611c128d8aabc2f",
              "IPY_MODEL_e3bc107e6b634be8b85d1337460c588f"
            ],
            "layout": "IPY_MODEL_93401829fc4e4cbfaa170d013325a724"
          }
        },
        "147cd739a7c54b53af129d7ed96401e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50950d22e7c45639459e5bd91998e35",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a884bc575354b56b0e117e96b76bb0a",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "224b97ab877b4b3e9611c128d8aabc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbaad6baed5f4ef89b300b5195c5eaab",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7d17291b0fa49ecb3a4e8bbd0382bd4",
            "value": 267954768
          }
        },
        "e3bc107e6b634be8b85d1337460c588f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29fcc61ae624f1a88a1e8d5b21c2f56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b186f831705d4fbfbd5d1ec91d0176d5",
            "value": "‚Äá268M/268M‚Äá[00:09&lt;00:00,‚Äá23.5MB/s]"
          }
        },
        "93401829fc4e4cbfaa170d013325a724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50950d22e7c45639459e5bd91998e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a884bc575354b56b0e117e96b76bb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbaad6baed5f4ef89b300b5195c5eaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d17291b0fa49ecb3a4e8bbd0382bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a29fcc61ae624f1a88a1e8d5b21c2f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b186f831705d4fbfbd5d1ec91d0176d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1d0cdaf24a44da9cb46f18dba4472e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36435456910146b8a6e81063cc4d4a2c",
              "IPY_MODEL_faf1b1bc620047b69bcf98f5414e6cb4",
              "IPY_MODEL_f1655280c6594305bb464fa45b9353c2"
            ],
            "layout": "IPY_MODEL_e893cfa2279b412283d182362cf8ccf4"
          }
        },
        "36435456910146b8a6e81063cc4d4a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edef40bdde744175953db1868655544c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1163a92422254997b00c18b226777a18",
            "value": "config.json:‚Äá100%"
          }
        },
        "faf1b1bc620047b69bcf98f5414e6cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5db71f7f9744cc5b528c2e6bb1bb005",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c1d2db435e443e09cf79f039cd15895",
            "value": 385
          }
        },
        "f1655280c6594305bb464fa45b9353c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f33e1990bca41c4a466664bc5702ee7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_54480187dfe14ccbb342d776de773ce9",
            "value": "‚Äá385/385‚Äá[00:00&lt;00:00,‚Äá29.5kB/s]"
          }
        },
        "e893cfa2279b412283d182362cf8ccf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edef40bdde744175953db1868655544c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1163a92422254997b00c18b226777a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5db71f7f9744cc5b528c2e6bb1bb005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1d2db435e443e09cf79f039cd15895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f33e1990bca41c4a466664bc5702ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54480187dfe14ccbb342d776de773ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108304913e1247f9bd4e55e7604879e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef73ee4716e04b39a5e6ec83ca098134",
              "IPY_MODEL_c60010d438b84d028f7396c41c9b3080",
              "IPY_MODEL_879e024698e74051b6e3ef539bc84cd9"
            ],
            "layout": "IPY_MODEL_0ac26a23895546f89cabca752fd6d544"
          }
        },
        "ef73ee4716e04b39a5e6ec83ca098134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc38b5222eb04b05ae1ce3abc1eb82eb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53c9e5eb4bb648e0a7a4bf06b39a865a",
            "value": "vocab.txt:‚Äá"
          }
        },
        "c60010d438b84d028f7396c41c9b3080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99db89e25f4c4201a226a6caf6480638",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bcd2dc7b3ab47e4b213c29f922ebadc",
            "value": 1
          }
        },
        "879e024698e74051b6e3ef539bc84cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b293c32fd146b883279cb6fc71996d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6aaa2eed39354362947d7387cce4b190",
            "value": "‚Äá213k/?‚Äá[00:00&lt;00:00,‚Äá6.18MB/s]"
          }
        },
        "0ac26a23895546f89cabca752fd6d544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc38b5222eb04b05ae1ce3abc1eb82eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53c9e5eb4bb648e0a7a4bf06b39a865a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99db89e25f4c4201a226a6caf6480638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5bcd2dc7b3ab47e4b213c29f922ebadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38b293c32fd146b883279cb6fc71996d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aaa2eed39354362947d7387cce4b190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}