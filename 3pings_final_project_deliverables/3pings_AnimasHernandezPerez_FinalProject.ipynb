{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "lOwoPghthZ2K",
      "metadata": {
        "id": "lOwoPghthZ2K"
      },
      "source": [
        "## 0) Setup (libraries and reproducibility)\n",
        "\n",
        "**Function Description:**\n",
        "This cell initializes the environment by importing all necessary libraries and setting up reproducibility controls. It loads tools for data manipulation, machine learning, and deep learning, then configures random seeds to ensure consistent results across multiple runs.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The imports follow a logical grouping pattern. Standard Python libraries like `os`, `math`, and `random` come first, followed by numerical computing tools (`numpy`, `pandas`), and finally the deep learning stack (`torch`, `transformers`, `sklearn`). The `AutoTokenizer` and `AutoModelForSequenceClassification` are convenience classes from Hugging Face that automatically detect and load the correct model architecture based on the checkpoint name you provide. The `TrainingArguments` class acts as a container for all training hyperparameters, while `Trainer` wraps the training loop and handles evaluation, logging, and checkpointing automatically. I set the random seed using `random.seed()`, `np.random.seed()`, `torch.manual_seed()`, and `torch.cuda.manual_seed_all()` to control randomness across all libraries. The device detection uses `torch.cuda.is_available()` to check for GPU availability.\n",
        "\n",
        "**Inputs:**\n",
        "This cell takes no external inputs. It operates on the Python environment itself, importing modules that are either built-in or installable via pip. The SEED value (42) is hardcoded as a constant.\n",
        "\n",
        "**Outputs:**\n",
        "You'll see a single print statement showing which device you're using - \"cuda\" if a GPU is available, \"cpu\" otherwise. This confirmation helps you understand whether training will be fast (GPU) or slow (CPU). GPU training can be 10-50x faster than CPU training for transformer models.\n",
        "\n",
        "**Code Flow:**\n",
        "The cell progresses from general to specific imports, starting with basic Python utilities and ending with specialized deep learning components. After imports, it sets reproducibility seeds across all random number generators. Finally, it detects and prints the compute device. This setup happens once at the beginning and affects all subsequent cells.\n",
        "\n",
        "**Comments and Observations:**\n",
        "Reproducibility is important for scientific experiments and debugging. Without setting seeds, you'd get different train/test splits and different model initializations each time you run the notebook, making it impossible to compare results. The seed value 42 is arbitrary but conventional in machine learning tutorials. GPU availability dramatically impacts training time - a full fine-tuning run that takes 3 hours on CPU might finish in 15 minutes on a GPU. If you're running on Google Colab, make sure you've enabled GPU in Runtime > Change runtime type > Hardware accelerator > GPU. The imports might take 10-30 seconds the first time you run them because Colab needs to load the libraries into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z1V0utC5hZ2L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1V0utC5hZ2L",
        "outputId": "c24ee66c-2c02-420c-955d-34ce0514fedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Every import has an explanatory comment.\n",
        "import os                         # file paths and environment checks\n",
        "import math                       # math helpers (may be useful for schedules)\n",
        "import random                     # Python's RNG for reproducibility\n",
        "import numpy as np                # numerical arrays and metrics support\n",
        "import pandas as pd               # data loading and manipulation\n",
        "from pathlib import Path          # convenient and robust path handling\n",
        "\n",
        "# Hugging Face / PyTorch stack (for transformer fine‚Äëtuning)\n",
        "import torch                      # tensor and GPU utilities\n",
        "from datasets import Dataset      # lightweight dataset wrapper around pandas\n",
        "from transformers import (       # core HF components for tokenization and training\n",
        "    AutoTokenizer,               # auto‚Äëloads the right tokenizer for a given model checkpoint\n",
        "    AutoModelForSequenceClassification,  # classification head on top of a transformer\n",
        "    TrainingArguments,           # training hyperparameters container\n",
        "    Trainer                      # training loop helper (handles eval and logging)\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Make runs reproducible (seed Python, NumPy, and PyTorch)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Detect device once and print for visibility\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")  # shows 'cuda' when a GPU is available in Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EGXgy5Be9SIS",
      "metadata": {
        "id": "EGXgy5Be9SIS"
      },
      "source": [
        "## 1) Load Dataset\n",
        "\n",
        "**Function Description:**\n",
        "This cell handles the complete data loading pipeline, from file upload through data cleaning and label encoding. It prompts you to upload a CSV file, validates the required columns, removes any problematic rows, and converts text labels into numerical format that machine learning models can process.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The `files.upload()` function from `google.colab` opens a browser file picker that lets you select a CSV from your computer. I capture the uploaded file using `list(uploaded.keys())[0]` which grabs the filename from the dictionary returned by the upload function. The `Path` object creates a cross-platform file path that works on Windows, Mac, and Linux. After loading with `pd.read_csv()`, I use `assert` to verify that both 'statement' and 'status' columns exist - if they don't, the code stops with an error message showing which columns are missing. The `dropna()` method removes any rows where either the text or label is missing, and `copy()` creates a new DataFrame to avoid pandas warnings about modifying views. Converting the statement column with `astype(str)` ensures all entries are strings, even if some got parsed as numbers. The `LabelEncoder` from sklearn automatically creates a mapping from unique text labels to integers (0, 1, 2, etc.) using `fit_transform()`. I temporarily store the encoded values in a new column, then replace the original status column and drop the temporary one.\n",
        "\n",
        "**Inputs:**\n",
        "You provide a CSV file through the browser upload dialog. The CSV must contain at least two columns: 'statement' with the text you want to classify (like \"I feel overwhelmed and can't cope\"), and 'status' with the mental health label (like \"Stress\", \"Anxiety\", \"Normal\"). The labels can be text strings or already-encoded numbers. If you have extra columns like 'Unnamed: 0' (a common artifact from saving DataFrames), they won't break anything.\n",
        "\n",
        "**Outputs:**\n",
        "You'll see several outputs: a confirmation message showing the file path, the label encoding map (which number represents which condition), the count of samples per class, and the first three rows of your cleaned dataset. The label encoding map is particularly important because you'll need it later to interpret predictions - if the model predicts \"5\", you need to know that means \"Stress\". The value counts reveal class imbalance, which affects how you should train your model.\n",
        "\n",
        "**Code Flow:**\n",
        "The flow moves through four distinct phases. First, file upload and path resolution. Second, loading and validation (checking for required columns). Third, data cleaning (removing nulls, ensuring correct data types). Fourth, label encoding (converting text to numbers) with the final reassignment of the status column. Each step depends on the previous one succeeding, which is why I use assertions for critical validations.\n",
        "\n",
        "**Comments and Observations:**\n",
        "Class imbalance is probably your biggest challenge here. If you see something like 16,343 Normal samples but only 1,077 Personality Disorder samples, your model will naturally bias toward predicting Normal because it sees that class 15 times more often. This is why I use class weights in later sections. The `LabelEncoder` assigns numbers alphabetically by default, so \"Anxiety\" becomes 0, \"Bipolar\" becomes 1, and so on. This alphabetical ordering doesn't affect model performance but does affect how you read the results. Some datasets have text encoding issues (weird characters, emojis) that can cause problems during tokenization. If you see strange symbols in the data preview, you might need to add encoding='utf-8' or encoding='latin-1' to the `read_csv()` call. The label encoder will fail if your status column has typos (like \"Stres\" vs \"Stress\") because it treats them as different classes. Always check your label counts to catch these issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CMBpEom1hZ2M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "CMBpEom1hZ2M",
        "outputId": "ffefe453-bee9-4455-b2a9-a1989b4831e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf3ff999-6ebc-432a-95a4-0bb5ff6f32e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf3ff999-6ebc-432a-95a4-0bb5ff6f32e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Combined Data.csv to Combined Data.csv\n",
            "‚úÖ File uploaded successfully: /content/Combined Data.csv\n",
            "üî§ Label encoding map:\n",
            "  0 ‚Üí Anxiety\n",
            "  1 ‚Üí Bipolar\n",
            "  2 ‚Üí Depression\n",
            "  3 ‚Üí Normal\n",
            "  4 ‚Üí Personality disorder\n",
            "  5 ‚Üí Stress\n",
            "  6 ‚Üí Suicidal\n",
            "\n",
            "‚úÖ Dataset loaded and label-encoded successfully!\n",
            "status\n",
            "3    16343\n",
            "2    15404\n",
            "6    10652\n",
            "0     3841\n",
            "1     2777\n",
            "5     2587\n",
            "4     1077\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                          statement  status\n",
              "0           0                                         oh my gosh       0\n",
              "1           1  trouble sleeping, confused mind, restless hear...       0\n",
              "2           2  All wrong, back off dear, forward doubt. Stay ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8184d1c4-7526-4587-ab13-2ce049d06bb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8184d1c4-7526-4587-ab13-2ce049d06bb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8184d1c4-7526-4587-ab13-2ce049d06bb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8184d1c4-7526-4587-ab13-2ce049d06bb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a6c1769-03f6-4326-b443-806e3e380b7a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a6c1769-03f6-4326-b443-806e3e380b7a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a6c1769-03f6-4326-b443-806e3e380b7a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52681,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15235,\n        \"min\": 0,\n        \"max\": 53042,\n        \"num_unique_values\": 52681,\n        \"samples\": [\n          3008,\n          44705,\n          50186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51073,\n        \"samples\": [\n          \"he's been a chain smoker for 30 years.\",\n          \"Dependence on therapist I attend IOP groups and individual therapy sessions at the same place, my therapist who I have worked with on and off for a year and a couple months just told me today that she is leaving soon and I am heartbroken. I love my therapist and I don't know how I am going to keep progressing without her. There will be a replacement for her but idk what to do, I don't want a different therapist. :(\",\n          \"These feelings constantly come back. Someone from my past that hurt me came back a month ago and once again disrespected me and i just feel like shit. Idk why these feelings keep resurfacing but it just hurts. I do not want to be over dramatic but Its hurts when you were nothing but loving/kind to someone and they disrespect you. I just hate feeling like this, feeling like i cannot trust anyone or that no one would ever truly love me unless i have something to offer. I am always worried about my looks and its just making me depressed. I really do not feel like i fit in with the world I am just here. Idk what my next step should be to get help but I am really going through it. (Yes I am in therapy) but how do i help myself ? I have been depressed/anxious for years and most day i do not even leave my house. But nobody around me seems to care and honestly I am tired of feeling this way. But at the same time i do not want to give up on myself bc i feel like I am here to be somebody great. I am just trying to find my way right now. It keeps coming back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# --- Load Dataset (Upload version, auto-encodes text labels) ---\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÇ Please upload your dataset CSV (e.g., Combined Data.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Automatically pick the first uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "csv_path = Path(f\"/content/{filename}\")\n",
        "\n",
        "print(f\"‚úÖ File uploaded successfully: {csv_path}\")\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# --- Validate columns ---\n",
        "expected_cols = {'statement', 'status'}\n",
        "assert expected_cols.issubset(df.columns), f\"‚ùå Missing required columns: {expected_cols - set(df.columns)}\"\n",
        "\n",
        "# --- Clean ---\n",
        "df = df.dropna(subset=['statement', 'status']).copy()\n",
        "df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "# --- Encode text labels into integers ---\n",
        "# This maps each unique label (like 'Anxiety', 'Stress', etc.) to a numeric ID\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['status_encoded'] = le.fit_transform(df['status'])\n",
        "\n",
        "# Optional: print mapping for your reference\n",
        "print(\"üî§ Label encoding map:\")\n",
        "for label, code in zip(le.classes_, range(len(le.classes_))):\n",
        "    print(f\"  {code} ‚Üí {label}\")\n",
        "\n",
        "# Replace 'status' with the encoded version\n",
        "df['status'] = df['status_encoded']\n",
        "df.drop(columns=['status_encoded'], inplace=True)\n",
        "\n",
        "print(\"\\n‚úÖ Dataset loaded and label-encoded successfully!\")\n",
        "print(df['status'].value_counts(dropna=False))\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g0kKhn-N9Ydz",
      "metadata": {
        "id": "g0kKhn-N9Ydz"
      },
      "source": [
        "## 2) Baseline Models (TF-IDF + Linear)\n",
        "\n",
        "**Function Description:**\n",
        "This cell establishes performance baselines using traditional machine learning before moving to deep learning. It splits your data, converts text to numerical features using TF-IDF, trains two simple linear models (Logistic Regression and Linear SVM), and reports their accuracy, precision, recall, and F1 scores.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The `train_test_split()` function from sklearn divides your data into 80% training and 20% validation using the random state 42 for reproducibility. The `stratify` parameter ensures both sets maintain the same class distribution as your original data. `TfidfVectorizer` converts text into numbers by analyzing word frequencies - the `ngram_range=(1,2)` parameter means it considers both individual words and two-word phrases, `min_df=2` ignores words appearing in fewer than 2 documents (filtering out typos and rare terms), and `max_features=40000` keeps only the 40,000 most informative features. The vectorizer's `fit_transform()` learns the vocabulary from training data and converts it to features in one step, while `transform()` applies that learned vocabulary to validation data without learning anything new. Both `LogisticRegression` and `LinearSVC` use `class_weight=\"balanced\"` which automatically adjusts for class imbalance by computing weights inversely proportional to class frequencies. The `precision_recall_fscore_support()` function calculates all metrics at once, and the `average` parameter determines how to aggregate across multiple classes (weighted average accounts for class imbalance).\n",
        "\n",
        "**Inputs:**\n",
        "This cell takes the cleaned DataFrame from the previous section and specifically uses the 'statement' column (text) as features and 'status' column (labels) as targets. The `train_test_split()` randomly selects which samples go into training vs validation based on the test_size ratio and random seed.\n",
        "\n",
        "**Outputs:**\n",
        "You get performance metrics for both baseline models printed in a compact format showing accuracy, precision, recall, and F1 score. The cell also prints which averaging method it's using (binary for 2 classes, weighted for more than 2) based on automatic detection of the number of unique classes. Typical baseline scores range from 75-85% accuracy depending on your data quality and class separability.\n",
        "\n",
        "**Code Flow:**\n",
        "The code follows a standard machine learning pipeline. First, split the data to create independent train and test sets. Second, fit the TF-IDF vectorizer on training text and transform both sets. Third, train the first model (Logistic Regression), make predictions, and calculate metrics. Fourth, repeat the training and evaluation process for the second model (Linear SVM). The vectorizer must be fit before the classifiers because the classifiers need fixed-size numerical inputs.\n",
        "\n",
        "**Comments and Observations:**\n",
        "These baseline models serve two purposes: they give you a performance floor that deep learning should beat, and they train in seconds rather than hours, letting you quickly spot data quality issues. If your baseline F1 is below 60%, something's wrong with your data (mislabeled samples, too much noise, or the classes aren't actually distinguishable from text alone). TF-IDF works surprisingly well for text classification because it captures which words are distinctive for each class. For example, the word \"overwhelmed\" might appear frequently in stress-related texts but rarely in normal texts, giving it high TF-IDF weight. The ngram_range=(1,2) parameter helps capture phrases like \"panic attack\" or \"feel good\" that carry more meaning than individual words. Linear models like Logistic Regression are also interpretable - you could examine the feature weights to see which words most strongly predict each class. The max_features limit prevents the feature space from exploding (some datasets have 100k+ unique words) and also acts as regularization by forcing the model to focus on the most informative terms. SVM typically performs slightly better than Logistic Regression on text because it finds the maximum-margin decision boundary, but both usually give similar results. If SVM and Logistic Regression give very different scores (more than 5% gap), that suggests your data has complex class boundaries that might benefit from deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k4IjGl_JhZ2M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4IjGl_JhZ2M",
        "outputId": "f6e4ba5a-b7c8-44a4-e229-c4e69a7d9c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA SPLIT SUMMARY\n",
            "================================================================================\n",
            "Training set:   36,875 samples (70.0%)\n",
            "Validation set: 7,903 samples (15.0%)\n",
            "Test set:       7,903 samples (15.0%)\n",
            "Total:          52,681 samples\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Ground-Truth Test Set exported to: Ground_Truth_Test_Set_Final_Version_20251119_115238.csv\n",
            "‚úÖ Ground-Truth Test Set (with labels) exported to: Ground_Truth_Test_Set_Final_Version_With_Labels_20251119_115238.csv\n",
            "\n",
            "‚ö†Ô∏è  IMPORTANT: The test set is held-out for final evaluation only!\n",
            "   Do not use it for training, validation, or hyperparameter tuning.\n",
            "================================================================================\n",
            "Detected 7 classes ‚Üí using average='weighted' for metrics.\n",
            "\n",
            "[Baseline-LR] Acc=0.779  P=0.785  R=0.779  F1=0.777\n",
            "[Baseline-SVM] Acc=0.789  P=0.786  R=0.789  F1=0.786\n"
          ]
        }
      ],
      "source": [
        "# --- Baseline Models (TF-IDF + Linear, supports multi-class) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# Three-Way Data Split: Train / Validation / Ground-Truth Test Set\n",
        "# ============================================================================\n",
        "# Split: 70% train, 15% validation, 15% held-out test set (for final evaluation)\n",
        "# ============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration\n",
        "TRAIN_SIZE = 0.70\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Ground truth test set metadata\n",
        "GROUND_TRUTH_TEST_SET = {\n",
        "    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'description': 'Held-out test set for final model evaluation. Do not use for training or validation.',\n",
        "    'split_ratio': f'Train: {TRAIN_SIZE*100:.0f}%, Validation: {VAL_SIZE*100:.0f}%, Test: {TEST_SIZE*100:.0f}%',\n",
        "    'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "# First split: Separate out the test set (15%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    df['statement'].values,\n",
        "    df['status'].values,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=df['status'].values\n",
        ")\n",
        "\n",
        "# Second split: Split remaining data into train (70%) and validation (15%)\n",
        "val_ratio = VAL_SIZE / (TRAIN_SIZE + VAL_SIZE)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=val_ratio,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Print split summary\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA SPLIT SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Training set:   {len(X_train):,} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
        "print(f\"Validation set: {len(X_val):,} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test set:       {len(X_test):,} samples ({len(X_test)/len(df)*100:.1f}%)\")\n",
        "print(f\"Total:          {len(df):,} samples\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Automatic Export: Save Ground-Truth Test Set to CSV\n",
        "test_df = pd.DataFrame({\n",
        "    'statement': X_test,\n",
        "    'status': y_test\n",
        "})\n",
        "test_df['test_set_id'] = range(1, len(test_df) + 1)\n",
        "test_df['created_at'] = GROUND_TRUTH_TEST_SET['created_at']\n",
        "test_df['description'] = GROUND_TRUTH_TEST_SET['description']\n",
        "test_df = test_df[['test_set_id', 'statement', 'status', 'created_at', 'description']]\n",
        "\n",
        "# Save test set with encoded labels\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "csv_filename = f\"Ground_Truth_Test_Set_Final_Version_{timestamp}.csv\"\n",
        "test_df.to_csv(csv_filename, index=False)\n",
        "print(f\"\\n‚úÖ Ground-Truth Test Set exported to: {csv_filename}\")\n",
        "\n",
        "# Also save with original labels if LabelEncoder is available\n",
        "if 'le' in globals():\n",
        "    test_df_with_labels = test_df.copy()\n",
        "    test_df_with_labels['status_label'] = le.inverse_transform(test_df['status'])\n",
        "    csv_filename_labels = f\"Ground_Truth_Test_Set_Final_Version_With_Labels_{timestamp}.csv\"\n",
        "    test_df_with_labels.to_csv(csv_filename_labels, index=False)\n",
        "    print(f\"‚úÖ Ground-Truth Test Set (with labels) exported to: {csv_filename_labels}\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT: The test set is held-out for final evaluation only!\")\n",
        "print(\"   Do not use it for training, validation, or hyperparameter tuning.\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Convert raw text into TF-IDF features\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=40000)\n",
        "Xtr = tfidf.fit_transform(X_train)\n",
        "Xva = tfidf.transform(X_val)\n",
        "\n",
        "# Detect if this is binary or multiclass\n",
        "num_classes = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "print(f\"Detected {num_classes} classes ‚Üí using average='{avg_type}' for metrics.\\n\")\n",
        "\n",
        "# --- Baseline 1: Logistic Regression ---\n",
        "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "logreg.fit(Xtr, y_train)\n",
        "pred_lr = logreg.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_lr, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_lr)\n",
        "print(f\"[Baseline-LR] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n",
        "\n",
        "# --- Baseline 2: Linear SVM ---\n",
        "svm = LinearSVC(class_weight=\"balanced\")\n",
        "svm.fit(Xtr, y_train)\n",
        "pred_svm = svm.predict(Xva)\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val, pred_svm, average=avg_type)\n",
        "acc = accuracy_score(y_val, pred_svm)\n",
        "print(f\"[Baseline-SVM] Acc={acc:.3f}  P={p:.3f}  R={r:.3f}  F1={f:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fSUPDc6_-7JH",
      "metadata": {
        "id": "fSUPDc6_-7JH"
      },
      "source": [
        "## 3) Pre-Trained Models (Tokenization and Dataset Prep)\n",
        "\n",
        "**Function Description:**\n",
        "This cell prepares your text data for transformer models by loading a specialized tokenizer and converting all text into the numerical format that BERT-based models expect. It tokenizes both training and validation texts, then packages them into HuggingFace Dataset objects that work seamlessly with the Trainer API.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "I define two model checkpoint names as constants - `CLINICAL_BERT` points to a model trained on clinical text, while `DISTIL_BERT` points to a smaller, faster baseline. The `AutoTokenizer.from_pretrained()` method downloads and initializes the tokenizer that matches your chosen model architecture. The `tokenize_texts()` helper function takes a list of strings and converts them to token IDs - the `padding=True` parameter adds zeros to shorter sequences so all sequences in a batch have the same length, `truncation=True` cuts off text exceeding the max_length, `max_length=128` sets the sequence limit, and `return_tensors=\"pt\"` formats the output as PyTorch tensors rather than lists. After tokenizing, I use `Dataset.from_dict()` to create HuggingFace datasets, passing dictionaries that contain input_ids (the tokenized text), attention_mask (which positions are real tokens vs padding), and labels (your encoded status values wrapped in `torch.tensor()`).\n",
        "\n",
        "**Inputs:**\n",
        "This cell uses the `X_train`, `X_val`, `y_train`, and `y_val` arrays created by the train_test_split in the previous section. X_train and X_val contain the text statements, while y_train and y_val contain the corresponding numerical labels.\n",
        "\n",
        "**Outputs:**\n",
        "You'll see progress bars as the tokenizer downloads (first run only), then the final line shows the sizes of your train and validation datasets as a tuple like (42144, 10537). This confirms you have roughly 80% of samples in training and 20% in validation. The tokenized datasets are stored in memory as `train_ds` and `val_ds` objects ready for training.\n",
        "\n",
        "**Code Flow:**\n",
        "The flow is straightforward and sequential. First, I define model checkpoints and select one as the default backbone. Second, I load the tokenizer for that backbone. Third, I define a helper function that wraps the tokenizer with specific parameters. Fourth, I apply that function to both train and validation texts. Fifth, I package the tokenized outputs and labels into Dataset objects. This preparation step only happens once before training multiple experiments.\n",
        "\n",
        "**Comments and Observations:**\n",
        "The choice between ClinicalBERT and DistilBERT matters more than you might think. ClinicalBERT was trained on clinical notes, discharge summaries, and medical text, so it understands medical terminology and the way healthcare professionals write. This makes it better suited for mental health classification where text might include clinical terms or formal descriptions. DistilBERT is a compressed version of BERT with 40% fewer parameters - it trains faster and uses less memory but might miss subtle patterns that the full model catches. The max_length=128 setting is a practical choice that balances speed and information retention. Most mental health statements are 20-80 words, which translates to roughly 30-120 tokens after subword tokenization. Setting max_length too high wastes computation on padding, while setting it too low truncates important information. The tokenizer uses subword tokenization, meaning it breaks rare or complex words into pieces - for example, \"unhappiness\" might become [\"un\", \"happiness\"]. This helps the model handle words it's never seen before by understanding their components. The attention_mask is important because it tells the model which tokens are real (value of 1) and which are padding (value of 0), preventing padding tokens from influencing the model's predictions. When you see the tokenizer downloading files, it's fetching the vocabulary file (which maps words to IDs) and the config file (which stores tokenization parameters). These downloads only happen once and get cached locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CJsRDxIlhZ2N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "2743b720cfa14634850fe0e1acbb08f3",
            "e12fd7da736b400e96a6c31289ede30b",
            "74e4de408d2d4147be00cb03b616e1ab",
            "6bc7c2f801844bef8ec14da718224dfd",
            "681ceb51892742d3816774cea2fa615e",
            "4cde5d60a6df4eb99c777577305002d5",
            "410e2d8cda244bb88918e4c17e11f628",
            "df36078f119b4f4c99a5952c54516501",
            "7d8ebc83be1242f69a9cf4b105469d42",
            "8f46d1603caf4ad29f82bbe703c2afc8",
            "cc1991c04d214e31a99d538293d6c421",
            "62e4b067deac465980a7e157429c01f6",
            "282ac484f646432cac9c13edfdf76643",
            "acac9ac7111748a98fb89fd599259783",
            "f8affcff1bd2450c815ad5761c2e0616",
            "1b33d405b5994356b5d1fa4337c86069",
            "6a90e9df04c243f7819a844f10bf1eb2",
            "14440a09ca494a4ab08d2993b26bef05",
            "9f6c015062b44d058748cebcf7804c5a",
            "395dec1199b246c0981e6678d7b5e319",
            "5e29cb7f9c1f4888a057700f9a7052ee",
            "5f60bda6a6f84d189ebbda058b237eac"
          ]
        },
        "id": "CJsRDxIlhZ2N",
        "outputId": "350090e2-93e5-4805-bf13-f9d9fb1345dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2743b720cfa14634850fe0e1acbb08f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62e4b067deac465980a7e157429c01f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36875, 7903)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "# Choose your checkpoints.\n",
        "# We include ClinicalBERT (for clinical text) and DistilBERT (fast baseline).\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "# Pick one as the default backbone for experiments below.\n",
        "BACKBONE = CLINICAL_BERT\n",
        "\n",
        "# Initialize tokenizer for the chosen backbone\n",
        "tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "\n",
        "# Helper to tokenize a pandas series with per-line comments\n",
        "def tokenize_texts(texts, max_length=128):\n",
        "    # Apply the tokenizer: returns dict with input_ids and attention_mask\n",
        "    return tokenizer(\n",
        "        list(texts),                 # a Python list of strings\n",
        "        padding=True,                # pad to the longest in the batch\n",
        "        truncation=True,             # cut off text exceeding max_length\n",
        "        max_length=max_length,       # cap sequence length\n",
        "        return_tensors=\"pt\"          # return PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize train/validation splits\n",
        "train_enc = tokenize_texts(X_train)\n",
        "val_enc   = tokenize_texts(X_val)\n",
        "\n",
        "# Wrap into HF Datasets with labels\n",
        "train_ds = Dataset.from_dict({\n",
        "    \"input_ids\": train_enc[\"input_ids\"],\n",
        "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_train)\n",
        "})\n",
        "val_ds = Dataset.from_dict({\n",
        "    \"input_ids\": val_enc[\"input_ids\"],\n",
        "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_val)\n",
        "})\n",
        "\n",
        "len(train_ds), len(val_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Es8uR0B--FD",
      "metadata": {
        "id": "6Es8uR0B--FD"
      },
      "source": [
        "## 4) Training of Data (Trainer utilities and metrics)\n",
        "\n",
        "**Function Description:**\n",
        "This cell sets up the infrastructure you need for training - specifically the metric computation function and the custom weighted loss. It defines how to evaluate model performance and how to handle class imbalance during training by penalizing mistakes on rare classes more heavily.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The `compute_metrics()` function takes an `eval_pred` tuple containing logits (raw model outputs before softmax) and true labels. Inside the function, `np.argmax(logits, axis=-1)` converts logits to class predictions by selecting the highest value along the last dimension. The `precision_recall_fscore_support()` function calculates all four metrics in one call using the average parameter to specify how to aggregate across classes (binary for 2-class, weighted for multi-class). For class weights, I count how many samples exist in each class using `(y_train == 1).sum()` for the positive class and similar for negative, then compute the weight for the positive class as `neg / max(pos, 1)` which gives higher weight to the minority class. The `max(pos, 1)` prevents division by zero if you somehow have zero positive samples. I create a PyTorch tensor from these weights and move it to the correct device using `.to(device)`. The `WeightedTrainer` class inherits from HuggingFace's `Trainer` and overrides only the `compute_loss()` method. Inside that method, I extract labels from inputs, run the model on the remaining inputs (everything except labels), get the logits from outputs, create a CrossEntropyLoss function with the class weights, and calculate loss by comparing predictions to true labels.\n",
        "\n",
        "**Inputs:**\n",
        "This cell uses `y_train` from the earlier train-test split to compute class frequencies and create weights. The compute_metrics function receives predictions from the Trainer during evaluation, while the WeightedTrainer receives model inputs, labels, and the model itself during training.\n",
        "\n",
        "**Outputs:**\n",
        "You'll see the class weights printed as a list showing the weight for each class. For a binary case with 20,000 negative and 5,000 positive samples, you'd see weights like [1.0, 4.0], meaning the model pays 4x more attention to positive class errors. For multi-class problems with severe imbalance, some weights might be 10x or higher.\n",
        "\n",
        "**Code Flow:**\n",
        "The code sets up two separate but related pieces of infrastructure. First, it defines and prints class weights that quantify the imbalance in your data. Second, it creates a custom Trainer class that uses those weights during loss calculation. These components work together during training - the Trainer calls compute_loss every batch to calculate weighted loss, and calls compute_metrics every epoch to evaluate on the validation set.\n",
        "\n",
        "**Comments and Observations:**\n",
        "Class imbalance is one of the biggest challenges in mental health classification. Without weighting, a model trained on data that's 80% Normal and 20% Other could achieve 80% accuracy by always predicting Normal and completely ignoring the minority classes. Weighted loss forces the model to care about all classes by making errors on rare classes expensive. The math behind class weighting is intuitive - if you have 4x more samples of class A than class B, you give class B a weight of 4.0 so that one mistake on class B costs as much as four mistakes on class A. This balances the gradient updates and prevents the model from ignoring minority classes. CrossEntropyLoss is the standard loss function for classification because it measures the difference between predicted probability distributions and true labels. Adding weights modifies the formula to multiply each sample's loss by its class weight before averaging. The custom Trainer override is necessary because the default Trainer doesn't support class weights out of the box. By inheriting and overriding just the compute_loss method, you keep all the other Trainer functionality (logging, checkpointing, evaluation) while adding custom loss calculation. The `return_outputs` parameter in compute_loss determines whether to return just the loss (for training) or both loss and full model outputs (for when you need predictions), and I handle both cases with the conditional return statement. This weighted approach works well for moderate imbalance (ratios up to 10:1 or 20:1) but for extreme imbalance you might need additional techniques like oversampling the minority class or using focal loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7qBrdq-yIspU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qBrdq-yIspU",
        "outputId": "7888746d-7026-4d88-ede0-787e523185d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data split complete:\n",
            "Train size: 42144 | Validation size: 10537\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your cleaned & encoded dataframe is called df\n",
        "# with columns: 'statement' (text) and 'status' (numeric label)\n",
        "X = df['statement']\n",
        "y = df['status']\n",
        "\n",
        "# Split into 80% train, 20% validation (you can adjust ratio)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data split complete:\")\n",
        "print(f\"Train size: {len(X_train)} | Validation size: {len(X_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_4oBKl6hZ2N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_4oBKl6hZ2N",
        "outputId": "fab7ae3d-fd7a-49c1-dda7-4db42f4fb765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights (neg, pos): [1.0, 1.3836109638214111]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Metric function for the Trainer: computes Accuracy, Precision, Recall, F1\n",
        "def compute_metrics(eval_pred):\n",
        "    # eval_pred is a tuple of (logits, labels)\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Optional: class weights for imbalanced datasets\n",
        "# Compute weights inversely proportional to class frequencies\n",
        "pos = (y_train == 1).sum()\n",
        "neg = (y_train == 0).sum()\n",
        "w_pos = neg / max(pos, 1)   # weight for positive class\n",
        "w_neg = 1.0                 # keep negative as baseline\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float).to(device)\n",
        "print(f\"Class weights (neg, pos): {class_weights.tolist()}\" )\n",
        "\n",
        "# Custom Trainer that injects weighted loss\n",
        "from torch.nn import CrossEntropyLoss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QzUAOSA6-_fL",
      "metadata": {
        "id": "QzUAOSA6-_fL"
      },
      "source": [
        "## 5) Fine-tuning (Three Experiments)\n",
        "\n",
        "**Function Description:**\n",
        "This cell runs three complete fine-tuning experiments with different hyperparameter configurations. It trains transformer models on your data, evaluates them on the validation set, and creates a leaderboard ranking them by F1 score. Each experiment uses different settings for learning rate, batch size, epochs, and model architecture to find the best configuration for your specific dataset.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The code starts by detecting the number of unique classes with `len(np.unique(y_train))` and setting the averaging strategy for metrics accordingly. The `compute_metrics()` function here is similar to Section 4 but adapts to multi-class by using weighted averaging. For class weights, I use `np.bincount(y_train, minlength=num_labels)` which counts occurrences of each class, then compute weights as `counts.max() / np.maximum(counts, 1)` which gives higher weights to rarer classes while avoiding division by zero. The weights become a PyTorch tensor on the correct device. The `WeightedTrainer` class override works identically to Section 4 but now handles the multi-class case properly. The `tokenize_texts()` function accepts a max_length parameter to allow different experiments to use different sequence lengths. The `make_training_args()` function is a factory that creates `TrainingArguments` objects with version compatibility - it first tries the modern signature with `evaluation_strategy` and `save_strategy`, and if that fails (older transformers versions), it falls back to legacy parameters like `do_eval`. The `run_experiment()` function orchestrates everything: it re-tokenizes data with the specified max_length, creates fresh Dataset objects, loads the pre-trained model with `AutoModelForSequenceClassification.from_pretrained()` while specifying the correct number of output classes, creates training arguments, instantiates the WeightedTrainer, calls `trainer.train()` to run training, calls `trainer.evaluate()` to get final metrics, and returns both metrics and the trainer object. Each of the three experiments (A, B, C) calls `run_experiment()` with different parameters and stores results in an OrderedDict. Finally, I extract the F1 scores from each result, sort experiments by F1, and print a leaderboard.\n",
        "\n",
        "**Inputs:**\n",
        "This cell uses `X_train`, `X_val`, `y_train`, and `y_val` from the train-test split. It also uses the model checkpoint names (CLINICAL_BERT, DISTIL_BERT) and the tokenizer defined in earlier sections. Each experiment re-tokenizes the data with its specific max_length setting.\n",
        "\n",
        "**Outputs:**\n",
        "During training, you'll see progress bars showing epoch progress, batch progress within each epoch, loss values that should decrease over time, and periodic evaluation metrics. After each experiment finishes, you'll see a summary of its final performance metrics including accuracy, precision, recall, and F1 score. At the very end, a leaderboard ranks all three experiments by F1 score, showing which configuration worked best. The entire cell might take 20-60 minutes to run depending on whether you have GPU and how large your dataset is.\n",
        "\n",
        "**Code Flow:**\n",
        "The flow is hierarchical and modular. At the top level, I set up shared infrastructure (metrics function, class weights). Then I define helper functions (tokenization, training args factory, experiment runner). Finally, I call the experiment runner three times with different parameters and collect results. Each experiment is independent - they don't share trained weights, though they do share the data and evaluation metrics. The leaderboard aggregation happens after all experiments complete, sorting by F1 score and displaying in descending order.\n",
        "\n",
        "**Comments and Observations:**\n",
        "Hyperparameter selection is part science, part art. Learning rates for fine-tuning transformers typically range from 1e-5 to 5e-5 because these models are already well-trained and you don't want to disturb the pre-trained weights too much. Going higher risks catastrophic forgetting where the model loses its pre-trained knowledge. Batch size is constrained by GPU memory - if you get out-of-memory errors, reduce batch size. Smaller batches (8-16) give noisier gradient updates but sometimes generalize better, while larger batches (32-64) give more stable training but might overfit. The number of epochs depends on dataset size - smaller datasets need more epochs to converge, but too many epochs causes overfitting. Weight decay adds L2 regularization by penalizing large weights, which prevents overfitting but too much weight decay can underfit. Warmup ratio gradually increases the learning rate from near-zero to the target value over the first X% of training steps, which stabilizes training when starting from random initialization of the classification head. The version compatibility fallback exists because HuggingFace frequently changes their API - older transformers versions used different parameter names for the same functionality. By catching the TypeError and falling back to legacy parameters, the code works across a wider range of library versions. Experiment A (conservative) uses safe defaults that should work reliably but might not achieve peak performance. Experiment B (aggressive) pushes the learning rate higher and trains longer, which might find better optima but risks overfitting. Experiment C (fast baseline) uses DistilBERT for speed comparison - if DistilBERT matches ClinicalBERT performance, you might prefer it for production due to faster inference. The leaderboard at the end tells you objectively which approach worked best on your specific data. Sometimes the aggressive approach wins, sometimes the conservative one does - it depends on your data characteristics and how much overfitting risk you face. The F1 score is the key metric here because it balances precision and recall, giving you a single number that captures overall classification quality while accounting for class imbalance through weighted averaging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LkYDOan1hZ2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c69126241636484ba529ac949f45d2d9",
            "e7e3cd1f34134e45a09dd4f71ce9a48d",
            "68e961bef26f46a4991bd21aef5567d1",
            "232610b0db89457ba288626ba5f0c2cd",
            "b4794f3efc4840929f9ff65dd74cfe71",
            "f1c254545d0041fe905fea3ebf32f833",
            "59083549596b464ca1a1156223bf67a6",
            "15d7486f56884c9e8b805c1fd1b11fde",
            "beeb3d13a86d464bb998d8bad55c6511",
            "317b2539f9af4cf8bedd0b9123ceb7e2",
            "4261dac2993d447f91d0065ddb2f5876",
            "aa2b0f0826e84157b9b0a7a7a5510d39",
            "4051c092ffe34233a178dc1d23b49cbc",
            "2d9e132b019a482bbf83e381ae34dcf1",
            "44ba20c07bf64fb495ea0715bd25dd7d",
            "df217802f8ef400aa40a12c6b8d2ca26",
            "42a9650b33cd41a19514555a3b57d0d3",
            "1f94d3d25ee14dcc829c703843541d81",
            "38a17e3bc34142ffbb76aee8c5e7a8a6",
            "c568fe15b1834329aa8c7652385329d7",
            "bc9fa6019c8847ab9904e5ce04e1767a",
            "51198c5fcf6d46d9ab570ef8d3bfd935"
          ]
        },
        "id": "LkYDOan1hZ2O",
        "outputId": "28b06c0b-d6fc-4aa1-f9ed-c15ad135cc6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Detected 7 classes ‚Üí metrics average='weighted'\n",
            "[Fine-tune] Class weights: [4.254474639892578, 5.886537551879883, 1.0609430074691772, 1.0, 15.16705322265625, 6.31594181060791, 1.5343269109725952]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c69126241636484ba529ac949f45d2d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune] Using legacy TrainingArguments fallback.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1839706526.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa2b0f0826e84157b9b0a7a7a5510d39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5001' max='7902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5001/7902 21:27 < 12:27, 3.88 it/s, Epoch 1.90/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.912600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.368300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.984600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.960300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.845400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.879500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.825100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.775700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.796300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.698800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.730200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.768300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.742100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.776800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.604600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.717900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.728300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.697000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.635300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.629400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.698700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.781800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.591600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.737300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.593300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.590500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.660100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.616300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.638300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.631600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.602100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.635700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.617700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.563400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.607500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.698000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.566800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.595700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.517100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.531400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.582200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.437400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.545500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.550600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.622600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.423800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.483600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.496900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.532500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.526400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.492700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.489900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.463200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.399700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.559300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.461500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.503800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.453800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.332700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.500200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.391200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.503800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.506900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.448000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.570300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.484600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.426900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.496800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.440100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.512100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.519300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.465100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.440800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.448300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.487100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.444700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.484200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- 5) Fine-tuning (Three Experiments) [version-compatible] ---\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Metrics: binary vs multiclass handled automatically\n",
        "num_labels = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "print(f\"[Fine-tune] Detected {num_labels} classes ‚Üí metrics average='{avg_type}'\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "# 2) Class weights for imbalanced data (size == num_labels)\n",
        "counts = np.bincount(y_train, minlength=num_labels)\n",
        "# Heuristic: inverse-frequency scaled to max=1.0 (safe for CE)\n",
        "weights = counts.max() / np.maximum(counts, 1)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "print(f\"[Fine-tune] Class weights: {class_weights.tolist()}\")\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 3) Helper: tokenizer already defined above. Re-tokenize per max_length\n",
        "def tokenize_texts(texts, max_length=160):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# 4) Version-compatible TrainingArguments factory\n",
        "import inspect\n",
        "\n",
        "def make_training_args(name, batch_size, lr, epochs, weight_decay, warmup_ratio):\n",
        "    kwargs_modern = dict(\n",
        "        output_dir=f\"./runs/{name}\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=[]\n",
        "    )\n",
        "    try:\n",
        "        # Try modern signature first\n",
        "        return TrainingArguments(**kwargs_modern)\n",
        "    except TypeError:\n",
        "        # Fallback for older transformers (no evaluation_strategy/save_strategy)\n",
        "        print(\"[Fine-tune] Using legacy TrainingArguments fallback.\")\n",
        "        kwargs_legacy = dict(\n",
        "            output_dir=f\"./runs/{name}\",\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            learning_rate=lr,\n",
        "            num_train_epochs=epochs,\n",
        "            weight_decay=weight_decay,\n",
        "            logging_steps=50,\n",
        "            do_eval=True,          # legacy way to enable evaluation\n",
        "            save_steps=500,        # periodic saving\n",
        "            overwrite_output_dir=True,\n",
        "            fp16=torch.cuda.is_available()\n",
        "        )\n",
        "        return TrainingArguments(**kwargs_legacy)\n",
        "\n",
        "def run_experiment(name, backbone, batch_size=16, lr=2e-5, epochs=3,\n",
        "                   weight_decay=0.01, warmup_ratio=0.1, max_length=160):\n",
        "    # Re-tokenize for this max_length\n",
        "    tr = tokenize_texts(X_train, max_length=max_length)\n",
        "    va = tokenize_texts(X_val,   max_length=max_length)\n",
        "\n",
        "    train_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": tr[\"input_ids\"],\n",
        "        \"attention_mask\": tr[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_train.to_numpy(), dtype=torch.long)   # <-- use .to_numpy()\n",
        "    })\n",
        "    val_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": va[\"input_ids\"],\n",
        "        \"attention_mask\": va[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_val.to_numpy(), dtype=torch.long)     # <-- use .to_numpy()\n",
        "    })\n",
        "\n",
        "\n",
        "    # Load backbone with correct num_labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        backbone, num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    args = make_training_args(\n",
        "        name=name, batch_size=batch_size, lr=lr, epochs=epochs,\n",
        "        weight_decay=weight_decay, warmup_ratio=warmup_ratio\n",
        "    )\n",
        "\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds_local,\n",
        "        eval_dataset=val_ds_local,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"\\n>>> {name} results: {metrics}\\n\")\n",
        "    return metrics, trainer\n",
        "\n",
        "# --- Define backbones (already set earlier) ---\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT   = \"distilbert-base-uncased\"\n",
        "\n",
        "results = OrderedDict()\n",
        "\n",
        "# Exp-A: ClinicalBERT, conservative LR, small batch\n",
        "results['expA_clinicalbert_bs16_lr2e-5_ep3'] = run_experiment(\n",
        "    name=\"expA_clinicalbert_bs16_lr2e-5_ep3\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=2e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-B: ClinicalBERT, slightly higher LR, more epochs\n",
        "results['expB_clinicalbert_bs16_lr5e-5_ep4'] = run_experiment(\n",
        "    name=\"expB_clinicalbert_bs16_lr5e-5_ep4\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=16, lr=5e-5, epochs=4,\n",
        "    weight_decay=0.01, warmup_ratio=0.06, max_length=160\n",
        ")\n",
        "\n",
        "# Exp-C: DistilBERT fast baseline\n",
        "results['expC_distilbert_bs32_lr3e-5_ep3'] = run_experiment(\n",
        "    name=\"expC_distilbert_bs32_lr3e-5_ep3\",\n",
        "    backbone=DISTIL_BERT,\n",
        "    batch_size=32, lr=3e-5, epochs=3,\n",
        "    weight_decay=0.01, warmup_ratio=0.1, max_length=128\n",
        ")\n",
        "\n",
        "# Leaderboard\n",
        "board = []\n",
        "for k,(m,_t) in results.items():\n",
        "    board.append((k, m.get('eval_f1', float('nan')), m.get('eval_accuracy', float('nan'))))\n",
        "board = sorted(board, key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nLeaderboard (by F1):\")\n",
        "for name, f1, acc in board:\n",
        "    print(f\"{name:35s}  F1={f1:.4f}  Acc={acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05dff337",
      "metadata": {
        "id": "05dff337"
      },
      "source": [
        "## 5b) Fast Fine-Tuning (Optimized for Speed)\n",
        "\n",
        "This section provides optimized training configurations to significantly speed up fine-tuning while maintaining good performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433ed5ea",
      "metadata": {
        "id": "433ed5ea"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FAST FINE-TUNING - Optimized for Speed\n",
        "# ============================================================================\n",
        "# This version uses multiple optimizations to train much faster\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Speed optimizations configuration\n",
        "SPEED_OPTIMIZATIONS = {\n",
        "    'use_gradient_checkpointing': True,  # Saves memory, allows larger batches\n",
        "    'gradient_accumulation_steps': 4,    # Simulate larger batch size\n",
        "    'dataloader_num_workers': 4,         # Parallel data loading\n",
        "    'dataloader_pin_memory': True,        # Faster GPU transfer\n",
        "    'max_length': 128,                    # Reduced from 160 (faster)\n",
        "    'logging_steps': 100,                 # Less frequent logging\n",
        "    'eval_steps': 500,                    # Less frequent evaluation\n",
        "    'save_steps': 1000,                   # Less frequent saving\n",
        "    'fp16': True,                         # Mixed precision (already using)\n",
        "    'optim': 'adamw_torch',               # Optimized optimizer\n",
        "}\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FAST FINE-TUNING CONFIGURATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Speed Optimizations Enabled:\")\n",
        "for key, value in SPEED_OPTIMIZATIONS.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Reuse metrics and class weights from previous cell\n",
        "if 'num_labels' not in globals():\n",
        "    num_labels = len(np.unique(y_train))\n",
        "    avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "else:\n",
        "    avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "\n",
        "if 'compute_metrics' not in globals():\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "        p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "if 'class_weights' not in globals():\n",
        "    counts = np.bincount(y_train, minlength=num_labels)\n",
        "    weights = counts.max() / np.maximum(counts, 1)\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "\n",
        "if 'WeightedTrainer' not in globals():\n",
        "    class WeightedTrainer(Trainer):\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "            labels = inputs.get(\"labels\")\n",
        "            outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "            logits = outputs.get(\"logits\")\n",
        "            loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Fast tokenization with reduced length\n",
        "def tokenize_texts_fast(texts, max_length=128):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "def make_fast_training_args(name, batch_size, lr, epochs, weight_decay=0.01, warmup_ratio=0.1):\n",
        "    \"\"\"Create optimized training arguments for speed\"\"\"\n",
        "    effective_batch_size = batch_size * SPEED_OPTIMIZATIONS['gradient_accumulation_steps']\n",
        "\n",
        "    kwargs = dict(\n",
        "        output_dir=f\"./runs_fast/{name}\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size * 2,  # Larger eval batch (faster)\n",
        "        gradient_accumulation_steps=SPEED_OPTIMIZATIONS['gradient_accumulation_steps'],\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        logging_steps=SPEED_OPTIMIZATIONS['logging_steps'],\n",
        "        eval_steps=SPEED_OPTIMIZATIONS['eval_steps'],\n",
        "        save_steps=SPEED_OPTIMIZATIONS['save_steps'],\n",
        "        evaluation_strategy=\"steps\",  # Evaluate by steps, not epoch (faster)\n",
        "        save_strategy=\"steps\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=SPEED_OPTIMIZATIONS['fp16'] and torch.cuda.is_available(),\n",
        "        dataloader_num_workers=SPEED_OPTIMIZATIONS['dataloader_num_workers'],\n",
        "        dataloader_pin_memory=SPEED_OPTIMIZATIONS['dataloader_pin_memory'],\n",
        "        optim=SPEED_OPTIMIZATIONS['optim'],\n",
        "        report_to=[],\n",
        "        # Disable unnecessary features for speed\n",
        "        save_total_limit=2,  # Keep only 2 checkpoints\n",
        "        prediction_loss_only=False,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        return TrainingArguments(**kwargs)\n",
        "    except TypeError:\n",
        "        # Fallback for older versions\n",
        "        kwargs_legacy = {k: v for k, v in kwargs.items() if k not in ['evaluation_strategy', 'save_strategy']}\n",
        "        kwargs_legacy.update({\n",
        "            'do_eval': True,\n",
        "            'eval_steps': SPEED_OPTIMIZATIONS['eval_steps'],\n",
        "            'save_steps': SPEED_OPTIMIZATIONS['save_steps'],\n",
        "        })\n",
        "        return TrainingArguments(**kwargs_legacy)\n",
        "\n",
        "def run_fast_experiment(name, backbone, batch_size=32, lr=2e-5, epochs=3,\n",
        "                       weight_decay=0.01, warmup_ratio=0.1):\n",
        "    \"\"\"Run optimized fast experiment\"\"\"\n",
        "    max_length = SPEED_OPTIMIZATIONS['max_length']\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FAST EXPERIMENT: {name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Backbone: {backbone}\")\n",
        "    print(f\"Batch size: {batch_size} (effective: {batch_size * SPEED_OPTIMIZATIONS['gradient_accumulation_steps']} with accumulation)\")\n",
        "    print(f\"Max length: {max_length} (reduced for speed)\")\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Tokenize with reduced length\n",
        "    tr = tokenize_texts_fast(X_train, max_length=max_length)\n",
        "    va = tokenize_texts_fast(X_val, max_length=max_length)\n",
        "\n",
        "    train_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": tr[\"input_ids\"],\n",
        "        \"attention_mask\": tr[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
        "    })\n",
        "    val_ds_local = Dataset.from_dict({\n",
        "        \"input_ids\": va[\"input_ids\"],\n",
        "        \"attention_mask\": va[\"attention_mask\"],\n",
        "        \"labels\": torch.tensor(y_val.to_numpy(), dtype=torch.long)\n",
        "    })\n",
        "\n",
        "    # Load model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        backbone, num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    # Enable gradient checkpointing to save memory (allows larger batches)\n",
        "    if SPEED_OPTIMIZATIONS['use_gradient_checkpointing']:\n",
        "        if hasattr(model, 'gradient_checkpointing_enable'):\n",
        "            model.gradient_checkpointing_enable()\n",
        "            print(\"‚úÖ Gradient checkpointing enabled (saves memory)\")\n",
        "\n",
        "    args = make_fast_training_args(\n",
        "        name=name, batch_size=batch_size, lr=lr, epochs=epochs,\n",
        "        weight_decay=weight_decay, warmup_ratio=warmup_ratio\n",
        "    )\n",
        "\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds_local,\n",
        "        eval_dataset=val_ds_local,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    metrics = trainer.evaluate()\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n>>> {name} results: {metrics}\")\n",
        "    print(f\">>> Training time: {train_time/60:.1f} minutes ({train_time:.0f} seconds)\")\n",
        "    print(f\">>> Total time: {total_time/60:.1f} minutes\\n\")\n",
        "\n",
        "    return metrics, trainer, total_time\n",
        "\n",
        "# Run fast experiments\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "DISTIL_BERT = \"distilbert-base-uncased\"\n",
        "\n",
        "fast_results = OrderedDict()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STARTING FAST EXPERIMENTS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"These experiments use speed optimizations:\")\n",
        "print(\"  - Larger batch sizes with gradient accumulation\")\n",
        "print(\"  - Reduced sequence length (128 vs 160)\")\n",
        "print(\"  - Optimized data loading\")\n",
        "print(\"  - Less frequent evaluation/saving\")\n",
        "print(\"  - Gradient checkpointing\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Fast Exp 1: DistilBERT (fastest model)\n",
        "fast_results['fast_exp1_distilbert_bs32_ep2'] = run_fast_experiment(\n",
        "    name=\"fast_exp1_distilbert_bs32_ep2\",\n",
        "    backbone=DISTIL_BERT,\n",
        "    batch_size=32,\n",
        "    lr=3e-5,\n",
        "    epochs=2,  # Fewer epochs for speed\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1\n",
        ")\n",
        "\n",
        "# Fast Exp 2: ClinicalBERT with optimizations\n",
        "fast_results['fast_exp2_clinicalbert_bs32_ep3'] = run_fast_experiment(\n",
        "    name=\"fast_exp2_clinicalbert_bs32_ep3\",\n",
        "    backbone=CLINICAL_BERT,\n",
        "    batch_size=32,  # Larger batch\n",
        "    lr=2e-5,\n",
        "    epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1\n",
        ")\n",
        "\n",
        "# Fast Exp 3: ClinicalBERT with even larger batch (if memory allows)\n",
        "# Uncomment if you have enough GPU memory\n",
        "# fast_results['fast_exp3_clinicalbert_bs64_ep3'] = run_fast_experiment(\n",
        "#     name=\"fast_exp3_clinicalbert_bs64_ep3\",\n",
        "#     backbone=CLINICAL_BERT,\n",
        "#     batch_size=64,  # Very large batch\n",
        "#     lr=2e-5,\n",
        "#     epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     warmup_ratio=0.1\n",
        "# )\n",
        "\n",
        "# Leaderboard\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FAST EXPERIMENTS LEADERBOARD\")\n",
        "print(\"=\" * 80)\n",
        "board = []\n",
        "for k, (m, t, time_taken) in fast_results.items():\n",
        "    board.append((k, m.get('eval_f1', float('nan')), m.get('eval_accuracy', float('nan')), time_taken))\n",
        "board = sorted(board, key=lambda x: x[1], reverse=True)\n",
        "print(f\"{'Experiment':40s}  F1 Score    Accuracy    Time (min)\")\n",
        "print(\"-\" * 80)\n",
        "for name, f1, acc, time_taken in board:\n",
        "    print(f\"{name:40s}  F1={f1:.4f}  Acc={acc:.4f}  {time_taken/60:.1f} min\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "736ec791",
      "metadata": {
        "id": "736ec791"
      },
      "source": [
        "### Speed Optimization Summary\n",
        "\n",
        "The fast fine-tuning uses these optimizations to train 2-4x faster:\n",
        "\n",
        "1. **Larger Batch Sizes**: Batch size 32-64 instead of 16 (fewer steps = faster)\n",
        "2. **Gradient Accumulation**: Simulates even larger batches without memory issues\n",
        "3. **Reduced Sequence Length**: 128 tokens instead of 160 (20% faster processing)\n",
        "4. **Optimized Data Loading**: Parallel workers and pinned memory\n",
        "5. **Less Frequent Evaluation**: Every 500 steps instead of every epoch\n",
        "6. **Gradient Checkpointing**: Saves memory, allows larger batches\n",
        "7. **Mixed Precision (FP16)**: Already enabled, but optimized\n",
        "8. **Fewer Checkpoints**: Saves only 2 best models instead of all\n",
        "\n",
        "**Expected Speed Improvement**: 2-4x faster than standard training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GqC_w9j4MCOg",
      "metadata": {
        "id": "GqC_w9j4MCOg"
      },
      "outputs": [],
      "source": [
        "# Record all experiment results to Excel log file\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Create a new workbook\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Experiment_Logs\"\n",
        "\n",
        "# Define header style\n",
        "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "header_font = Font(bold=True, color=\"FFFFFF\")\n",
        "\n",
        "# Define headers\n",
        "headers = [\n",
        "    \"Experiment_ID\",\n",
        "    \"Model_Backbone\",\n",
        "    \"Batch_Size\",\n",
        "    \"Learning_Rate\",\n",
        "    \"Epochs\",\n",
        "    \"Weight_Decay\",\n",
        "    \"Warmup_Ratio\",\n",
        "    \"Max_Length\",\n",
        "    \"Accuracy\",\n",
        "    \"F1_Score\",\n",
        "    \"Precision\",\n",
        "    \"Recall\"\n",
        "]\n",
        "\n",
        "# Write headers\n",
        "for col_idx, header in enumerate(headers, 1):\n",
        "    cell = ws.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "# Function to parse experiment name and extract hyperparameters\n",
        "def parse_experiment_name(exp_name):\n",
        "    \"\"\"Extract hyperparameters from experiment name\"\"\"\n",
        "    params = {\n",
        "        \"backbone\": \"Unknown\",\n",
        "        \"batch_size\": None,\n",
        "        \"learning_rate\": None,\n",
        "        \"epochs\": None\n",
        "    }\n",
        "\n",
        "    # Extract backbone\n",
        "    if \"clinicalbert\" in exp_name.lower():\n",
        "        params[\"backbone\"] = \"ClinicalBERT\"\n",
        "    elif \"distilbert\" in exp_name.lower():\n",
        "        params[\"backbone\"] = \"DistilBERT\"\n",
        "\n",
        "    # Extract batch size (bs16, bs32, etc.)\n",
        "    bs_match = re.search(r'bs(\\d+)', exp_name.lower())\n",
        "    if bs_match:\n",
        "        params[\"batch_size\"] = int(bs_match.group(1))\n",
        "\n",
        "    # Extract learning rate (lr2e-5, lr5e-5, etc.)\n",
        "    lr_match = re.search(r'lr([\\d.e-]+)', exp_name.lower())\n",
        "    if lr_match:\n",
        "        lr_str = lr_match.group(1)\n",
        "        # Convert scientific notation string to float\n",
        "        if 'e' in lr_str:\n",
        "            base, exp = lr_str.split('e')\n",
        "            params[\"learning_rate\"] = float(base) * (10 ** int(exp))\n",
        "        else:\n",
        "            params[\"learning_rate\"] = float(lr_str)\n",
        "\n",
        "    # Extract epochs (ep3, ep4, etc.)\n",
        "    ep_match = re.search(r'ep(\\d+)', exp_name.lower())\n",
        "    if ep_match:\n",
        "        params[\"epochs\"] = int(ep_match.group(1))\n",
        "\n",
        "    return params\n",
        "\n",
        "# Store experiment configurations (you may need to adjust these based on your actual runs)\n",
        "experiment_configs = {\n",
        "    \"expA_clinicalbert_bs16_lr2e-5_ep3\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"max_length\": 160\n",
        "    },\n",
        "    \"expB_clinicalbert_bs16_lr5e-5_ep4\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.06,\n",
        "        \"max_length\": 160\n",
        "    },\n",
        "    \"expC_distilbert_bs32_lr3e-5_ep3\": {\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"max_length\": 128\n",
        "    }\n",
        "}\n",
        "\n",
        "# Write experiment data\n",
        "row = 2\n",
        "for exp_name, (metrics, trainer) in results.items():\n",
        "    # Parse experiment name\n",
        "    parsed = parse_experiment_name(exp_name)\n",
        "    config = experiment_configs.get(exp_name, {})\n",
        "\n",
        "    # Write data\n",
        "    ws.cell(row=row, column=1, value=exp_name)  # Experiment_ID\n",
        "    ws.cell(row=row, column=2, value=parsed[\"backbone\"])  # Model_Backbone\n",
        "    ws.cell(row=row, column=3, value=parsed[\"batch_size\"])  # Batch_Size\n",
        "    ws.cell(row=row, column=4, value=parsed[\"learning_rate\"])  # Learning_Rate\n",
        "    ws.cell(row=row, column=5, value=parsed[\"epochs\"])  # Epochs\n",
        "    ws.cell(row=row, column=6, value=config.get(\"weight_decay\", \"N/A\"))  # Weight_Decay\n",
        "    ws.cell(row=row, column=7, value=config.get(\"warmup_ratio\", \"N/A\"))  # Warmup_Ratio\n",
        "    ws.cell(row=row, column=8, value=config.get(\"max_length\", \"N/A\"))  # Max_Length\n",
        "    ws.cell(row=row, column=9, value=metrics.get(\"eval_accuracy\", \"N/A\"))  # Accuracy\n",
        "    ws.cell(row=row, column=10, value=metrics.get(\"eval_f1\", \"N/A\"))  # F1_Score\n",
        "    ws.cell(row=row, column=11, value=metrics.get(\"eval_precision\", \"N/A\"))  # Precision\n",
        "    ws.cell(row=row, column=12, value=metrics.get(\"eval_recall\", \"N/A\"))  # Recall\n",
        "\n",
        "    row += 1\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min(max_length + 2, 30)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save the file\n",
        "excel_filename = f\"Exercise_F2_Experiment_Logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "wb.save(excel_filename)\n",
        "\n",
        "print(f\"‚úÖ Experiment logs saved to: {excel_filename}\")\n",
        "print(f\"   Total experiments logged: {len(results)}\")\n",
        "print(f\"   Columns: {', '.join(headers)}\")\n",
        "\n",
        "# Automatically download the file\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(excel_filename)\n",
        "    print(f\"‚úÖ File automatically downloaded: {excel_filename}\")\n",
        "except ImportError:\n",
        "    print(\"Note: Not running in Google Colab. File saved locally.\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not auto-download. File saved at: {excel_filename}\")\n",
        "    print(f\"   Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9406965c",
      "metadata": {
        "id": "9406965c"
      },
      "source": [
        "## Epoch Analysis: Determine Feasible Number of Epochs\n",
        "\n",
        "This cell analyzes your dataset and training configuration to determine how many epochs are feasible based on:\n",
        "- Dataset size\n",
        "- Training time per epoch\n",
        "- GPU/CPU constraints\n",
        "- Best practices for fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6f4756",
      "metadata": {
        "id": "1f6f4756"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Epoch Feasibility Analysis\n",
        "# ============================================================================\n",
        "# Analyzes dataset and training configuration to determine optimal epochs\n",
        "# ============================================================================\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EPOCH FEASIBILITY ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get dataset information\n",
        "if 'X_train' in globals() and 'y_train' in globals():\n",
        "    train_size = len(X_train)\n",
        "    val_size = len(X_val) if 'X_val' in globals() else 0\n",
        "    print(f\"\\nüìä Dataset Information:\")\n",
        "    print(f\"  Training samples: {train_size:,}\")\n",
        "    print(f\"  Validation samples: {val_size:,}\")\n",
        "    print(f\"  Total training data: {train_size + val_size:,}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Training data not found. Please run data split cells first.\")\n",
        "    train_size = 0\n",
        "    val_size = 0\n",
        "\n",
        "# Get device information\n",
        "if 'device' in globals():\n",
        "    is_cuda = torch.cuda.is_available() and (str(device) == \"cuda\" or \"cuda\" in str(device).lower())\n",
        "    device_type = \"GPU (CUDA)\" if is_cuda else \"CPU\"\n",
        "    print(f\"\\nüñ•Ô∏è  Device: {device_type}\")\n",
        "\n",
        "    if is_cuda and torch.cuda.is_available():\n",
        "        try:\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            print(f\"  GPU Name: {gpu_name}\")\n",
        "            print(f\"  GPU Memory: {gpu_memory:.2f} GB\")\n",
        "        except:\n",
        "            print(f\"  GPU details unavailable\")\n",
        "else:\n",
        "    device_type = \"Unknown\"\n",
        "    is_cuda = False\n",
        "    print(f\"\\n‚ö†Ô∏è  Device information not available\")\n",
        "\n",
        "# Training configuration analysis\n",
        "print(f\"\\n‚öôÔ∏è  Training Configuration Analysis:\")\n",
        "\n",
        "# Common batch sizes and their impact\n",
        "batch_sizes = [8, 16, 32]\n",
        "print(f\"\\nBatch Size Impact on Training:\")\n",
        "for bs in batch_sizes:\n",
        "    steps_per_epoch = math.ceil(train_size / bs) if train_size > 0 else 0\n",
        "    print(f\"  Batch size {bs:2d}: ~{steps_per_epoch:,} steps per epoch\")\n",
        "\n",
        "# Estimate training time per epoch (rough estimates)\n",
        "print(f\"\\n‚è±Ô∏è  Estimated Training Time Per Epoch:\")\n",
        "print(f\"  (Based on typical transformer fine-tuning speeds)\")\n",
        "\n",
        "if is_cuda:\n",
        "    # GPU estimates (more accurate)\n",
        "    time_per_step_gpu = 0.5  # seconds per step (typical for ClinicalBERT on GPU)\n",
        "    for bs in batch_sizes:\n",
        "        steps = math.ceil(train_size / bs) if train_size > 0 else 0\n",
        "        time_per_epoch = (steps * time_per_step_gpu) / 60  # in minutes\n",
        "        print(f\"  Batch size {bs:2d}: ~{time_per_epoch:.1f} minutes per epoch ({steps:,} steps)\")\n",
        "else:\n",
        "    # CPU estimates (much slower)\n",
        "    time_per_step_cpu = 5.0  # seconds per step (typical for ClinicalBERT on CPU)\n",
        "    for bs in batch_sizes:\n",
        "        steps = math.ceil(train_size / bs) if train_size > 0 else 0\n",
        "        time_per_epoch = (steps * time_per_step_cpu) / 60  # in minutes\n",
        "        print(f\"  Batch size {bs:2d}: ~{time_per_epoch:.1f} minutes per epoch ({steps:,} steps)\")\n",
        "\n",
        "# Recommended epochs based on dataset size\n",
        "print(f\"\\nüìà Recommended Epochs Based on Dataset Size:\")\n",
        "\n",
        "if train_size > 0:\n",
        "    if train_size < 1000:\n",
        "        recommended_min = 10\n",
        "        recommended_max = 20\n",
        "        reason = \"Small dataset - more epochs needed to learn patterns\"\n",
        "    elif train_size < 10000:\n",
        "        recommended_min = 5\n",
        "        recommended_max = 10\n",
        "        reason = \"Medium dataset - moderate epochs sufficient\"\n",
        "    elif train_size < 50000:\n",
        "        recommended_min = 3\n",
        "        recommended_max = 7\n",
        "        reason = \"Large dataset - fewer epochs needed, risk of overfitting\"\n",
        "    else:\n",
        "        recommended_min = 2\n",
        "        recommended_max = 5\n",
        "        reason = \"Very large dataset - minimal epochs, focus on regularization\"\n",
        "\n",
        "    print(f\"  Dataset size: {train_size:,} samples\")\n",
        "    print(f\"  Recommended range: {recommended_min}-{recommended_max} epochs\")\n",
        "    print(f\"  Reason: {reason}\")\n",
        "else:\n",
        "    recommended_min = 3\n",
        "    recommended_max = 5\n",
        "\n",
        "# Best practices for fine-tuning\n",
        "print(f\"\\nüí° Best Practices for Fine-Tuning Transformers:\")\n",
        "print(f\"  1. Start with 3-5 epochs for initial experiments\")\n",
        "print(f\"  2. Use early stopping to prevent overfitting\")\n",
        "print(f\"  3. Monitor validation loss - stop if it starts increasing\")\n",
        "print(f\"  4. For hyperparameter search: 2-3 epochs per trial (faster)\")\n",
        "print(f\"  5. For final model: 3-7 epochs (depending on dataset size)\")\n",
        "print(f\"  6. Maximum practical: 10-15 epochs (rarely needed)\")\n",
        "\n",
        "# Calculate feasible epochs based on time constraints\n",
        "print(f\"\\n‚è∞ Feasible Epochs Based on Time Constraints:\")\n",
        "\n",
        "time_constraints = [\n",
        "    (30, \"30 minutes\"),\n",
        "    (60, \"1 hour\"),\n",
        "    (120, \"2 hours\"),\n",
        "    (240, \"4 hours\"),\n",
        "    (480, \"8 hours\"),\n",
        "    (1440, \"24 hours\")\n",
        "]\n",
        "\n",
        "if train_size > 0 and is_cuda:\n",
        "    typical_batch = 16  # Most common batch size\n",
        "    steps = math.ceil(train_size / typical_batch)\n",
        "    time_per_epoch = (steps * time_per_step_gpu) / 60  # minutes\n",
        "\n",
        "    print(f\"  Using batch size 16, ~{time_per_epoch:.1f} min per epoch:\")\n",
        "    for max_time, label in time_constraints:\n",
        "        max_epochs = int(max_time / time_per_epoch)\n",
        "        if max_epochs > 0:\n",
        "            print(f\"    {label:12s}: Up to {max_epochs} epochs\")\n",
        "\n",
        "# Current configuration summary\n",
        "print(f\"\\nüìã Current Configuration Summary:\")\n",
        "if 'results' in globals():\n",
        "    print(f\"  Experiments run: {len(results)}\")\n",
        "    for exp_name in results.keys():\n",
        "        # Extract epochs from experiment name\n",
        "        if 'ep' in exp_name.lower():\n",
        "            import re\n",
        "            ep_match = re.search(r'ep(\\d+)', exp_name.lower())\n",
        "            if ep_match:\n",
        "                epochs_used = int(ep_match.group(1))\n",
        "                print(f\"    {exp_name}: {epochs_used} epochs\")\n",
        "else:\n",
        "    print(f\"  No experiments run yet\")\n",
        "\n",
        "# Final recommendations\n",
        "print(f\"\\n\" + \"=\" * 80)\n",
        "print(\"üéØ FINAL RECOMMENDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Recommended epoch range: {recommended_min}-{recommended_max} epochs\")\n",
        "print(f\"\\nFor different scenarios:\")\n",
        "print(f\"  ‚Ä¢ Quick experiments/hyperparameter search: 2-3 epochs\")\n",
        "print(f\"  ‚Ä¢ Standard fine-tuning: {recommended_min}-{recommended_max} epochs\")\n",
        "print(f\"  ‚Ä¢ Final model training: {min(recommended_max + 2, 10)} epochs (with early stopping)\")\n",
        "print(f\"  ‚Ä¢ Maximum safe: 10-15 epochs (monitor for overfitting)\")\n",
        "\n",
        "if train_size > 0:\n",
        "    print(f\"\\nüíæ With your dataset size ({train_size:,} samples):\")\n",
        "    print(f\"   Optimal: {recommended_min}-{recommended_max} epochs\")\n",
        "    print(f\"   Maximum practical: {min(recommended_max * 2, 15)} epochs\")\n",
        "    print(f\"   Use early stopping to automatically find best epoch\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Store recommendations\n",
        "EPOCH_RECOMMENDATIONS = {\n",
        "    'min_epochs': recommended_min,\n",
        "    'max_epochs': recommended_max,\n",
        "    'optimal_range': f\"{recommended_min}-{recommended_max}\",\n",
        "    'quick_experiments': '2-3',\n",
        "    'final_training': min(recommended_max + 2, 10),\n",
        "    'maximum_safe': 15,\n",
        "    'dataset_size': train_size,\n",
        "    'device_type': device_type\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Recommendations stored in: EPOCH_RECOMMENDATIONS\")\n",
        "print(f\"   Access with: EPOCH_RECOMMENDATIONS['optimal_range']\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GuFo0oKC_Dwo",
      "metadata": {
        "id": "GuFo0oKC_Dwo"
      },
      "source": [
        "## 6) Eval (Pick Best and Run Inference)\n",
        "\n",
        "**Function Description:**\n",
        "This cell identifies the best-performing experiment from your fine-tuning runs, saves that model to disk for future use, and demonstrates how to make predictions on new text. It shows you the complete inference pipeline from raw text to predicted class and confidence scores.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The selection logic iterates through the results dictionary using `.items()` which gives you both the experiment name and its (metrics, trainer) tuple. For each experiment, I check if its `eval_f1` score beats the current best, and if so, update both `best_f1` and `best_name` while storing the trainer object. After finding the winner, `trainer.save_model()` writes the model weights to disk at the specified path, and `tokenizer.save_pretrained()` saves the tokenizer configuration alongside it. The `predict()` function encapsulates the inference pipeline - it loads the saved tokenizer with `AutoTokenizer.from_pretrained()`, loads the saved model with `AutoModelForSequenceClassification.from_pretrained()`, moves the model to the correct device with `.to(device)`, tokenizes input texts using the same parameters as training, wraps the forward pass in `torch.no_grad()` to disable gradient computation (speeds up inference and saves memory), extracts logits from model outputs, applies `torch.argmax()` to get predicted classes, applies `torch.softmax()` to convert logits to probabilities, and returns both predictions and confidence scores after moving them from GPU to CPU and converting to numpy arrays. For the demo, I define three test sentences covering different scenarios (clearly calm, clearly stressed, ambiguous) and call predict on them. The output loop uses zip to iterate over texts, predictions, and probabilities simultaneously, formatting each as a readable string with the predicted label and confidence.\n",
        "\n",
        "**Inputs:**\n",
        "This cell uses the results dictionary populated in Section 5, which contains metrics and trainer objects from all three experiments. The predict function takes a list of text strings and optionally a model directory path.\n",
        "\n",
        "**Outputs:**\n",
        "You'll see a message identifying which experiment won and what its F1 score was, followed by the save directory path. Then you'll see three prediction lines showing the predicted class (as both a number and label), the confidence probability, and the original text. For example: \"[stressed(1) p=0.873] My chest is tight and I cannot focus, I think I am very stressed.\"\n",
        "\n",
        "**Code Flow:**\n",
        "The flow divides into three phases. First, iterate through all experiment results to find the highest F1 score and corresponding trainer. Second, save both the model and tokenizer to disk. Third, demonstrate inference by defining a predict function, creating test samples, calling predict, and formatting the output. The save and load operations prove that you can persist your model and reload it later without retraining.\n",
        "\n",
        "**Comments and Observations:**\n",
        "Saving the model is important because fine-tuning takes significant time and compute resources - you don't want to retrain every time you need to make predictions. The saved directory contains multiple files including model weights (pytorch_model.bin), model configuration (config.json), and tokenizer files (vocab.txt, tokenizer_config.json). Together these files fully specify your trained model and can be loaded on any machine with the same library versions. The predict function is production-ready - you could import it into a web API or batch processing script. The `torch.no_grad()` context manager is important for inference because it tells PyTorch not to track gradients, which cuts memory usage in half and speeds up computation. The difference between logits and probabilities matters: logits are raw scores that can be any value from negative to positive infinity, while probabilities are normalized to sum to 1.0 and range from 0 to 1. Softmax converts logits to probabilities using the formula exp(logit_i) / sum(exp(logit_j)). The probability value tells you confidence - 0.95 means highly confident, 0.55 means barely confident. In production, you might set a threshold like 0.7 and only act on predictions above that threshold, sending lower-confidence predictions to human review. The three test sentences demonstrate different difficulty levels. The first (\"calm and in control\") should be easy for the model - clear language indicating low stress. The second (\"chest is tight, cannot focus, very stressed\") contains multiple stress indicators and explicitly mentions stress, so the model should confidently predict stressed. The third (\"workload is heavy but manageable\") is ambiguous - \"heavy\" suggests stress but \"manageable\" suggests coping, so this tests whether the model can handle nuance. If the model gets the easy cases right but fails on ambiguous ones, that's actually good behavior showing it's not just memorizing keywords. You can expand this demo by adding more test cases, especially edge cases like very short text (\"I'm fine\"), very long text (multiple paragraphs), or text with mixed signals. The model architecture (ClinicalBERT vs DistilBERT) affects inference speed - DistilBERT is roughly 2x faster for the same input, which matters if you're processing millions of texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24E_Tay_hZ2O",
      "metadata": {
        "id": "24E_Tay_hZ2O"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select the best run from 'results' dict above\n",
        "best_name, best_f1 = None, -1.0\n",
        "best_trainer = None\n",
        "for name,(metrics, trainer) in results.items():\n",
        "    if metrics['eval_f1'] > best_f1:\n",
        "        best_f1 = metrics['eval_f1']\n",
        "        best_name = name\n",
        "        best_trainer = trainer\n",
        "\n",
        "print(f\"Best run: {best_name} with F1={best_f1:.4f}\")\n",
        "\n",
        "# Save the best model for reuse\n",
        "save_dir = f\"./best_model_{best_name}\"\n",
        "best_trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# Simple inference helper\n",
        "def predict(texts, model_dir=save_dir):\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)\n",
        "    enc = tok(list(texts), padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "    pred = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "    prob = torch.softmax(logits, dim=-1).cpu().numpy()[:,1]\n",
        "    return pred, prob\n",
        "\n",
        "# Demo predictions on a few samples\n",
        "samples = [\n",
        "    \"I feel calm and in control today.\",\n",
        "    \"My chest is tight and I cannot focus, I think I am very stressed.\",\n",
        "    \"Workload is heavy but manageable so far.\"\n",
        "]\n",
        "pred, prob = predict(samples)\n",
        "for s, y, p in zip(samples, pred, prob):\n",
        "    lab = \"stressed(1)\" if y==1 else \"not‚Äëstressed(0)\"\n",
        "    print(f\"[{lab}  p={p:.3f}]  {s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60280a27",
      "metadata": {
        "id": "60280a27"
      },
      "source": [
        "# Exercise F3: Automated Hyperparameter Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1DKRMdyUmm_5",
      "metadata": {
        "id": "1DKRMdyUmm_5"
      },
      "source": [
        "This cell installs the packages needed for hyperparameter optimization. You need transformers for model training, datasets for data handling, accelerate for faster training, ray and optuna for search algorithms, and openpyxl for creating Excel files.\n",
        "\n",
        "The pip install command uses the quiet flag to reduce output noise. All packages update to their latest versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d70dbc7",
      "metadata": {
        "id": "8d70dbc7"
      },
      "outputs": [],
      "source": [
        "# Install required packages for hyperparameter optimization\n",
        "!pip install transformers datasets accelerate ray[tune] optuna openpyxl -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AyeCECQYmoBd",
      "metadata": {
        "id": "AyeCECQYmoBd"
      },
      "source": [
        "This cell prepares your environment for automated hyperparameter tuning. It imports libraries for timing, Excel file creation, and model training. The code uses the same data splits and model from Exercise F2.\n",
        "\n",
        "The setup does several things. First, it imports time to track how long each search takes. It imports openpyxl to create Excel workbooks with formatted cells. It imports transformers components for model training and evaluation.\n",
        "\n",
        "The code reuses X_train, X_val, y_train, and y_val from Exercise F2. These variables contain your training and validation data splits. It also uses the same ClinicalBERT model and tokenizer.\n",
        "\n",
        "The tokenize_texts function converts text into token IDs that the model understands. It takes your text data and a maximum length parameter. The function returns input_ids and attention_mask tensors.\n",
        "\n",
        "The code creates Dataset objects from your tokenized data. These objects wrap your data in a format that the Trainer class expects. Each dataset contains input_ids, attention_mask, and labels.\n",
        "\n",
        "Class weights get computed using the same method as Exercise F2. The weights balance your classes since you have imbalanced data. The compute_metrics function calculates accuracy, precision, recall, and F1 score during evaluation.\n",
        "\n",
        "The WeightedTrainer class extends the standard Trainer. It applies class weights to the loss function during training. This helps the model learn from minority classes better.\n",
        "\n",
        "When you run this cell, it prints the device being used and the number of classes detected. The setup completes when you see the success message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343e5038",
      "metadata": {
        "id": "343e5038"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Exercise F3: Setup for Automated Hyperparameter Optimization\n",
        "# ============================================================================\n",
        "# IMPORTANT: This exercise uses the SAME data and model from Exercise F2:\n",
        "#   - Same model: ClinicalBERT (emilyalsentzer/Bio_ClinicalBERT)\n",
        "#   - Same data splits: X_train, X_val, y_train, y_val (from Exercise F2)\n",
        "#   - Same class weights and metrics computation\n",
        "#   - Only difference: Using automated hyperparameter optimization\n",
        "# ============================================================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model and tokenizer setup (using ClinicalBERT from Exercise F2)\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "\n",
        "# Number of classes (from Exercise F2 - using same y_train variable)\n",
        "num_labels = len(np.unique(y_train))\n",
        "avg_type = \"binary\" if num_labels == 2 else \"weighted\"\n",
        "print(f\"Detected {num_labels} classes ‚Üí using average='{avg_type}' for metrics\")\n",
        "\n",
        "# Tokenize datasets (reusing SAME X_train, X_val, y_train, y_val from Exercise F2)\n",
        "def tokenize_texts(texts, max_length=160):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_enc = tokenize_texts(X_train, max_length=160)\n",
        "val_enc = tokenize_texts(X_val, max_length=160)\n",
        "\n",
        "train_ds = Dataset.from_dict({\n",
        "    \"input_ids\": train_enc[\"input_ids\"],\n",
        "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
        "})\n",
        "\n",
        "val_ds = Dataset.from_dict({\n",
        "    \"input_ids\": val_enc[\"input_ids\"],\n",
        "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(y_val.to_numpy(), dtype=torch.long)\n",
        "})\n",
        "\n",
        "# Compute class weights (from Exercise F2)\n",
        "counts = np.bincount(y_train, minlength=num_labels)\n",
        "weights = counts.max() / np.maximum(counts, 1)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "\n",
        "# Metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=avg_type)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
        "\n",
        "# Weighted Trainer class\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print(\"‚úÖ Exercise F3 setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863ffde6",
      "metadata": {
        "id": "863ffde6"
      },
      "source": [
        "### F3.2: Random Search Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t3ymupYIm1ym",
      "metadata": {
        "id": "t3ymupYIm1ym"
      },
      "source": [
        "This cell runs Random Search to find the best hyperparameters. Random Search picks hyperparameter values randomly from the ranges you define. It can explore continuous ranges that Grid Search cannot.\n",
        "\n",
        "The random_search_hp_space function defines the hyperparameter space differently than Grid Search. It uses trial.suggest_float for continuous values and trial.suggest_categorical for discrete choices.\n",
        "\n",
        "For learning rate, Random Search samples from a continuous range between 1e-5 and 5e-5. The log parameter set to True means it samples on a logarithmic scale. This helps because learning rates often work better on log scales.\n",
        "\n",
        "For batch size, it picks randomly from the same three options as Grid Search. For weight decay, it samples from a continuous range between 0.0 and 0.1. For epochs, it picks randomly between 3 and 4.\n",
        "\n",
        "Random Search runs 24 trials, same as Grid Search. This makes the comparison fair. Each trial picks random hyperparameter values and trains a model.\n",
        "\n",
        "The TrainingArguments and WeightedTrainer work the same way as in Grid Search. The only difference is how hyperparameters get selected.\n",
        "\n",
        "Random Search can find better hyperparameters in fewer trials when the optimal values are not on your grid points. It explores the continuous space more efficiently.\n",
        "\n",
        "When Random Search finishes, it returns the best trial with the highest F1 score. The code prints the best hyperparameters and execution time. You use this information to compare against Grid Search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311cbad7",
      "metadata": {
        "id": "311cbad7"
      },
      "outputs": [],
      "source": [
        "# Random Search Implementation\n",
        "# This randomly samples from the hyperparameter space\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "def random_search_hp_space(trial):\n",
        "    \"\"\"\n",
        "    Define the hyperparameter space for Random Search.\n",
        "    Random Search samples RANDOMLY from continuous/discrete ranges.\n",
        "    \"\"\"\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 3e-5, log=True)  # Lower range\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16])  # Smaller batches\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.01)  # Same (already low)\n",
        "\n",
        "    # Use maximum feasible epochs based on recommendations\n",
        "    # Check if EPOCH_RECOMMENDATIONS exists from epoch analysis\n",
        "    if 'EPOCH_RECOMMENDATIONS' in globals():\n",
        "        max_epochs = EPOCH_RECOMMENDATIONS.get('maximum_safe', 15)\n",
        "        min_epochs = max(EPOCH_RECOMMENDATIONS.get('min_epochs', 3), 3)  # At least 3\n",
        "    else:\n",
        "        # Default range: 3 to 15 epochs (reasonable maximum)\n",
        "        min_epochs = 3\n",
        "        max_epochs = 15\n",
        "\n",
        "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", min_epochs, max_epochs)\n",
        "\n",
        "    return {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"num_train_epochs\": num_train_epochs,\n",
        "    }\n",
        "\n",
        "# Training arguments template (same as grid search)\n",
        "random_training_args = TrainingArguments(\n",
        "    output_dir=\"./random_search_results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    warmup_steps=500,\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        CLINICAL_BERT,\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "\n",
        "\n",
        "# Initialize trainer for random search\n",
        "random_trainer = WeightedTrainer(\n",
        "    model_init=model_init,\n",
        "    args=random_training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"--- Starting Random Search ---\")\n",
        "print(\"Random Search will sample 6 trials from the hyperparameter space\")\n",
        "print(\"This allows exploration of continuous ranges efficiently.\")\n",
        "\n",
        "# Display epoch range being used\n",
        "if 'EPOCH_RECOMMENDATIONS' in globals():\n",
        "    max_epochs = EPOCH_RECOMMENDATIONS.get('maximum_safe', 15)\n",
        "    min_epochs = max(EPOCH_RECOMMENDATIONS.get('min_epochs', 3), 3)\n",
        "    print(f\"Epoch range: {min_epochs}-{max_epochs} (from EPOCH_RECOMMENDATIONS)\")\n",
        "else:\n",
        "    print(f\"Epoch range: 3-15 (default maximum)\")\n",
        "print()\n",
        "\n",
        "# Track start time\n",
        "random_start_time = time.time()\n",
        "\n",
        "# Execute Random Search\n",
        "# Use same number of trials as grid search for fair comparison\n",
        "random_best_trial = random_trainer.hyperparameter_search(\n",
        "    backend=\"optuna\",\n",
        "    hp_space=random_search_hp_space,\n",
        "    direction=\"maximize\",\n",
        "    n_trials=6,  # Same number of trials as grid search for fair comparison\n",
        ")\n",
        "\n",
        "random_end_time = time.time()\n",
        "random_total_time = random_end_time - random_start_time\n",
        "\n",
        "print(f\"\\n--- Random Search Complete (Time: {random_total_time:.2f} seconds) ---\")\n",
        "print(\"\\nBEST HYPERPARAMETERS FROM RANDOM SEARCH:\")\n",
        "if random_best_trial:\n",
        "    print(random_best_trial)\n",
        "    random_best_hps = random_best_trial.hyperparameters\n",
        "    print(\"\\nBest Hyperparameters:\")\n",
        "    for key, value in random_best_hps.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    print(f\"\\nBest F1 Score: {random_best_trial.objective:.4f}\")\n",
        "else:\n",
        "    print(\"Random search failed or no best trial found.\")\n",
        "    random_best_hps = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bbe7cc",
      "metadata": {
        "id": "e4bbe7cc"
      },
      "source": [
        "### F3.3: Extract All Trial Results and Log to Excel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LLXOkH_JnADl",
      "metadata": {
        "id": "LLXOkH_JnADl"
      },
      "source": [
        "This cell attempts to extract all trial results from Random Search. The transformers library does not directly expose all trials, so this code tries to access them through Optuna's study storage.\n",
        "\n",
        "The extract_trial_results function takes an Optuna study object and extracts completed trials. It loops through all trials and collects their parameters and results. Each result includes trial number, hyperparameters, and F1 score.\n",
        "\n",
        "The code tries to access the study objects from both trainers. If this fails, it prints a note explaining the limitation. The best trial information remains available even if individual trial extraction fails.\n",
        "\n",
        "The code creates a summary dataframe that compares both strategies. It includes best F1 scores, best hyperparameters, total trials, and execution times. This summary helps you understand the results at a glance.\n",
        "\n",
        "The summary gets printed to the console so you can see it immediately. You also use this data when creating the Excel log file in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2885c88",
      "metadata": {
        "id": "a2885c88"
      },
      "outputs": [],
      "source": [
        "# Prepare Random Search results for Excel logging\n",
        "# Note: Individual trial extraction is limited by transformers library\n",
        "# We'll log the best trial results with full metrics\n",
        "\n",
        "print(\"Preparing Random Search results for Excel logging...\")\n",
        "print(\"Note: Individual trial extraction may be limited by transformers library.\")\n",
        "print(\"Best trial results will be logged to Excel with full metrics.\")\n",
        "print(\"Creating summary and Excel log sheet...\")\n",
        "\n",
        "# Create summary data for Excel logging\n",
        "# Since we can't easily extract all individual trials from hyperparameter_search,\n",
        "# we'll create a summary with the best Random Search results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create summary data for Excel\n",
        "summary_data = []\n",
        "\n",
        "# Random Search Summary\n",
        "if random_best_trial:\n",
        "    summary_data.append({\n",
        "        \"Search_Type\": \"Random Search (Automated)\",\n",
        "        \"Best_F1_Score\": random_best_trial.objective,\n",
        "        \"Best_Learning_Rate\": random_best_hps.get(\"learning_rate\", \"N/A\"),\n",
        "        \"Best_Batch_Size\": random_best_hps.get(\"per_device_train_batch_size\", \"N/A\"),\n",
        "        \"Best_Weight_Decay\": random_best_hps.get(\"weight_decay\", \"N/A\"),\n",
        "        \"Best_Epochs\": random_best_hps.get(\"num_train_epochs\", \"N/A\"),\n",
        "        \"Total_Trials\": 6,  # Updated for fast config\n",
        "        \"Total_Time_Seconds\": random_total_time,\n",
        "        \"Time_Per_Trial_Seconds\": random_total_time / 6,\n",
        "        \"Strategy\": \"Random Sampling - Continuous ranges\",\n",
        "    })\n",
        "\n",
        "if summary_data:\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(\"\\n=== RANDOM SEARCH SUMMARY ===\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    print(\"\\nNote: This will be compared to Exercise F2 manual experiments in the Excel file.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Random Search did not complete. Please run Random Search first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jLiRXiKLDo1V",
      "metadata": {
        "id": "jLiRXiKLDo1V"
      },
      "source": [
        "In this section of my code, I create a comprehensive Excel workbook to log and analyze the results from my Random Search hyperparameter optimization experiment (Exercise F3). I start by initializing a new workbook using Workbook() from the openpyxl library and naming the active worksheet \"F3_Random_Search_Results\".  I record the best trial results in row 2, including my member number, a \"Best\" label, all hyperparameters retrieved using .get() with \"N/A\" fallbacks, the objective F1 score, total training time, and a formatted timestamp. I then create a second worksheet called \"Comparison_Analysis\" with four columns to compare my automated Random Search results against my previous manual tuning from Exercise F2, populating it with three key metrics: Best F1 Score (4 decimals), Total Time (2 decimals), and Efficiency calculated as F1/Time (6 decimals) with zero-division protection. Below the comparison data, I add bolded \"Analysis Notes:\" followed by four explanatory points about the differences between automated and manual approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273a6e28",
      "metadata": {
        "id": "273a6e28"
      },
      "outputs": [],
      "source": [
        "# Create Excel log sheet for Random Search only\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"F3_Random_Search_Results\"\n",
        "\n",
        "# Header styling\n",
        "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "header_font = Font(bold=True, color=\"FFFFFF\")\n",
        "\n",
        "# Write headers\n",
        "headers = [\n",
        "    \"Member\", \"Trial #\", \"Learning Rate\", \"Batch Size\", \"Weight Decay\",\n",
        "    \"Epochs\", \"F1 Score\", \"Accuracy\", \"Precision\", \"Recall\",\n",
        "    \"Training Time (s)\", \"Timestamp\"\n",
        "]\n",
        "\n",
        "for col_idx, header in enumerate(headers, 1):\n",
        "    cell = ws.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "row = 2\n",
        "\n",
        "# Add Random Search best result\n",
        "if random_best_trial:\n",
        "    ws.cell(row=row, column=1, value=f\"Member 3\")  # Use member number from config\n",
        "    ws.cell(row=row, column=2, value=\"Best\")\n",
        "    ws.cell(row=row, column=3, value=random_best_hps.get(\"learning_rate\", \"N/A\"))\n",
        "    ws.cell(row=row, column=4, value=random_best_hps.get(\"per_device_train_batch_size\", \"N/A\"))\n",
        "    ws.cell(row=row, column=5, value=random_best_hps.get(\"weight_decay\", \"N/A\"))\n",
        "    ws.cell(row=row, column=6, value=random_best_hps.get(\"num_train_epochs\", \"N/A\"))\n",
        "    ws.cell(row=row, column=7, value=random_best_trial.objective)\n",
        "    ws.cell(row=row, column=11, value=random_total_time)\n",
        "    ws.cell(row=row, column=12, value=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "    row += 1\n",
        "\n",
        "# Add comparison sheet (Random Search vs Exercise F2)\n",
        "ws2 = wb.create_sheet(\"Comparison_Analysis\")\n",
        "\n",
        "comparison_headers = [\n",
        "    \"Metric\", \"Random Search (Automated)\", \"Exercise F2 (Manual)\", \"Notes\"\n",
        "]\n",
        "\n",
        "for col_idx, header in enumerate(comparison_headers, 1):\n",
        "    cell = ws2.cell(row=1, column=col_idx, value=header)\n",
        "    cell.fill = header_fill\n",
        "    cell.font = header_font\n",
        "    cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "# Comparison data (you'll need to add Exercise F2 best F1 score manually)\n",
        "comparison_data = []\n",
        "\n",
        "if random_best_trial:\n",
        "    comparison_data.append([\n",
        "        \"Best F1 Score\",\n",
        "        f\"{random_best_trial.objective:.4f}\",\n",
        "        \"Add Exercise F2 best F1 here\",\n",
        "        \"Random Search uses automated optimization\"\n",
        "    ])\n",
        "\n",
        "    comparison_data.append([\n",
        "        \"Total Time (seconds)\",\n",
        "        f\"{random_total_time:.2f}\",\n",
        "        \"Add Exercise F2 total time here\",\n",
        "        \"Time for 6 automated trials\"\n",
        "    ])\n",
        "\n",
        "    # Efficiency\n",
        "    random_efficiency = random_best_trial.objective / random_total_time if random_total_time > 0 else 0\n",
        "    comparison_data.append([\n",
        "        \"Efficiency (F1/Time)\",\n",
        "        f\"{random_efficiency:.6f}\",\n",
        "        \"Calculate from F2\",\n",
        "        \"Higher is better\"\n",
        "    ])\n",
        "\n",
        "# Write comparison data\n",
        "for row_idx, data in enumerate(comparison_data, 2):\n",
        "    for col_idx, value in enumerate(data, 1):\n",
        "        ws2.cell(row=row_idx, column=col_idx, value=value)\n",
        "\n",
        "# Add analysis notes\n",
        "notes_row = len(comparison_data) + 3\n",
        "ws2.cell(row=notes_row, column=1, value=\"Analysis Notes:\").font = Font(bold=True)\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"1. Random Search uses automated hyperparameter optimization\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"2. Exercise F2 used manual hyperparameter tuning\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"3. Random Search can explore continuous hyperparameter ranges\")\n",
        "notes_row += 1\n",
        "ws2.cell(row=notes_row, column=1, value=\"4. Efficiency = Best F1 Score / Total Time\")\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min(max_length + 2, 30)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "excel_filename = f\"Exercise_F3_Random_Search{3}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "wb.save(excel_filename)\n",
        "\n",
        "print(f\"\\n‚úÖ Excel log saved: {excel_filename}\")\n",
        "print(f\"   - Sheet 1: F3_Random_Search_Results\")\n",
        "print(f\"   - Sheet 2: Comparison_Analysis (vs Exercise F2)\")\n",
        "\n",
        "# Automatically download the file\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(excel_filename)\n",
        "    print(f\"‚úÖ File automatically downloaded: {excel_filename}\")\n",
        "except ImportError:\n",
        "    print(\"Note: Not running in Google Colab. File saved locally.\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not auto-download. File saved at: {excel_filename}\")\n",
        "    print(f\"   Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tJmPQTqk6Gky",
      "metadata": {
        "id": "tJmPQTqk6Gky"
      },
      "source": [
        "## Stress Identification System\n",
        "\n",
        "**Function Description:**\n",
        "\n",
        "This system identifies patients experiencing stress from their statements using a fine-tuned transformer model. It provides multiple fallback strategies for loading trained models, processes patient statements through the model, and returns detailed predictions with probability scores. The system includes utility functions for displaying results, filtering stress cases, and ensuring the model is properly loaded before use.\n",
        "\n",
        "\n",
        "**Syntax Explanation:**\n",
        "\n",
        "* `LABEL_MAP` dictionary - Maps numeric class indices (0-6) to human-readable mental health labels\n",
        "* `STRESS_LABEL = 5` - Defines stress as class 5 in the classification scheme\n",
        "* **Strategy 1**: `AutoTokenizer.from_pretrained(model_dir)` and `AutoModelForSequenceClassification.from_pretrained(model_dir)` - Attempts to load from saved directory if `best_name` variable exists\n",
        "* **Strategy 2**: Tries default saved directory path `\"./best_model_expB_clinicalbert_bs16_lr5e-5_ep4\"`\n",
        "* **Strategy 3**: `results.items()` - Iterates through results dictionary to find trainer with highest F1 score\n",
        "* `metrics.get('eval_f1', 0)` - Safely retrieves F1 score with default value of 0\n",
        "* `best_trainer_obj.model` - Extracts the trained model from the best trainer object\n",
        "* **Strategy 4**: Uses `best_trainer.model` if available in global scope\n",
        "* **Strategy 5**: `AutoModelForSequenceClassification.from_pretrained(CLINICAL_BERT, num_labels=num_labels)` - Loads pre-trained model as last resort (not fine-tuned)\n",
        "* `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` - Detects and sets appropriate device (GPU or CPU)\n",
        "* `model.to(device)` - Moves model to the selected device\n",
        "* `model.eval()` - Sets model to evaluation mode (disables dropout, batch normalization updates)\n",
        "* `identify_stress()` function - Main prediction function with automatic model loading capabilities\n",
        "* `isinstance(statements, str)` - Checks if input is single statement or list\n",
        "* `tokenizer(statements, padding=True, truncation=True, max_length=160, return_tensors=\"pt\")` - Tokenizes input text with padding, truncation to 160 tokens, and returns PyTorch tensors\n",
        "* `.to(device)` - Moves tokenized inputs to correct device\n",
        "* `torch.no_grad()` - Disables gradient computation for inference (saves memory and speeds up)\n",
        "* `torch.softmax(logits, dim=-1)` - Converts raw model outputs to probability distributions\n",
        "* `np.argmax(probabilities, axis=-1)` - Gets predicted class by finding highest probability\n",
        "* `stress_prob = probs[STRESS_LABEL]` - Extracts probability for stress class specifically\n",
        "* `stress_prob >= stress_threshold` - Checks if stress probability exceeds threshold (default 0.3)\n",
        "* `result[\"all_probabilities\"]` - Optional dictionary comprehension creating label-to-probability mapping\n",
        "* `display_stress_results()` - Formats and prints results in readable format with stress warnings\n",
        "* `filter_stress_cases()` - List comprehension filtering only cases with detected stress\n",
        "* `ensure_model_loaded()` - Helper function that attempts all loading strategies to ensure model availability\n",
        "\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "The system requires a trained model (from previous fine-tuning experiments) and can accept either a single patient statement as a string or a list of statements. Optional parameters include custom model/tokenizer objects, `return_all_probs` flag, and `stress_threshold` value.\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "Returns a dictionary (for single input) or list of dictionaries (for multiple inputs) containing:\n",
        "* Original statement\n",
        "* Predicted class (numeric and label)\n",
        "* Stress detection flags (`is_stress`, `above_threshold`, `needs_attention`)\n",
        "* Stress probability score\n",
        "* Optionally all class probabilities\n",
        "\n",
        "The `display_stress_results()` function provides formatted console output with visual indicators (‚ö†Ô∏è for stress detected, ‚úì for no stress).\n",
        "\n",
        "\n",
        "**Code Flow:**\n",
        "\n",
        "The cell first attempts to load a trained model using five fallback strategies in order of preference, from most specific (saved best model directory) to most general (pre-trained base model). Once loaded, the model is moved to the appropriate device and set to evaluation mode. The `identify_stress()` function handles automatic model loading if needed, tokenizes input statements, runs inference, applies softmax to get probabilities, and packages results into dictionaries. Helper functions provide additional functionality for displaying results in readable format, filtering stress cases, and ensuring model availability.\n",
        "\n",
        "\n",
        "**Comments and Observations:**\n",
        "\n",
        "The multiple fallback strategies ensure robustness - the system can find the trained model in various scenarios depending on which cells were run and in what order. Strategy 3 (extracting from results dictionary) is most reliable after running training experiments. Strategy 5 (pre-trained model) works but provides warnings since the model hasn't been fine-tuned on your data yet, resulting in lower accuracy. The stress threshold of 0.3 (30%) catches cases where stress isn't the top prediction but has significant probability, improving recall for this critical use case. The `needs_attention` flag combines both direct stress predictions and threshold-based detection for comprehensive screening. Setting `max_length=160` balances capturing full patient statements while staying efficient. The automatic device detection ensures the code works on both GPU and CPU systems. The `eval()` mode is critical for accurate predictions as it disables training-specific behaviors like dropout. The probability extraction `probs[STRESS_LABEL]` allows monitoring stress likelihood even when other conditions are predicted, which is valuable for clinical decision support where multiple concerns may coexist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ghIvC7cr4p2G",
      "metadata": {
        "id": "ghIvC7cr4p2G"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Stress Identification System\n",
        "# Identifies patients experiencing stress from their statements\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Label mapping (from the dataset encoding)\n",
        "LABEL_MAP = {\n",
        "    0: \"Anxiety\",\n",
        "    1: \"Bipolar\",\n",
        "    2: \"Depression\",\n",
        "    3: \"Normal\",\n",
        "    4: \"Personality disorder\",\n",
        "    5: \"Stress\",\n",
        "    6: \"Suicidal\"\n",
        "}\n",
        "\n",
        "STRESS_LABEL = 5  # Stress is class 5\n",
        "\n",
        "# Load the best model (use the saved model from previous experiments)\n",
        "# Multiple fallback strategies to find the trained model\n",
        "stress_model = None\n",
        "stress_tokenizer = None\n",
        "model_loaded = False\n",
        "\n",
        "# Strategy 1: Try to load from saved directory (if best_name exists)\n",
        "if 'best_name' in globals():\n",
        "    try:\n",
        "        model_dir = f\"./best_model_{best_name}\"\n",
        "        stress_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "        stress_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        print(f\"‚úÖ Loaded model from saved directory: {model_dir}\")\n",
        "        model_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not load from {model_dir}: {e}\")\n",
        "\n",
        "# Strategy 2: Try default saved directory\n",
        "if not model_loaded:\n",
        "    try:\n",
        "        model_dir = \"./best_model_expB_clinicalbert_bs16_lr5e-5_ep4\"\n",
        "        stress_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "        stress_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        print(f\"‚úÖ Loaded model from default directory: {model_dir}\")\n",
        "        model_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not load from default directory: {e}\")\n",
        "\n",
        "# Strategy 3: Extract best model from results dictionary\n",
        "if not model_loaded and 'results' in globals():\n",
        "    try:\n",
        "        # Find the best model from results\n",
        "        best_f1 = -1.0\n",
        "        best_trainer_obj = None\n",
        "        for name, (metrics, trainer) in results.items():\n",
        "            if metrics.get('eval_f1', 0) > best_f1:\n",
        "                best_f1 = metrics.get('eval_f1', 0)\n",
        "                best_trainer_obj = trainer\n",
        "\n",
        "        if best_trainer_obj is not None:\n",
        "            stress_model = best_trainer_obj.model\n",
        "            stress_tokenizer = tokenizer if 'tokenizer' in globals() else AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "            print(f\"‚úÖ Using best model from results dictionary (F1={best_f1:.4f})\")\n",
        "            model_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not extract model from results: {e}\")\n",
        "\n",
        "# Strategy 4: Use best_trainer if available\n",
        "if not model_loaded and 'best_trainer' in globals():\n",
        "    try:\n",
        "        stress_model = best_trainer.model\n",
        "        stress_tokenizer = tokenizer if 'tokenizer' in globals() else AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "        print(\"‚úÖ Using best_trainer's model\")\n",
        "        model_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not use best_trainer: {e}\")\n",
        "\n",
        "# Strategy 5: Load pre-trained model as last resort (will need fine-tuning)\n",
        "if not model_loaded:\n",
        "    try:\n",
        "        CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "        num_labels = 7  # Default: 7 classes (Anxiety, Bipolar, Depression, Normal, Personality disorder, Stress, Suicidal)\n",
        "\n",
        "        # Try to get num_labels from existing data\n",
        "        if 'y_train' in globals():\n",
        "            num_labels = len(np.unique(y_train))\n",
        "\n",
        "        stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "        stress_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            CLINICAL_BERT,\n",
        "            num_labels=num_labels\n",
        "        )\n",
        "        print(\"‚ö†Ô∏è  Loaded PRE-TRAINED model (not fine-tuned).\")\n",
        "        print(\"   This model has NOT been trained on your data yet.\")\n",
        "        print(\"   For best results, please run the training cells first.\")\n",
        "        print(\"   You can still use this model, but accuracy will be lower.\")\n",
        "        model_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not load pre-trained model: {e}\")\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"INSTRUCTIONS:\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"To use the stress identification system:\")\n",
        "        print(\"1. Run the training cells (Cell 12) to fine-tune the model\")\n",
        "        print(\"2. Run the model saving cell (Cell 15) to save the best model\")\n",
        "        print(\"3. Then run this cell again\")\n",
        "        print(\"=\"*80)\n",
        "        stress_model = None\n",
        "        stress_tokenizer = None\n",
        "\n",
        "if stress_model is not None:\n",
        "    # Ensure device is available\n",
        "    if 'device' not in globals():\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Device set to: {device}\")\n",
        "\n",
        "    stress_model = stress_model.to(device)\n",
        "    stress_model.eval()  # Set to evaluation mode\n",
        "    print(f\"‚úÖ Model loaded and ready on device: {device}\")\n",
        "\n",
        "def identify_stress(statements, model=None, tokenizer=None,\n",
        "                   return_all_probs=False, stress_threshold=0.3):\n",
        "    \"\"\"\n",
        "    Identify patients experiencing stress from their statements.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    statements : str or list of str\n",
        "        Single statement or list of patient statements\n",
        "    model : torch.nn.Module, optional\n",
        "        Trained classification model (if None, uses global stress_model)\n",
        "    tokenizer : AutoTokenizer, optional\n",
        "        Tokenizer for the model (if None, uses global stress_tokenizer)\n",
        "    return_all_probs : bool\n",
        "        If True, return probabilities for all classes\n",
        "    stress_threshold : float\n",
        "        Minimum probability threshold to consider as stress (default: 0.3)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict or list of dict\n",
        "        Prediction results with stress identification\n",
        "    \"\"\"\n",
        "    # Use global model/tokenizer if not provided, or try to load automatically\n",
        "    global stress_model, stress_tokenizer, device\n",
        "\n",
        "    # Debug: Check current state\n",
        "    # print(f\"DEBUG: model={model is not None}, stress_model={stress_model is not None}, tokenizer={tokenizer is not None}, stress_tokenizer={stress_tokenizer is not None}\")\n",
        "\n",
        "    if model is None:\n",
        "        if stress_model is not None:\n",
        "            model = stress_model\n",
        "        else:\n",
        "            # Try to load model automatically from results\n",
        "            if 'results' in globals():\n",
        "                try:\n",
        "                    best_f1 = -1.0\n",
        "                    best_trainer_obj = None\n",
        "                    for name, (metrics, trainer) in results.items():\n",
        "                        if metrics.get('eval_f1', 0) > best_f1:\n",
        "                            best_f1 = metrics.get('eval_f1', 0)\n",
        "                            best_trainer_obj = trainer\n",
        "\n",
        "                    if best_trainer_obj is not None:\n",
        "                        stress_model = best_trainer_obj.model\n",
        "                        model = stress_model\n",
        "                        if stress_tokenizer is None:\n",
        "                            if 'tokenizer' in globals():\n",
        "                                stress_tokenizer = tokenizer\n",
        "                            else:\n",
        "                                CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "                                stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "                        print(f\"‚úÖ Auto-loaded model from results (F1={best_f1:.4f})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è  Could not auto-load from results: {e}\")\n",
        "\n",
        "            # If still None, try pre-trained model\n",
        "            if model is None:\n",
        "                try:\n",
        "                    CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "                    num_labels = 7\n",
        "                    if 'y_train' in globals():\n",
        "                        num_labels = len(np.unique(y_train))\n",
        "                    stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "                    stress_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                        CLINICAL_BERT, num_labels=num_labels\n",
        "                    )\n",
        "                    model = stress_model\n",
        "                    print(\"‚ö†Ô∏è  Auto-loaded PRE-TRAINED model (not fine-tuned)\")\n",
        "                except Exception as e:\n",
        "                    raise ValueError(f\"Model not loaded and could not auto-load: {e}\\nPlease run the model loading cell (Cell 30) first.\")\n",
        "\n",
        "    if tokenizer is None:\n",
        "        if stress_tokenizer is not None:\n",
        "            tokenizer = stress_tokenizer\n",
        "        else:\n",
        "            # Try to load tokenizer\n",
        "            if 'tokenizer' in globals():\n",
        "                stress_tokenizer = tokenizer\n",
        "                tokenizer = stress_tokenizer\n",
        "            else:\n",
        "                try:\n",
        "                    CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "                    stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "                    tokenizer = stress_tokenizer\n",
        "                except Exception as e:\n",
        "                    raise ValueError(f\"Tokenizer not loaded and could not auto-load: {e}\\nPlease run the model loading cell (Cell 30) first.\")\n",
        "\n",
        "    # Ensure device is available and model is on correct device\n",
        "    if 'device' not in globals():\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    else:\n",
        "        device = globals()['device']\n",
        "\n",
        "    # Ensure model is on the correct device and in eval mode\n",
        "    if model is not None:\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "        # Update global stress_model if it was just loaded\n",
        "        if stress_model is not None and stress_model is not model:\n",
        "            stress_model = model\n",
        "\n",
        "    # Convert single statement to list\n",
        "    if isinstance(statements, str):\n",
        "        statements = [statements]\n",
        "        single_input = True\n",
        "    else:\n",
        "        single_input = False\n",
        "\n",
        "    # Tokenize statements\n",
        "    encoded = tokenizer(\n",
        "        statements,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=160,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "        predictions = np.argmax(probabilities, axis=-1)\n",
        "\n",
        "    # Process results\n",
        "    results = []\n",
        "    for i, (statement, pred, probs) in enumerate(zip(statements, predictions, probabilities)):\n",
        "        stress_prob = probs[STRESS_LABEL]\n",
        "        is_stress = pred == STRESS_LABEL\n",
        "        above_threshold = stress_prob >= stress_threshold\n",
        "\n",
        "        result = {\n",
        "            \"statement\": statement,\n",
        "            \"predicted_class\": int(pred),\n",
        "            \"predicted_label\": LABEL_MAP[int(pred)],\n",
        "            \"is_stress\": is_stress,\n",
        "            \"stress_probability\": float(stress_prob),\n",
        "            \"above_threshold\": above_threshold,\n",
        "            \"needs_attention\": is_stress or above_threshold\n",
        "        }\n",
        "\n",
        "        if return_all_probs:\n",
        "            result[\"all_probabilities\"] = {\n",
        "                LABEL_MAP[i]: float(prob) for i, prob in enumerate(probs)\n",
        "            }\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    return results[0] if single_input else results\n",
        "\n",
        "def display_stress_results(results):\n",
        "    \"\"\"\n",
        "    Display stress identification results in a readable format.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    results : dict or list of dict\n",
        "        Results from identify_stress function\n",
        "    \"\"\"\n",
        "    if isinstance(results, dict):\n",
        "        results = [results]\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STRESS IDENTIFICATION RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    stress_count = sum(1 for r in results if r['is_stress'] or r['above_threshold'])\n",
        "\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"\\n[Patient Statement {i}]\")\n",
        "        print(f\"Statement: {result['statement']}\")\n",
        "        print(f\"Predicted Class: {result['predicted_label']} (Class {result['predicted_class']})\")\n",
        "        print(f\"Stress Probability: {result['stress_probability']:.1%}\")\n",
        "\n",
        "        if result['is_stress']:\n",
        "            print(\"‚ö†Ô∏è  STRESS DETECTED - Primary Prediction\")\n",
        "        elif result['above_threshold']:\n",
        "            print(\"‚ö†Ô∏è  STRESS LIKELY - Above threshold\")\n",
        "        else:\n",
        "            print(\"‚úì No significant stress detected\")\n",
        "\n",
        "        if 'all_probabilities' in result:\n",
        "            print(\"\\nAll Class Probabilities:\")\n",
        "            for label, prob in sorted(result['all_probabilities'].items(),\n",
        "                                     key=lambda x: x[1], reverse=True):\n",
        "                marker = \" ‚Üê\" if label == result['predicted_label'] else \"\"\n",
        "                print(f\"  {label}: {prob:.1%}{marker}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"Summary: {stress_count} out of {len(results)} patients show signs of stress\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "def filter_stress_cases(results):\n",
        "    \"\"\"\n",
        "    Filter and return only cases where stress is detected.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    results : dict or list of dict\n",
        "        Results from identify_stress function\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list of dict\n",
        "        Only cases with stress detected\n",
        "    \"\"\"\n",
        "    if isinstance(results, dict):\n",
        "        results = [results]\n",
        "\n",
        "    return [r for r in results if r['is_stress'] or r['above_threshold']]\n",
        "\n",
        "def ensure_model_loaded():\n",
        "    \"\"\"\n",
        "    Helper function to ensure model and tokenizer are loaded.\n",
        "    Can be called before using identify_stress if needed.\n",
        "    \"\"\"\n",
        "    global stress_model, stress_tokenizer, device\n",
        "\n",
        "    if stress_model is None or stress_tokenizer is None:\n",
        "        print(\"‚ö†Ô∏è  Model not loaded. Attempting to load now...\")\n",
        "\n",
        "        # Try Strategy 3: Extract from results (most likely to work if training was done)\n",
        "        if 'results' in globals():\n",
        "            try:\n",
        "                best_f1 = -1.0\n",
        "                best_trainer_obj = None\n",
        "                for name, (metrics, trainer) in results.items():\n",
        "                    if metrics.get('eval_f1', 0) > best_f1:\n",
        "                        best_f1 = metrics.get('eval_f1', 0)\n",
        "                        best_trainer_obj = trainer\n",
        "\n",
        "                if best_trainer_obj is not None:\n",
        "                    stress_model = best_trainer_obj.model\n",
        "                    if 'tokenizer' in globals():\n",
        "                        stress_tokenizer = tokenizer\n",
        "                    else:\n",
        "                        CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "                        stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "                    print(f\"‚úÖ Loaded model from results dictionary (F1={best_f1:.4f})\")\n",
        "                else:\n",
        "                    raise ValueError(\"No trainer found in results\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è  Could not load from results: {e}\")\n",
        "\n",
        "        # Try Strategy 5: Load pre-trained model\n",
        "        if stress_model is None:\n",
        "            try:\n",
        "                CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "                num_labels = 7\n",
        "                if 'y_train' in globals():\n",
        "                    num_labels = len(np.unique(y_train))\n",
        "\n",
        "                stress_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "                stress_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                    CLINICAL_BERT, num_labels=num_labels\n",
        "                )\n",
        "                print(\"‚ö†Ô∏è  Loaded PRE-TRAINED model (not fine-tuned)\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Could not load model: {e}\")\n",
        "                raise\n",
        "\n",
        "    # Ensure device is set\n",
        "    if 'device' not in globals():\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move model to device and set to eval mode\n",
        "    if stress_model is not None:\n",
        "        stress_model = stress_model.to(device)\n",
        "        stress_model.eval()\n",
        "\n",
        "    return stress_model is not None and stress_tokenizer is not None\n",
        "\n",
        "# Example usage with sample patient statements\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STRESS IDENTIFICATION SYSTEM READY\")\n",
        "print(\"=\" * 80)\n",
        "if stress_model is not None and stress_tokenizer is not None:\n",
        "    print(\"‚úÖ Model and tokenizer are loaded and ready!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not yet loaded. Run ensure_model_loaded() if needed.\")\n",
        "print(\"\\nExample Usage:\")\n",
        "print(\"  results = identify_stress('I feel overwhelmed and cannot cope with work')\")\n",
        "print(\"  display_stress_results(results)\")\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oqnViib19RdF",
      "metadata": {
        "id": "oqnViib19RdF"
      },
      "source": [
        "## Quick Test - Stress Identification System\n",
        "\n",
        "**Function Description:**\n",
        "\n",
        "This cell performs a quick verification test to ensure the stress identification system is properly loaded and functioning. It runs a simple test statement through the model and displays the results, providing immediate feedback on whether the system is ready for use or if troubleshooting is needed.\n",
        "\n",
        "\n",
        "**Syntax Explanation:**\n",
        "\n",
        "* `print(\"=\" * 80)` - Creates a visual separator line of 80 equal signs for better readability\n",
        "* `try-except` block - Wraps the test in error handling to catch and gracefully handle any loading or prediction errors\n",
        "* `test_statement = \"I feel very stressed and overwhelmed\"` - Defines a sample patient statement that should trigger stress detection\n",
        "* `identify_stress(test_statement)` - Calls the main prediction function with the test statement\n",
        "* `result['predicted_label']` - Accesses the human-readable predicted class label from the result dictionary\n",
        "* `result['stress_probability']:.1%` - Formats the stress probability as a percentage with one decimal place\n",
        "* `result['is_stress']` - Boolean flag indicating whether stress was the top predicted class\n",
        "* `‚úÖ` and `‚ùå` emoji markers - Visual indicators for success or failure status\n",
        "* `Exception as e` - Catches any errors that occur during model loading or prediction\n",
        "* `print(f\"‚ùå Error: {e}\")` - Displays the specific error message to help with debugging\n",
        "* Troubleshooting guide - Prints step-by-step instructions if the test fails\n",
        "\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "This cell requires that the stress identification system (from the previous cell) has been run. It uses the globally loaded `stress_model`, `stress_tokenizer`, and the `identify_stress()` function. No user input is required - the test statement is hardcoded.\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "**Success case**: Displays a success message with the test statement, predicted label, stress probability percentage, and a confirmation that the system is ready.\n",
        "\n",
        "**Failure case**: Shows an error message with the specific exception, followed by a detailed troubleshooting guide with numbered steps to resolve common issues (model not loaded, training not completed, etc.).\n",
        "\n",
        "\n",
        "**Code Flow:**\n",
        "\n",
        "The cell starts by printing a header announcing the test. It then enters a try-except block where it defines a test statement, passes it to `identify_stress()`, and if successful, extracts and displays key information from the result dictionary including the predicted label and stress probability. If any exception occurs (model not loaded, function not defined, etc.), the except block catches it, displays the error, and prints a comprehensive troubleshooting guide with step-by-step instructions for common problems.\n",
        "\n",
        "\n",
        "**Comments and Observations:**\n",
        "\n",
        "This test cell serves as a quick sanity check before running the system on real patient data. The test statement \"I feel very stressed and overwhelmed\" is deliberately designed to have clear stress indicators, so it should reliably detect stress if the model is working correctly. If this test fails, it typically means either the model hasn't been loaded yet (run Cell 30), or the model hasn't been trained yet (run Cell 12 first). The troubleshooting guide provides clear next steps based on common failure scenarios. Running this test is recommended before analyzing actual patient statements to avoid wasting time on a non-functional system. The formatted output with emoji indicators makes it immediately obvious whether everything is working - you should see green checkmarks if successful. This cell is safe to run multiple times and can be used as a quick verification after making any changes to the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "srgKMhk34rmn",
      "metadata": {
        "id": "srgKMhk34rmn"
      },
      "outputs": [],
      "source": [
        "# Quick test to verify model is loaded and working\n",
        "print(\"Testing stress identification system...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Test with a simple statement\n",
        "    test_statement = \"I feel very stressed and overwhelmed\"\n",
        "    result = identify_stress(test_statement)\n",
        "\n",
        "    print(f\"‚úÖ Model is loaded and working!\")\n",
        "    print(f\"\\nTest Statement: '{test_statement}'\")\n",
        "    print(f\"Predicted: {result['predicted_label']}\")\n",
        "    print(f\"Stress Probability: {result['stress_probability']:.1%}\")\n",
        "    print(f\"Is Stress: {result['is_stress']}\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"‚úÖ System is ready to analyze patient statements!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TROUBLESHOOTING:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"1. Make sure you have run Cell 30 (Stress Identification System)\")\n",
        "    print(\"2. If you see 'Model not loaded', try running Cell 12 (Training) first\")\n",
        "    print(\"3. Then re-run Cell 30 to load the trained model\")\n",
        "    print(\"4. If 'results' dictionary exists, the model will auto-load from there\")\n",
        "    print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A14awR0W9poW",
      "metadata": {
        "id": "A14awR0W9poW"
      },
      "source": [
        "## Example: Stress Identification Demo\n",
        "\n",
        "**Function Description:**\n",
        "\n",
        "This cell demonstrates the complete functionality of the stress identification system using real-world example patient statements. It shows how to analyze multiple statements at once, display comprehensive results with all class probabilities, filter only the stress cases for prioritized attention, and analyze individual statements. This serves as both a demonstration and a template for using the system in practice.\n",
        "\n",
        "\n",
        "**Syntax Explanation:**\n",
        "\n",
        "* `patient_statements = [...]` - Creates a list of 7 sample patient statements with varying levels and types of mental health concerns\n",
        "* `identify_stress(patient_statements, return_all_probs=True)` - Analyzes all statements at once with the flag to include probability scores for all 7 classes\n",
        "* `return_all_probs=True` - Optional parameter that adds complete probability distribution across all mental health categories to the results\n",
        "* `display_stress_results(results)` - Calls the display function to print formatted results with visual indicators and probability scores\n",
        "* `filter_stress_cases(results)` - Filters the results to return only cases where stress was detected (either as top prediction or above threshold)\n",
        "* `enumerate(stress_cases, 1)` - Iterates through filtered stress cases with 1-based indexing for readable numbering\n",
        "* `case['statement']` - Accesses the original patient statement from the result dictionary\n",
        "* `case['stress_probability']:.1%` - Formats stress probability as percentage with one decimal place\n",
        "* `case['predicted_label']` - Gets the human-readable predicted mental health category\n",
        "* `if stress_cases:` - Checks if any stress cases were found before attempting to display them\n",
        "* `identify_stress(\"single statement\", return_all_probs=True)` - Demonstrates analyzing a single statement (string input instead of list)\n",
        "* `display_stress_results(single_result)` - Shows results for single statement analysis\n",
        "\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "This cell uses the previously loaded stress identification system including the `identify_stress()`, `display_stress_results()`, and `filter_stress_cases()` functions. The input data consists of 7 hardcoded sample patient statements designed to represent a range of mental health states from healthy/normal to various levels of stress and anxiety. No external data files are required.\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "The cell produces three main output sections:\n",
        "\n",
        "* **Full Analysis Section**: Displays complete results for all 7 patient statements including predicted class, stress probability, detection flags (‚ö†Ô∏è or ‚úì), and probability distributions across all 7 mental health categories for each statement.\n",
        "\n",
        "* **Filtered Stress Cases Section**: Shows only the statements where stress was detected, providing a prioritized list of patients who need attention with their stress probability and predicted class.\n",
        "\n",
        "* **Single Statement Analysis Section**: Demonstrates analyzing one statement at a time, showing the same detailed output format as the full analysis but for a single patient.\n",
        "\n",
        "The output includes visual indicators, formatted percentages, summary statistics, and clear section headers for easy interpretation.\n",
        "\n",
        "\n",
        "**Code Flow:**\n",
        "\n",
        "The cell begins by defining a diverse set of 7 sample patient statements ranging from clear stress indicators to normal/healthy states. It then calls `identify_stress()` with the entire list and `return_all_probs=True` to get comprehensive results. These results are displayed using `display_stress_results()` which formats and prints all predictions with probabilities. Next, it filters only stress cases using `filter_stress_cases()` and displays them in a focused summary section. If no stress cases exist, it prints an appropriate message. Finally, it demonstrates single-statement analysis by processing one new statement individually and displaying its results, showing the flexibility of the system for both batch and individual analyses.\n",
        "\n",
        "\n",
        "**Comments and Observations:**\n",
        "\n",
        "This demo cell is designed to be educational and practical. The 7 sample statements were carefully chosen to represent real patient scenarios: statements 1, 3, 4, and 6 contain clear stress indicators and should trigger detection; statements 2, 5, and 7 represent normal/healthy states and should not trigger stress detection. This variety helps validate the model's accuracy and demonstrates both true positives and true negatives. The `return_all_probs=True` flag is particularly useful for clinical review because it shows not just the top prediction but the model's confidence distribution across all mental health categories - for example, a patient might be classified as \"Anxiety\" but have a high stress probability (30-40%) that still warrants attention. The filtered stress cases section is especially valuable in real-world applications where clinicians need to prioritize which patients require immediate follow-up. The single statement analysis at the end shows how the system can be used interactively for individual patient assessments during consultations. You can modify the `patient_statements` list with your own data or load statements from a file/database. The stress threshold (default 0.3 or 30%) can be adjusted in the `identify_stress()` function if you want to be more or less sensitive to potential stress cases - lower thresholds catch more cases but may have more false positives, while higher thresholds are more conservative but might miss some at-risk patients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vYrc2nJt4thN",
      "metadata": {
        "id": "vYrc2nJt4thN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# Example: Stress Identification Demo\n",
        "# ============================================================================\n",
        "\n",
        "# Sample patient statements for testing\n",
        "patient_statements = [\n",
        "    \"I feel overwhelmed and cannot cope with my workload. My chest feels tight and I can't sleep.\",\n",
        "    \"I'm doing great today, feeling calm and in control of my life.\",\n",
        "    \"The pressure at work is too much. I feel stressed all the time and it's affecting my health.\",\n",
        "    \"I have been experiencing anxiety attacks and feeling very stressed about my future.\",\n",
        "    \"Everything is fine, I'm managing well and feeling positive about things.\",\n",
        "    \"I can't handle this anymore. The stress is killing me and I don't know what to do.\",\n",
        "    \"I feel normal today, nothing out of the ordinary happening.\"\n",
        "]\n",
        "\n",
        "# Identify stress in all patient statements\n",
        "print(\"Analyzing patient statements for stress...\")\n",
        "print(\"\\n\")\n",
        "\n",
        "results = identify_stress(patient_statements, return_all_probs=True)\n",
        "\n",
        "# Display results\n",
        "display_stress_results(results)\n",
        "\n",
        "# Filter only stress cases\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FILTERED: PATIENTS WITH STRESS DETECTED\")\n",
        "print(\"=\" * 80)\n",
        "stress_cases = filter_stress_cases(results)\n",
        "\n",
        "if stress_cases:\n",
        "    for i, case in enumerate(stress_cases, 1):\n",
        "        print(f\"\\n[Stress Case {i}]\")\n",
        "        print(f\"Statement: {case['statement']}\")\n",
        "        print(f\"Stress Probability: {case['stress_probability']:.1%}\")\n",
        "        print(f\"Predicted Class: {case['predicted_label']}\")\n",
        "else:\n",
        "    print(\"\\nNo stress cases detected in the provided statements.\")\n",
        "\n",
        "# Example: Single statement analysis\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SINGLE STATEMENT ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "single_result = identify_stress(\n",
        "    \"I am extremely stressed about my exams and cannot focus on anything else.\",\n",
        "    return_all_probs=True\n",
        ")\n",
        "display_stress_results(single_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E_SIF1wm-F1U",
      "metadata": {
        "id": "E_SIF1wm-F1U"
      },
      "source": [
        "## Analyze CSV File for Stress Cases\n",
        "\n",
        "**Function Description:**\n",
        "\n",
        "This cell reads a CSV file containing patient statements and performs batch stress identification analysis on all records. It processes statements in configurable batches to manage memory efficiently, displays real-time progress updates, generates comprehensive statistics, shows example stress cases, and automatically saves results to timestamped CSV files. This is designed for large-scale analysis of patient datasets.\n",
        "\n",
        "\n",
        "**Syntax Explanation:**\n",
        "\n",
        "* `CSV_FILE = \"Combined Data.csv\"` - Specifies the name of the CSV file to analyze\n",
        "* `STATEMENT_COL = \"statement\"` - Defines which column contains the patient statements to analyze\n",
        "* `MAX_ROWS = None` - Optional limit on number of rows to process (None = process all rows)\n",
        "* `BATCH_SIZE = 100` - Number of statements to process in each batch for memory efficiency and progress tracking\n",
        "* `Path(CSV_FILE)` - Creates a Path object for better file path handling across operating systems\n",
        "* `csv_file.exists()` - Checks if the CSV file exists before attempting to load it\n",
        "* `pd.read_csv(csv_file)` - Loads the entire CSV file into a pandas DataFrame\n",
        "* `if STATEMENT_COL not in df.columns:` - Validates that the specified column name exists in the dataset\n",
        "* `df[STATEMENT_COL].astype(str).tolist()` - Extracts statements column, converts all to strings, and creates a Python list\n",
        "* `df.head(MAX_ROWS)` - Limits DataFrame to first MAX_ROWS if specified\n",
        "* `(total_statements + BATCH_SIZE - 1) // BATCH_SIZE` - Calculates number of batches using ceiling division\n",
        "* `for batch_num in range(num_batches):` - Iterates through each batch for processing\n",
        "* `min(start_idx + BATCH_SIZE, total_statements)` - Ensures last batch doesn't exceed total statements\n",
        "* `batch_statements = statements[start_idx:end_idx]` - Slices list to get current batch of statements\n",
        "* `identify_stress(batch_statements, return_all_probs=False)` - Analyzes batch without full probability distributions for faster processing\n",
        "* `all_results.extend(batch_results)` - Appends batch results to master results list\n",
        "* `print(..., end='\\r')` - Prints progress on same line using carriage return for live updates\n",
        "* `pd.DataFrame(all_results)` - Converts list of result dictionaries into pandas DataFrame for easy manipulation\n",
        "* `results_df.insert(0, 'patient_id', range(1, len(results_df) + 1))` - Adds sequential patient IDs as first column\n",
        "* `results_df['is_stress'].sum()` - Counts number of True values in boolean column for stress statistics\n",
        "* `filter_stress_cases(all_results)` - Extracts only cases where stress was detected or probability exceeded threshold\n",
        "* `stmt[:70] + \"...\"` - Truncates long statements to 70 characters for readable display\n",
        "* `datetime.now().strftime('%Y%m%d_%H%M%S')` - Generates timestamp in format YYYYMMDD_HHMMSS for unique filenames\n",
        "* `results_df.to_csv(all_file, index=False)` - Saves DataFrame to CSV without row index column\n",
        "* `results_df[results_df['needs_attention'] == True]` - Filters DataFrame to only rows where stress needs attention\n",
        "* `traceback.print_exc()` - Prints full error traceback for debugging if unexpected exception occurs\n",
        "\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "This cell requires:\n",
        "* A CSV file named in `CSV_FILE` variable (default: \"Combined Data.csv\") located in the same directory as the notebook\n",
        "* The CSV must contain a column matching `STATEMENT_COL` (default: \"statement\") with patient text data\n",
        "* The stress identification system must be loaded and functional (from previous cells)\n",
        "* Optional configuration: `MAX_ROWS` to limit processing, `BATCH_SIZE` to control memory usage and progress update frequency\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "**Console Output**:\n",
        "* Loading confirmation showing filename and total rows\n",
        "* Real-time progress updates showing batch number, percentage complete, and statements processed\n",
        "* Summary statistics including total patients, stress detected count and percentage, attention needed count and percentage\n",
        "* First 5 stress cases with truncated statements, stress probability, and predicted class\n",
        "* Confirmation messages for saved files with filenames and case counts\n",
        "\n",
        "**File Output**:\n",
        "* `stress_analysis_all_[timestamp].csv` - Complete results for all patients with columns: patient_id, statement, predicted_class, predicted_label, is_stress, stress_probability, above_threshold, needs_attention\n",
        "* `stress_cases_only_[timestamp].csv` - Filtered results containing only patients flagged for attention (stress detected or above threshold)\n",
        "\n",
        "\n",
        "**Code Flow:**\n",
        "\n",
        "The cell begins by setting configuration variables and printing a header. It attempts to load the CSV file using pandas, validating that the file exists and the specified column is present. If `MAX_ROWS` is set, it limits the dataset. The cell extracts all statements as a string list, then calculates how many batches are needed based on `BATCH_SIZE`. It enters a loop processing each batch: slicing the statements list, calling `identify_stress()` on the batch, collecting results, and updating progress display. After all batches complete, it converts results to a DataFrame, adds patient IDs, and calculates summary statistics (total, stress count, attention needed). It displays the first 5 stress cases as examples, then saves two CSV files - one with all results and one with only stress cases, both with timestamped filenames. Comprehensive error handling catches file not found errors and other exceptions, providing helpful troubleshooting messages.\n",
        "\n",
        "\n",
        "**Comments and Observations:**\n",
        "\n",
        "Batch processing is critical for large datasets to avoid memory errors and provide progress feedback. A `BATCH_SIZE` of 100 works well for most systems - increase to 200-500 for faster processing if you have sufficient RAM, or decrease to 32-64 for memory-constrained environments. Setting `return_all_probs=False` significantly speeds up processing since full probability distributions aren't needed for batch analysis. The `MAX_ROWS` parameter is useful for testing on a subset before running the full dataset - try `MAX_ROWS = 100` first to verify everything works. The progress indicator updates in real-time using `end='\\r'` which overwrites the same line, giving immediate feedback on long-running analyses. Timestamped output files prevent accidentally overwriting previous results and create a historical record of analyses. The two output files serve different purposes: the \"all\" file is comprehensive for record-keeping and further analysis, while the \"stress_cases_only\" file provides a focused list for clinical follow-up. Patient IDs are added as sequential numbers starting from 1, but you can modify this to use an ID column from your CSV if one exists (e.g., `results_df['patient_id'] = df['patient_id'].values`). The first 5 stress cases preview helps you quickly assess if the model is performing correctly - you should see reasonable stress detections. If many non-stress statements appear in the preview, consider retraining the model or adjusting the threshold. Processing time depends on dataset size, batch size, and hardware: expect roughly 1-2 seconds per 100 statements on CPU, or 0.2-0.5 seconds per 100 on GPU. A dataset of 10,000 statements might take 2-3 minutes on CPU or 30-60 seconds on GPU. The error handling distinguishes between file not found errors (which get specific instructions) and other errors (which print full traceback for debugging). Always check that your CSV column name matches `STATEMENT_COL` exactly - column name mismatches are the most common error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65oi2FIsiC_",
      "metadata": {
        "id": "f65oi2FIsiC_"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Analyze CSV File for Stress Cases\n",
        "# ============================================================================\n",
        "# This cell reads your CSV file and identifies all patients with stress\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration\n",
        "CSV_FILE = \"Combined Data.csv\"  # Your CSV file name\n",
        "STATEMENT_COL = \"statement\"      # Column name with patient statements\n",
        "MAX_ROWS = None                  # Set to number (e.g., 1000) to limit, or None for all\n",
        "BATCH_SIZE = 100                 # Process this many statements at a time (lower = more progress updates, higher = faster)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ANALYZING CSV FILE FOR STRESS CASES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Load CSV\n",
        "    csv_file = Path(CSV_FILE)\n",
        "    if not csv_file.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {CSV_FILE}\")\n",
        "\n",
        "    print(f\"Loading: {csv_file}\")\n",
        "    df = pd.read_csv(csv_file)\n",
        "    print(f\"Loaded {len(df)} rows\")\n",
        "\n",
        "    # Check column exists\n",
        "    if STATEMENT_COL not in df.columns:\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "        raise ValueError(f\"Column '{STATEMENT_COL}' not found\")\n",
        "\n",
        "    # Limit rows if specified\n",
        "    if MAX_ROWS and MAX_ROWS < len(df):\n",
        "        df = df.head(MAX_ROWS)\n",
        "        print(f\"Limited to {MAX_ROWS} rows\")\n",
        "\n",
        "    # Get statements\n",
        "    statements = df[STATEMENT_COL].astype(str).tolist()\n",
        "    total_statements = len(statements)\n",
        "    print(f\"\\nAnalyzing {total_statements} patient statements...\")\n",
        "    print(\"(Processing in batches for better performance)\\n\")\n",
        "\n",
        "    # Process in batches to avoid memory issues and show progress\n",
        "    all_results = []\n",
        "\n",
        "    num_batches = (total_statements + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "    for batch_num in range(num_batches):\n",
        "        start_idx = batch_num * BATCH_SIZE\n",
        "        end_idx = min(start_idx + BATCH_SIZE, total_statements)\n",
        "        batch_statements = statements[start_idx:end_idx]\n",
        "\n",
        "        # Analyze this batch\n",
        "        batch_results = identify_stress(batch_statements, return_all_probs=False)\n",
        "        all_results.extend(batch_results)\n",
        "\n",
        "        # Show progress\n",
        "        progress = (batch_num + 1) / num_batches * 100\n",
        "        print(f\"Progress: {batch_num + 1}/{num_batches} batches ({progress:.1f}%) - {end_idx}/{total_statements} statements\", end='\\r')\n",
        "\n",
        "    print(f\"\\n‚úÖ Completed analysis of {total_statements} statements!\")\n",
        "\n",
        "    # Convert all results to DataFrame\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "\n",
        "    # Add patient IDs\n",
        "    results_df.insert(0, 'patient_id', range(1, len(results_df) + 1))\n",
        "\n",
        "    # Fix statement column if it exists\n",
        "    if 'statement' in results_df.columns:\n",
        "        stmt = results_df['statement'].values.copy()\n",
        "        results_df = results_df.drop(columns=['statement'])\n",
        "        results_df.insert(1, 'statement', stmt)\n",
        "\n",
        "    # Calculate statistics\n",
        "    total = len(results_df)\n",
        "    stress = results_df['is_stress'].sum()\n",
        "    attention = results_df['needs_attention'].sum()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"RESULTS SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Total Patients: {total}\")\n",
        "    print(f\"Stress Detected: {stress} ({stress/total*100:.1f}%)\")\n",
        "    print(f\"Need Attention: {attention} ({attention/total*100:.1f}%)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get stress cases\n",
        "    stress_cases = filter_stress_cases(all_results)\n",
        "    print(f\"\\nTotal Stress Cases: {len(stress_cases)}\")\n",
        "\n",
        "    # Show examples\n",
        "    if stress_cases:\n",
        "        print(\"\\nFirst 5 stress cases:\")\n",
        "        for i, case in enumerate(stress_cases[:5], 1):\n",
        "            stmt = case['statement'][:70] + \"...\" if len(case['statement']) > 70 else case['statement']\n",
        "            print(f\"{i}. [{case['stress_probability']:.1%}] {stmt}\")\n",
        "            print(f\"   Class: {case['predicted_label']}\")\n",
        "\n",
        "    # Save results\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "    all_file = f\"stress_analysis_all_{timestamp}.csv\"\n",
        "    results_df.to_csv(all_file, index=False)\n",
        "    print(f\"\\n‚úÖ Saved all results: {all_file}\")\n",
        "\n",
        "    if len(stress_cases) > 0:\n",
        "        stress_df = results_df[results_df['needs_attention'] == True]\n",
        "        stress_file = f\"stress_cases_only_{timestamp}.csv\"\n",
        "        stress_df.to_csv(stress_file, index=False)\n",
        "        print(f\"‚úÖ Saved stress cases: {stress_file} ({len(stress_df)} cases)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ANALYSIS COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    print(\"\\nMake sure:\")\n",
        "    print(\"1. The CSV file is in the same folder as this notebook\")\n",
        "    print(\"2. The file name is correct\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q5AaztXH-evh",
      "metadata": {
        "id": "Q5AaztXH-evh"
      },
      "source": [
        "## Export All Stress Cases to CSV File\n",
        "\n",
        "**Function Description:**\n",
        "\n",
        "This cell extracts all patients identified with stress from analysis results and exports them to a dedicated CSV file. It intelligently searches for results in multiple locations (memory, specified file, or most recent auto-saved file), filters for stress cases using multiple criteria, sorts by stress probability, generates detailed statistics and breakdowns, and saves a clean, focused dataset of only stress-positive patients for clinical review and follow-up.\n",
        "\n",
        "\n",
        "**Syntax Explanation:**\n",
        "\n",
        "* `RESULTS_FILE = \"stress_analysis_all_20241117_123456.csv\"` - Optional variable to specify a saved results file to load (commented out by default)\n",
        "* `if 'results_df' in globals()` - Checks if results DataFrame exists in global scope from previous analysis\n",
        "* `results_df.copy()` - Creates a copy of the DataFrame to avoid modifying the original\n",
        "* `elif 'RESULTS_FILE' in locals() and RESULTS_FILE:` - Checks if user uncommented and set a specific results file\n",
        "* `glob.glob(\"stress_analysis_all_*.csv\")` - Searches for all files matching the pattern with wildcard\n",
        "* `max(result_files, key=lambda x: Path(x).stat().st_mtime)` - Finds most recently modified file using modification timestamp\n",
        "* `Path(x).stat().st_mtime` - Gets file modification time for comparison\n",
        "* `pd.read_csv(latest_file)` - Loads the automatically detected most recent results file\n",
        "* `df_to_use[(df_to_use['is_stress'] == True) | (df_to_use['needs_attention'] == True) | (df_to_use['above_threshold'] == True)]` - Filters DataFrame using OR logic across three stress criteria\n",
        "* `|` operator - Logical OR for pandas boolean indexing (combines multiple conditions)\n",
        "* `.copy()` - Creates copy of filtered DataFrame to avoid SettingWithCopyWarning\n",
        "* `stress_df.sort_values('stress_probability', ascending=False)` - Sorts by stress probability in descending order (highest risk first)\n",
        "* `stress_count / total_patients * 100` - Calculates percentage of patients with stress\n",
        "* `if total_patients > 0 else 0` - Ternary operator to avoid division by zero\n",
        "* `stress_df['predicted_label'].value_counts()` - Counts occurrences of each predicted class label\n",
        "* `class_counts.items()` - Iterates through class names and their counts\n",
        "* `stress_df['stress_probability'].mean()` - Calculates average stress probability across all stress cases\n",
        "* `.min()`, `.max()`, `.median()` - Statistical functions for probability distribution analysis\n",
        "* `datetime.now().strftime('%Y%m%d_%H%M%S')` - Generates timestamp string in YYYYMMDD_HHMMSS format\n",
        "* `output_file = f\"stress_cases_identified_{timestamp}.csv\"` - Creates timestamped filename for export\n",
        "* `columns_to_save = [...]` - Defines ordered list of columns to include in export\n",
        "* `[col for col in columns_to_save if col in stress_df.columns]` - List comprehension filtering only existing columns\n",
        "* `stress_df[available_columns].to_csv(output_file, index=False)` - Saves selected columns to CSV without row indices\n",
        "* `stress_df.head(5).iterrows()` - Iterates through first 5 rows with index and row data\n",
        "* `row.get('patient_id', 'N/A')` - Safely retrieves patient_id with default value if missing\n",
        "* `stmt[:100] + \"...\"` - Truncates statements longer than 100 characters for display\n",
        "* `except NameError as e:` - Catches errors when required variables don't exist\n",
        "* `except FileNotFoundError as e:` - Catches errors when specified file cannot be found\n",
        "* `traceback.print_exc()` - Prints full error traceback for debugging unexpected exceptions\n",
        "\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "This cell requires results from a previous stress analysis, which it attempts to find using three strategies in priority order:\n",
        "1. **Memory**: Uses `results_df` from the most recent analysis cell execution\n",
        "2. **Specified File**: Uses file path defined in `RESULTS_FILE` variable if uncommented\n",
        "3. **Auto-detect**: Searches for most recent `stress_analysis_all_*.csv` file in current directory\n",
        "\n",
        "No manual input required if analysis was just run. To use a specific file, uncomment the `RESULTS_FILE` line and set the filename.\n",
        "\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "**Console Output**:\n",
        "* Source confirmation (memory, specified file, or auto-detected file)\n",
        "* Summary statistics showing total patients analyzed, stress cases count, and percentage\n",
        "* Breakdown by predicted class showing distribution of mental health categories among stress cases\n",
        "* Stress probability statistics including average, minimum, maximum, and median values\n",
        "* First 5 stress cases as examples with patient ID, truncated statement, stress probability, and predicted class\n",
        "* File save confirmation with filename, total cases, and included columns\n",
        "\n",
        "**File Output**:\n",
        "* `stress_cases_identified_[timestamp].csv` - Contains only patients flagged with stress, sorted by stress probability (highest first), with columns: patient_id, statement, predicted_label, predicted_class, stress_probability, is_stress, above_threshold, needs_attention\n",
        "\n",
        "\n",
        "**Code Flow:**\n",
        "\n",
        "The cell starts by checking three locations for results data in priority order: first checking global memory for `results_df`, then checking if user specified `RESULTS_FILE`, and finally auto-detecting the most recent saved results file using glob pattern matching. Once data is loaded, it filters the DataFrame using OR logic to include any row where `is_stress`, `needs_attention`, or `above_threshold` is True. The filtered stress cases are sorted by stress probability in descending order to prioritize highest-risk patients. Statistical summaries are calculated and printed including total counts, percentages, class distribution breakdown, and probability statistics. The cell defines a column ordering for readable output, filters to only available columns, and saves to a timestamped CSV file. Finally, it displays the first 5 stress cases as examples with truncated statements for quick verification. Comprehensive error handling catches missing variables, file not found errors, and other exceptions with helpful troubleshooting messages.\n",
        "\n",
        "\n",
        "**Comments and Observations:**\n",
        "\n",
        "The three-tiered loading strategy makes this cell very flexible - it works whether you just ran the analysis, want to reprocess an older file, or forgot which file to use. Auto-detection using `glob.glob()` with `max()` on modification time is particularly helpful when you have multiple result files and want the latest one without remembering the exact timestamp. The stress filtering uses OR logic `(condition1) | (condition2) | (condition3)` which is more inclusive than AND logic - a patient is included if they meet ANY of the three stress criteria, not all three. This catches edge cases where stress probability is high but another condition was predicted, or where the threshold was exceeded but stress wasn't the top prediction. Sorting by stress probability puts the highest-risk patients first, making the output immediately actionable for clinical triage - start reviewing from the top of the file. The class breakdown is valuable for understanding what other conditions co-occur with stress - you might see many \"Anxiety\" predictions with high stress probability, indicating comorbidity. Probability statistics help you understand the confidence distribution: if the average is 65% and minimum is 35%, that's different from average 45% and minimum 31% - the first suggests stronger, more confident detections. The timestamp ensures you never accidentally overwrite exports, and creates an audit trail of when analyses were performed. Column ordering in `columns_to_save` is deliberately chosen to put the most important information first (patient_id, statement) followed by predictions and flags. The `available_columns` filtering prevents errors if your results file is missing some columns (perhaps from an older version of the analysis code). If no stress cases are found, the cell gracefully reports this rather than erroring - in a healthy population sample, it's possible to have zero stress detections. For large datasets with thousands of stress cases, consider adding `MAX_EXPORT = 1000` to limit the export file size, or create multiple files by stress probability ranges (high risk, medium risk, etc.). The 5-example preview lets you quickly sanity-check that the filtering worked correctly - you should see statements with clear stress indicators in the examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5J5zVAQhwbBL",
      "metadata": {
        "id": "5J5zVAQhwbBL"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Export All Stress Cases to CSV File\n",
        "# ============================================================================\n",
        "# This cell extracts all patients identified with stress and saves to CSV\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import glob\n",
        "\n",
        "# Option 1: Use results from memory (if you just ran the analysis cell above)\n",
        "# Option 2: Load from a saved results file (uncomment and set the filename)\n",
        "# RESULTS_FILE = \"stress_analysis_all_20241117_123456.csv\"  # Change to your file name\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPORTING STRESS CASES TO CSV\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Try to use results from memory first\n",
        "    if 'results_df' in globals() and results_df is not None:\n",
        "        print(\"‚úÖ Using results from memory (from previous analysis)\")\n",
        "        df_to_use = results_df.copy()\n",
        "    elif 'RESULTS_FILE' in locals() and RESULTS_FILE:\n",
        "        # Load from saved file\n",
        "        print(f\"üìÇ Loading results from: {RESULTS_FILE}\")\n",
        "        df_to_use = pd.read_csv(RESULTS_FILE)\n",
        "        print(f\"‚úÖ Loaded {len(df_to_use)} records\")\n",
        "    else:\n",
        "        # Try to find the most recent results file\n",
        "        result_files = glob.glob(\"stress_analysis_all_*.csv\")\n",
        "        if result_files:\n",
        "            # Get the most recent file\n",
        "            latest_file = max(result_files, key=lambda x: Path(x).stat().st_mtime)\n",
        "            print(f\"üìÇ Found recent results file: {latest_file}\")\n",
        "            df_to_use = pd.read_csv(latest_file)\n",
        "            print(f\"‚úÖ Loaded {len(df_to_use)} records\")\n",
        "        else:\n",
        "            raise ValueError(\"No results found. Please run the analysis cell first or specify RESULTS_FILE.\")\n",
        "\n",
        "    # Filter for stress cases\n",
        "    # A patient has stress if: is_stress=True OR needs_attention=True OR above_threshold=True\n",
        "    stress_df = df_to_use[\n",
        "        (df_to_use['is_stress'] == True) |\n",
        "        (df_to_use['needs_attention'] == True) |\n",
        "        (df_to_use['above_threshold'] == True)\n",
        "    ].copy()\n",
        "\n",
        "    # Sort by stress probability (highest first)\n",
        "    if 'stress_probability' in stress_df.columns:\n",
        "        stress_df = stress_df.sort_values('stress_probability', ascending=False)\n",
        "\n",
        "    # Summary\n",
        "    total_patients = len(df_to_use)\n",
        "    stress_count = len(stress_df)\n",
        "    stress_percentage = (stress_count / total_patients * 100) if total_patients > 0 else 0\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STRESS CASES SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Total Patients Analyzed: {total_patients}\")\n",
        "    print(f\"Patients with Stress: {stress_count} ({stress_percentage:.1f}%)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if len(stress_df) > 0:\n",
        "        # Show breakdown by predicted class\n",
        "        if 'predicted_label' in stress_df.columns:\n",
        "            print(\"\\nBreakdown by Predicted Class:\")\n",
        "            class_counts = stress_df['predicted_label'].value_counts()\n",
        "            for class_name, count in class_counts.items():\n",
        "                print(f\"  {class_name}: {count}\")\n",
        "\n",
        "        # Show stress probability statistics\n",
        "        if 'stress_probability' in stress_df.columns:\n",
        "            print(f\"\\nStress Probability Statistics:\")\n",
        "            print(f\"  Average: {stress_df['stress_probability'].mean():.1%}\")\n",
        "            print(f\"  Minimum: {stress_df['stress_probability'].min():.1%}\")\n",
        "            print(f\"  Maximum: {stress_df['stress_probability'].max():.1%}\")\n",
        "            print(f\"  Median: {stress_df['stress_probability'].median():.1%}\")\n",
        "\n",
        "        # Save to CSV\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        output_file = f\"stress_cases_identified_{timestamp}.csv\"\n",
        "\n",
        "        # Select columns to save (in a readable order)\n",
        "        columns_to_save = [\n",
        "            'patient_id',\n",
        "            'statement',\n",
        "            'predicted_label',\n",
        "            'predicted_class',\n",
        "            'stress_probability',\n",
        "            'is_stress',\n",
        "            'above_threshold',\n",
        "            'needs_attention'\n",
        "        ]\n",
        "\n",
        "        # Only include columns that exist\n",
        "        available_columns = [col for col in columns_to_save if col in stress_df.columns]\n",
        "        stress_df[available_columns].to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ Stress cases saved to: {output_file}\")\n",
        "        print(f\"   Total stress cases: {len(stress_df)}\")\n",
        "        print(f\"   Columns: {', '.join(available_columns)}\")\n",
        "\n",
        "        # Show first few examples\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"SAMPLE STRESS CASES (First 5)\")\n",
        "        print(\"=\" * 80)\n",
        "        for idx, row in stress_df.head(5).iterrows():\n",
        "            print(f\"\\n[Patient {row.get('patient_id', 'N/A')}]\")\n",
        "            stmt = row['statement']\n",
        "            if len(stmt) > 100:\n",
        "                stmt = stmt[:100] + \"...\"\n",
        "            print(f\"Statement: {stmt}\")\n",
        "            print(f\"Stress Probability: {row.get('stress_probability', 0):.1%}\")\n",
        "            print(f\"Predicted Class: {row.get('predicted_label', 'N/A')}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"EXPORT COMPLETE!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nüìÑ File saved: {output_file}\")\n",
        "        print(f\"üìä Total stress cases: {stress_count}\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  No stress cases found in the analyzed data.\")\n",
        "        print(\"   All patients appear to be stress-free.\")\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    print(\"\\nPlease run the analysis cell first, or specify a RESULTS_FILE to load from.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n‚ùå Error: File not found - {e}\")\n",
        "    print(\"\\nPlease check the file path and try again.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error occurred: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2370658",
      "metadata": {
        "id": "d2370658"
      },
      "source": [
        "## User Input: Check Stress Level from Statement\n",
        "\n",
        "Enter a patient statement below to check if the patient is experiencing stress and see the stress probability percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308034ce",
      "metadata": {
        "id": "308034ce"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# User Input: Check Stress Level from Statement\n",
        "# ============================================================================\n",
        "# Enter a patient statement to check stress level and probability\n",
        "# ============================================================================\n",
        "\n",
        "def check_stress_from_statement(statement, model=None, tokenizer=None):\n",
        "    \"\"\"\n",
        "    Check if a patient statement indicates stress and return probability.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    statement : str\n",
        "        Patient statement to analyze\n",
        "    model : optional\n",
        "        Trained model (uses best model if available)\n",
        "    tokenizer : optional\n",
        "        Tokenizer (uses global tokenizer if available)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Results with stress detection and probability\n",
        "    \"\"\"\n",
        "    # Try to get model and tokenizer\n",
        "    if model is None:\n",
        "        if 'best_trainer' in globals():\n",
        "            model = best_trainer.model\n",
        "        elif 'stress_model' in globals():\n",
        "            model = stress_model\n",
        "        else:\n",
        "            raise ValueError(\"No model found. Please train a model first or load one.\")\n",
        "\n",
        "    if tokenizer is None:\n",
        "        if 'tokenizer' in globals():\n",
        "            tokenizer = tokenizer\n",
        "        elif 'stress_tokenizer' in globals():\n",
        "            tokenizer = stress_tokenizer\n",
        "        else:\n",
        "            raise ValueError(\"No tokenizer found. Please load tokenizer first.\")\n",
        "\n",
        "    # Ensure model is on correct device and in eval mode\n",
        "    if 'device' not in globals():\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Label mapping\n",
        "    LABEL_MAP = {\n",
        "        0: \"Anxiety\",\n",
        "        1: \"Bipolar\",\n",
        "        2: \"Depression\",\n",
        "        3: \"Normal\",\n",
        "        4: \"Personality disorder\",\n",
        "        5: \"Stress\",\n",
        "        6: \"Suicidal\"\n",
        "    }\n",
        "    STRESS_LABEL = 5\n",
        "\n",
        "    # Tokenize statement\n",
        "    encoded = tokenizer(\n",
        "        statement,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=160,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "        prediction = np.argmax(probabilities)\n",
        "\n",
        "    # Extract stress probability\n",
        "    stress_probability = probabilities[STRESS_LABEL]\n",
        "    is_stress = prediction == STRESS_LABEL\n",
        "\n",
        "    # Determine stress level\n",
        "    if stress_probability >= 0.7:\n",
        "        stress_level = \"HIGH STRESS\"\n",
        "        recommendation = \"‚ö†Ô∏è  Patient shows high signs of stress. Immediate attention recommended.\"\n",
        "    elif stress_probability >= 0.5:\n",
        "        stress_level = \"MODERATE STRESS\"\n",
        "        recommendation = \"‚ö†Ô∏è  Patient shows moderate signs of stress. Monitoring recommended.\"\n",
        "    elif stress_probability >= 0.3:\n",
        "        stress_level = \"LOW STRESS\"\n",
        "        recommendation = \"‚ö†Ô∏è  Patient shows some signs of stress. Regular check-ins recommended.\"\n",
        "    else:\n",
        "        stress_level = \"NO SIGNIFICANT STRESS\"\n",
        "        recommendation = \"‚úì Patient appears to have low stress levels.\"\n",
        "\n",
        "    result = {\n",
        "        'statement': statement,\n",
        "        'is_stress': is_stress,\n",
        "        'stress_probability': float(stress_probability),\n",
        "        'stress_percentage': float(stress_probability * 100),\n",
        "        'stress_level': stress_level,\n",
        "        'predicted_class': int(prediction),\n",
        "        'predicted_label': LABEL_MAP[int(prediction)],\n",
        "        'all_probabilities': {LABEL_MAP[i]: float(prob) for i, prob in enumerate(probabilities)},\n",
        "        'recommendation': recommendation\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def display_stress_result(result):\n",
        "    \"\"\"Display stress analysis result in a user-friendly format.\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STRESS ANALYSIS RESULT\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nPatient Statement:\")\n",
        "    print(f'  \"{result[\"statement\"]}\"')\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(f\"STRESS PROBABILITY: {result['stress_percentage']:.1f}%\")\n",
        "    print(f\"Stress Level: {result['stress_level']}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    if result['is_stress']:\n",
        "        print(\"üî¥ STRESS DETECTED - Primary Prediction\")\n",
        "    else:\n",
        "        print(\"üü¢ No stress detected as primary prediction\")\n",
        "\n",
        "    print(f\"\\nPredicted Mental Health Status: {result['predicted_label']}\")\n",
        "    print(f\"\\n{result['recommendation']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"DETAILED PROBABILITIES\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"All class probabilities:\")\n",
        "    for label, prob in sorted(result['all_probabilities'].items(),\n",
        "                             key=lambda x: x[1], reverse=True):\n",
        "        marker = \" ‚Üê PREDICTED\" if label == result['predicted_label'] else \"\"\n",
        "        print(f\"  {label:25s}: {prob*100:5.1f}%{marker}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# USER INPUT SECTION\n",
        "# ============================================================================\n",
        "# Enter your patient statement here\n",
        "# ============================================================================\n",
        "\n",
        "# Option 1: Direct input (modify this variable)\n",
        "patient_statement = input(\"Enter patient statement: \") if False else None\n",
        "\n",
        "# Option 2: Set statement directly (uncomment and modify)\n",
        "# patient_statement = \"I feel overwhelmed and cannot cope with my workload. My chest feels tight and I can't sleep.\"\n",
        "\n",
        "# If no statement provided, prompt user\n",
        "if patient_statement is None or patient_statement.strip() == \"\":\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STRESS DETECTION SYSTEM\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nPlease enter a patient statement to analyze for stress.\")\n",
        "    print(\"\\nYou can:\")\n",
        "    print(\"  1. Modify the 'patient_statement' variable in this cell\")\n",
        "    print(\"  2. Or use the function directly: result = check_stress_from_statement('your statement here')\")\n",
        "    print(\"\\nExample:\")\n",
        "    print('  result = check_stress_from_statement(\"I feel very stressed and overwhelmed\")')\n",
        "    print('  display_stress_result(result)')\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    # Analyze the statement\n",
        "    try:\n",
        "        result = check_stress_from_statement(patient_statement)\n",
        "        display_stress_result(result)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nMake sure you have:\")\n",
        "        print(\"  1. Trained a model (run training cells)\")\n",
        "        print(\"  2. Or loaded a saved model\")\n",
        "        print(\"  3. Tokenizer is available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be27035",
      "metadata": {
        "id": "0be27035"
      },
      "source": [
        "### Quick Test: Enter Statement Here\n",
        "\n",
        "Simply modify the statement below and run the cell to get instant stress analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1ff020",
      "metadata": {
        "id": "4c1ff020"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# QUICK STRESS CHECK - Enter Your Statement Here\n",
        "# ============================================================================\n",
        "# Just modify the statement below and run this cell!\n",
        "# ============================================================================\n",
        "\n",
        "# üëá ENTER PATIENT STATEMENT HERE üëá\n",
        "patient_statement = \"I feel overwhelmed and cannot cope with my workload. My chest feels tight and I can't sleep.\"\n",
        "\n",
        "# ============================================================================\n",
        "# (No need to modify anything below this line)\n",
        "# ============================================================================\n",
        "\n",
        "try:\n",
        "    # Check if functions are available\n",
        "    if 'check_stress_from_statement' not in globals():\n",
        "        print(\"‚ö†Ô∏è  Please run the previous cell (Cell 42) first to load the functions.\")\n",
        "    else:\n",
        "        # Analyze the statement\n",
        "        result = check_stress_from_statement(patient_statement)\n",
        "        display_stress_result(result)\n",
        "\n",
        "        # Additional summary\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"QUICK SUMMARY\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Stress Detected: {'YES' if result['is_stress'] else 'NO'}\")\n",
        "        print(f\"Stress Probability: {result['stress_percentage']:.1f}%\")\n",
        "        print(f\"Stress Level: {result['stress_level']}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"\\nPlease make sure:\")\n",
        "    print(\"  1. You have run Cell 42 to load the functions\")\n",
        "    print(\"  2. You have a trained model available\")\n",
        "    print(\"  3. The model and tokenizer are loaded\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd30b5ba",
      "metadata": {
        "id": "fd30b5ba"
      },
      "source": [
        "## Final Evaluation on Ground-Truth Test Set\n",
        "\n",
        "This section provides functions to evaluate your trained model on the held-out ground truth test set for unbiased final performance assessment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1a6a7c",
      "metadata": {
        "id": "6f1a6a7c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Load Ground-Truth Test Set from CSV\n",
        "# ============================================================================\n",
        "\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "def load_ground_truth_test_set_from_csv(csv_file=None):\n",
        "    \"\"\"\n",
        "    Load the ground truth test set from a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    csv_file : str, optional\n",
        "        Path to the CSV file. If None, automatically finds the most recent test set.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (X_test, y_test) - Test statements and labels\n",
        "    \"\"\"\n",
        "    if csv_file is None:\n",
        "        # Automatically find the most recent ground truth test set\n",
        "        test_files = glob.glob(\"Ground_Truth_Test_Set_Final_Version_*.csv\")\n",
        "        if not test_files:\n",
        "            raise FileNotFoundError(\n",
        "                \"No ground truth test set CSV found. \"\n",
        "                \"Please run Cell 5 to create the test set first.\"\n",
        "            )\n",
        "        # Sort by modification time and get the most recent\n",
        "        csv_file = max(test_files, key=Path().stat if hasattr(Path(), 'stat') else lambda f: Path(f).stat().st_mtime)\n",
        "        print(f\"üìÇ Auto-detected test set: {csv_file}\")\n",
        "\n",
        "    # Load the CSV\n",
        "    test_df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Validate required columns\n",
        "    if 'statement' not in test_df.columns or 'status' not in test_df.columns:\n",
        "        raise ValueError(f\"CSV must contain 'statement' and 'status' columns. Found: {test_df.columns.tolist()}\")\n",
        "\n",
        "    X_test = test_df['statement'].values\n",
        "    y_test = test_df['status'].values\n",
        "\n",
        "    print(f\"‚úÖ Loaded ground truth test set: {len(X_test)} samples\")\n",
        "    print(f\"   File: {csv_file}\")\n",
        "\n",
        "    return X_test, y_test\n",
        "\n",
        "# Load the test set (uses in-memory X_test, y_test if available, otherwise loads from CSV)\n",
        "if 'X_test' in globals() and 'y_test' in globals():\n",
        "    print(\"‚úÖ Using in-memory test set (from Cell 5)\")\n",
        "    print(f\"   Test set size: {len(X_test)} samples\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  In-memory test set not found. Loading from CSV...\")\n",
        "    try:\n",
        "        X_test, y_test = load_ground_truth_test_set_from_csv()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading test set: {e}\")\n",
        "        print(\"\\nMake sure you have:\")\n",
        "        print(\"  1. Run Cell 5 to create the test set, OR\")\n",
        "        print(\"  2. Have a Ground_Truth_Test_Set_Final_Version_*.csv file available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea82edc9",
      "metadata": {
        "id": "ea82edc9"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Final Evaluation on Ground-Truth Test Set\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "def evaluate_on_ground_truth_test_set(model=None, tokenizer=None, X_test=None, y_test=None):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model on the held-out ground truth test set.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : optional\n",
        "        Trained model. If None, uses best_trainer.model or best saved model.\n",
        "    tokenizer : optional\n",
        "        Tokenizer. If None, uses global tokenizer.\n",
        "    X_test : optional\n",
        "        Test statements. If None, uses global X_test.\n",
        "    y_test : optional\n",
        "        Test labels. If None, uses global y_test.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Evaluation metrics\n",
        "    \"\"\"\n",
        "    # Get model\n",
        "    if model is None:\n",
        "        if 'best_trainer' in globals():\n",
        "            model = best_trainer.model\n",
        "            print(\"‚úÖ Using best_trainer.model\")\n",
        "        elif 'best_name' in globals():\n",
        "            save_dir = f\"./best_model_{best_name}\"\n",
        "            try:\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "                print(f\"‚úÖ Loaded model from: {save_dir}\")\n",
        "            except:\n",
        "                raise ValueError(\"No trained model found. Please train a model first.\")\n",
        "        else:\n",
        "            raise ValueError(\"No trained model found. Please train a model first.\")\n",
        "\n",
        "    # Get tokenizer\n",
        "    if tokenizer is None:\n",
        "        if 'tokenizer' in globals():\n",
        "            tokenizer = tokenizer\n",
        "        elif 'best_name' in globals():\n",
        "            save_dir = f\"./best_model_{best_name}\"\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "                print(f\"‚úÖ Loaded tokenizer from: {save_dir}\")\n",
        "            except:\n",
        "                raise ValueError(\"No tokenizer found.\")\n",
        "        else:\n",
        "            raise ValueError(\"No tokenizer found.\")\n",
        "\n",
        "    # Get test data\n",
        "    if X_test is None:\n",
        "        if 'X_test' not in globals():\n",
        "            raise ValueError(\"Test set not found. Please run Cell 49 to load it.\")\n",
        "        X_test = globals()['X_test']\n",
        "\n",
        "    if y_test is None:\n",
        "        if 'y_test' not in globals():\n",
        "            raise ValueError(\"Test labels not found. Please run Cell 49 to load them.\")\n",
        "        y_test = globals()['y_test']\n",
        "\n",
        "    # Ensure model is on correct device\n",
        "    if 'device' not in globals():\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    else:\n",
        "        device = globals()['device']\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"FINAL EVALUATION ON GROUND-TRUTH TEST SET\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Test set size: {len(X_test)} samples\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Tokenize test set\n",
        "    print(\"\\nTokenizing test set...\")\n",
        "    test_enc = tokenizer(\n",
        "        list(X_test),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=160,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    print(\"Running inference...\")\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    # Process in batches to avoid memory issues\n",
        "    batch_size = 32\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X_test), batch_size):\n",
        "            end_idx = min(i + batch_size, len(X_test))\n",
        "            batch_input_ids = test_enc['input_ids'][i:end_idx]\n",
        "            batch_attention_mask = test_enc['attention_mask'][i:end_idx]\n",
        "\n",
        "            batch_enc = {\n",
        "                'input_ids': batch_input_ids,\n",
        "                'attention_mask': batch_attention_mask\n",
        "            }\n",
        "\n",
        "            outputs = model(**batch_enc)\n",
        "            logits = outputs.logits\n",
        "            batch_probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "            batch_preds = np.argmax(batch_probs, axis=-1)\n",
        "\n",
        "            predictions.extend(batch_preds)\n",
        "            probabilities.extend(batch_probs)\n",
        "\n",
        "            if (i // batch_size + 1) % 10 == 0:\n",
        "                print(f\"  Processed {end_idx}/{len(X_test)} samples...\")\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    probabilities = np.array(probabilities)\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"EVALUATION METRICS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Overall metrics\n",
        "    num_classes = len(np.unique(y_test))\n",
        "    avg_type = \"binary\" if num_classes == 2 else \"weighted\"\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_test, predictions, average=avg_type, zero_division=0\n",
        "    )\n",
        "\n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    # Per-class metrics\n",
        "    print(f\"\\nPer-Class Performance:\")\n",
        "    precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
        "        y_test, predictions, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Get label names if available\n",
        "    if 'le' in globals():\n",
        "        label_names = le.classes_\n",
        "    else:\n",
        "        label_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "    print(f\"\\n{'Class':<20} {'Precision':<12} {'Recall':<12} {'F1':<12} {'Support':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "    for i, label in enumerate(label_names):\n",
        "        print(f\"{label:<20} {precision_per_class[i]:<12.4f} {recall_per_class[i]:<12.4f} \"\n",
        "              f\"{f1_per_class[i]:<12.4f} {support_per_class[i]:<10}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(\"CONFUSION MATRIX\")\n",
        "    print(\"=\" * 80)\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    print(\"\\nRows = True labels, Columns = Predicted labels\")\n",
        "    print(f\"\\n{'':<15}\", end=\"\")\n",
        "    for label in label_names:\n",
        "        print(f\"{label[:10]:<12}\", end=\"\")\n",
        "    print()\n",
        "    for i, label in enumerate(label_names):\n",
        "        print(f\"{label[:14]:<15}\", end=\"\")\n",
        "        for j in range(len(label_names)):\n",
        "            print(f\"{cm[i, j]:<12}\", end=\"\")\n",
        "        print(f\"  (True: {support_per_class[i]})\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "    print(\"=\" * 80)\n",
        "    print(classification_report(y_test, predictions, target_names=label_names, zero_division=0))\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'per_class_metrics': {\n",
        "            label: {\n",
        "                'precision': precision_per_class[i],\n",
        "                'recall': recall_per_class[i],\n",
        "                'f1': f1_per_class[i],\n",
        "                'support': support_per_class[i]\n",
        "            }\n",
        "            for i, label in enumerate(label_names)\n",
        "        },\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': predictions,\n",
        "        'probabilities': probabilities\n",
        "    }\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"‚úÖ Final evaluation complete!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run final evaluation\n",
        "print(\"Ready to evaluate on ground truth test set.\")\n",
        "print(\"Run: results = evaluate_on_ground_truth_test_set()\")\n",
        "print(\"\\nOr if you want to evaluate now, uncomment the line below:\")\n",
        "# results = evaluate_on_ground_truth_test_set()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2743b720cfa14634850fe0e1acbb08f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e12fd7da736b400e96a6c31289ede30b",
              "IPY_MODEL_74e4de408d2d4147be00cb03b616e1ab",
              "IPY_MODEL_6bc7c2f801844bef8ec14da718224dfd"
            ],
            "layout": "IPY_MODEL_681ceb51892742d3816774cea2fa615e"
          }
        },
        "e12fd7da736b400e96a6c31289ede30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cde5d60a6df4eb99c777577305002d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_410e2d8cda244bb88918e4c17e11f628",
            "value": "config.json:‚Äá100%"
          }
        },
        "74e4de408d2d4147be00cb03b616e1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df36078f119b4f4c99a5952c54516501",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d8ebc83be1242f69a9cf4b105469d42",
            "value": 385
          }
        },
        "6bc7c2f801844bef8ec14da718224dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f46d1603caf4ad29f82bbe703c2afc8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cc1991c04d214e31a99d538293d6c421",
            "value": "‚Äá385/385‚Äá[00:00&lt;00:00,‚Äá43.0kB/s]"
          }
        },
        "681ceb51892742d3816774cea2fa615e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cde5d60a6df4eb99c777577305002d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410e2d8cda244bb88918e4c17e11f628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df36078f119b4f4c99a5952c54516501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8ebc83be1242f69a9cf4b105469d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f46d1603caf4ad29f82bbe703c2afc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1991c04d214e31a99d538293d6c421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e4b067deac465980a7e157429c01f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_282ac484f646432cac9c13edfdf76643",
              "IPY_MODEL_acac9ac7111748a98fb89fd599259783",
              "IPY_MODEL_f8affcff1bd2450c815ad5761c2e0616"
            ],
            "layout": "IPY_MODEL_1b33d405b5994356b5d1fa4337c86069"
          }
        },
        "282ac484f646432cac9c13edfdf76643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a90e9df04c243f7819a844f10bf1eb2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_14440a09ca494a4ab08d2993b26bef05",
            "value": "vocab.txt:‚Äá"
          }
        },
        "acac9ac7111748a98fb89fd599259783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f6c015062b44d058748cebcf7804c5a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_395dec1199b246c0981e6678d7b5e319",
            "value": 1
          }
        },
        "f8affcff1bd2450c815ad5761c2e0616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e29cb7f9c1f4888a057700f9a7052ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f60bda6a6f84d189ebbda058b237eac",
            "value": "‚Äá213k/?‚Äá[00:00&lt;00:00,‚Äá10.8MB/s]"
          }
        },
        "1b33d405b5994356b5d1fa4337c86069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a90e9df04c243f7819a844f10bf1eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14440a09ca494a4ab08d2993b26bef05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6c015062b44d058748cebcf7804c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "395dec1199b246c0981e6678d7b5e319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e29cb7f9c1f4888a057700f9a7052ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f60bda6a6f84d189ebbda058b237eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69126241636484ba529ac949f45d2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e3cd1f34134e45a09dd4f71ce9a48d",
              "IPY_MODEL_68e961bef26f46a4991bd21aef5567d1",
              "IPY_MODEL_232610b0db89457ba288626ba5f0c2cd"
            ],
            "layout": "IPY_MODEL_b4794f3efc4840929f9ff65dd74cfe71"
          }
        },
        "e7e3cd1f34134e45a09dd4f71ce9a48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1c254545d0041fe905fea3ebf32f833",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_59083549596b464ca1a1156223bf67a6",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "68e961bef26f46a4991bd21aef5567d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d7486f56884c9e8b805c1fd1b11fde",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beeb3d13a86d464bb998d8bad55c6511",
            "value": 435778770
          }
        },
        "232610b0db89457ba288626ba5f0c2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317b2539f9af4cf8bedd0b9123ceb7e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4261dac2993d447f91d0065ddb2f5876",
            "value": "‚Äá436M/436M‚Äá[00:07&lt;00:00,‚Äá55.1MB/s]"
          }
        },
        "b4794f3efc4840929f9ff65dd74cfe71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c254545d0041fe905fea3ebf32f833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59083549596b464ca1a1156223bf67a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15d7486f56884c9e8b805c1fd1b11fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beeb3d13a86d464bb998d8bad55c6511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "317b2539f9af4cf8bedd0b9123ceb7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4261dac2993d447f91d0065ddb2f5876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa2b0f0826e84157b9b0a7a7a5510d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4051c092ffe34233a178dc1d23b49cbc",
              "IPY_MODEL_2d9e132b019a482bbf83e381ae34dcf1",
              "IPY_MODEL_44ba20c07bf64fb495ea0715bd25dd7d"
            ],
            "layout": "IPY_MODEL_df217802f8ef400aa40a12c6b8d2ca26"
          }
        },
        "4051c092ffe34233a178dc1d23b49cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a9650b33cd41a19514555a3b57d0d3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1f94d3d25ee14dcc829c703843541d81",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "2d9e132b019a482bbf83e381ae34dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38a17e3bc34142ffbb76aee8c5e7a8a6",
            "max": 435755888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c568fe15b1834329aa8c7652385329d7",
            "value": 435755888
          }
        },
        "44ba20c07bf64fb495ea0715bd25dd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9fa6019c8847ab9904e5ce04e1767a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_51198c5fcf6d46d9ab570ef8d3bfd935",
            "value": "‚Äá436M/436M‚Äá[00:04&lt;00:00,‚Äá171MB/s]"
          }
        },
        "df217802f8ef400aa40a12c6b8d2ca26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a9650b33cd41a19514555a3b57d0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f94d3d25ee14dcc829c703843541d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38a17e3bc34142ffbb76aee8c5e7a8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c568fe15b1834329aa8c7652385329d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9fa6019c8847ab9904e5ce04e1767a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51198c5fcf6d46d9ab570ef8d3bfd935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}